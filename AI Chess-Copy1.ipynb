{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPMIND ALPHAZERO CHESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "\n",
    "\n",
    "## TODO LATER\n",
    "#### - Get backward possibly loss to train the controller. Might need to save the tensor output like states, values, etc in MCTS\n",
    "- Create Self play class\n",
    "- Create Arena class\n",
    "\n",
    "DEEP MIND OPEN ACCESS PAPER \n",
    "\n",
    "https://kstatic.googleusercontent.com/files/2f51b2a749a284c2e2dfa13911da965f4855092a179469aedd15fbe4efe8f8cbf9c515ef83ac03a6515fa990e6f85fd827dcd477845e806f23a17845072dc7bd\n",
    "\n",
    "RAY ALPHA ZERO IMPLEMENTATION \n",
    "\n",
    "https://github.com/ray-project/ray/tree/master/rllib/contrib/alpha_zero\n",
    "\n",
    "DUPLICATED MCTS IMPLEMENTATION\n",
    "\n",
    "https://github.com/suragnair/alpha-zero-general/blob/master/MCTS.py\n",
    "\n",
    "DISTRIBUTED IMPLEMENTATION\n",
    "\n",
    "https://github.com/mokemokechicken/reversi-alpha-zero/blob/master/src/reversi_zero/lib/ggf.py\n",
    "\n",
    "CHESS MOVES\n",
    "\n",
    "https://www.ichess.net/blog/chess-pieces-moves/\n",
    "\n",
    "BOARD REPRESENTATIONS\n",
    "\n",
    "https://medium.com/datadriveninvestor/reconstructing-chess-positions-f195fd5944e\n",
    "\n",
    "ALPHA ZERO EXPLANATION\n",
    "\n",
    "https://nikcheerla.github.io/deeplearningschool/2018/01/01/AlphaZero-Explained/\n",
    "\n",
    "TRANSFORMER NETWORK IMPLEMENTATION\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess, gym, pickle, random, torch, math\n",
    "import chess.svg as svg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy, deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Categorical\n",
    "# plt.style.use('ggplot')\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from copy import deepcopy\n",
    "from colorama import init, Fore, Back, Style\n",
    "from collections import Counter, deque\n",
    "from tqdm import tqdm, tnrange, notebook\n",
    "from random import shuffle\n",
    "\n",
    "from utilities import *\n",
    "# import constants \n",
    "from constants import *\n",
    "from models.vae import CNN_VAE, train_vae, Conv\n",
    "from models.mdn import MDN_RNN, loss_function, clip_grad_norm_\n",
    "from models.controller import Controller\n",
    "\n",
    "# init(convert = True)\n",
    "# REFERENCES\n",
    "# Tensorflow implementation for Chess\n",
    "# https://github.com/saurabhk7/chess-alpha-zero\n",
    "\n",
    "# Pytorch implementation for Connect4\n",
    "# https://github.com/plkmo/AlphaZero_Connect4/tree/master/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"390\" version=\"1.1\" viewBox=\"0 0 390 390\" width=\"390\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><g class=\"white pawn\" id=\"white-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#000000; stroke:#000000;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /></g><g class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g class=\"black pawn\" id=\"black-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#ececec; stroke:#ececec;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-linejoin=\"miter\" stroke-width=\"1\" /></g><g class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect fill=\"#212121\" height=\"390\" width=\"390\" x=\"0\" y=\"0\" /><rect class=\"square dark a1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"330\" /><use transform=\"translate(15, 330)\" xlink:href=\"#white-rook\" /><rect class=\"square light b1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"330\" /><use transform=\"translate(60, 330)\" xlink:href=\"#white-knight\" /><rect class=\"square dark c1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"330\" /><use transform=\"translate(105, 330)\" xlink:href=\"#white-bishop\" /><rect class=\"square light d1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"330\" /><use transform=\"translate(150, 330)\" xlink:href=\"#white-queen\" /><rect class=\"square dark e1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"330\" /><use transform=\"translate(195, 330)\" xlink:href=\"#white-king\" /><rect class=\"square light f1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"330\" /><use transform=\"translate(240, 330)\" xlink:href=\"#white-bishop\" /><rect class=\"square dark g1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"330\" /><use transform=\"translate(285, 330)\" xlink:href=\"#white-knight\" /><rect class=\"square light h1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"330\" /><use transform=\"translate(330, 330)\" xlink:href=\"#white-rook\" /><rect class=\"square light a2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"285\" /><use transform=\"translate(15, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark b2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"285\" /><use transform=\"translate(60, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light c2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"285\" /><use transform=\"translate(105, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark d2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"285\" /><use transform=\"translate(150, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light e2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"285\" /><use transform=\"translate(195, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark f2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"285\" /><use transform=\"translate(240, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light g2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"285\" /><use transform=\"translate(285, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark h2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"285\" /><use transform=\"translate(330, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark a3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"240\" /><rect class=\"square light b3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"240\" /><rect class=\"square dark c3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"240\" /><rect class=\"square light d3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"240\" /><rect class=\"square dark e3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"240\" /><rect class=\"square light f3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"240\" /><rect class=\"square dark g3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"240\" /><rect class=\"square light h3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"240\" /><rect class=\"square light a4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"195\" /><rect class=\"square dark b4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"195\" /><rect class=\"square light c4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"195\" /><rect class=\"square dark d4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"195\" /><rect class=\"square light e4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"195\" /><rect class=\"square dark f4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"195\" /><rect class=\"square light g4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"195\" /><rect class=\"square dark h4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"195\" /><rect class=\"square dark a5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"150\" /><rect class=\"square light b5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"150\" /><rect class=\"square dark c5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"150\" /><rect class=\"square light d5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"150\" /><rect class=\"square dark e5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"150\" /><rect class=\"square light f5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"150\" /><rect class=\"square dark g5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"150\" /><rect class=\"square light h5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"150\" /><rect class=\"square light a6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"105\" /><rect class=\"square dark b6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"105\" /><rect class=\"square light c6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"105\" /><rect class=\"square dark d6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"105\" /><rect class=\"square light e6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"105\" /><rect class=\"square dark f6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"105\" /><rect class=\"square light g6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"105\" /><rect class=\"square dark h6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"105\" /><rect class=\"square dark a7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"60\" /><use transform=\"translate(15, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light b7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"60\" /><use transform=\"translate(60, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark c7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"60\" /><use transform=\"translate(105, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light d7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"60\" /><use transform=\"translate(150, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark e7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"60\" /><use transform=\"translate(195, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light f7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"60\" /><use transform=\"translate(240, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark g7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"60\" /><use transform=\"translate(285, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light h7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"60\" /><use transform=\"translate(330, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light a8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"15\" /><use transform=\"translate(15, 15)\" xlink:href=\"#black-rook\" /><rect class=\"square dark b8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"15\" /><use transform=\"translate(60, 15)\" xlink:href=\"#black-knight\" /><rect class=\"square light c8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"15\" /><use transform=\"translate(105, 15)\" xlink:href=\"#black-bishop\" /><rect class=\"square dark d8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"15\" /><use transform=\"translate(150, 15)\" xlink:href=\"#black-queen\" /><rect class=\"square light e8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"15\" /><use transform=\"translate(195, 15)\" xlink:href=\"#black-king\" /><rect class=\"square dark f8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"15\" /><use transform=\"translate(240, 15)\" xlink:href=\"#black-bishop\" /><rect class=\"square light g8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"15\" /><use transform=\"translate(285, 15)\" xlink:href=\"#black-knight\" /><rect class=\"square dark h8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"15\" /><use transform=\"translate(330, 15)\" xlink:href=\"#black-rook\" /><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 0) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 375) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 0) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 375) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 0) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 375) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 0) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 375) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 0) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 375) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 0) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 375) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 0) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 375) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 0) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 375) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
      ],
      "text/plain": [
       "Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chess_Environment(gym.Env):\n",
    "    \"\"\"Chess Environment\"\"\"\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "        self.white_pieces = ['P', 'N', 'B', 'R', 'Q', 'K']\n",
    "        self.black_pieces = [piece.lower() for piece in self.white_pieces]\n",
    "        self.x_coords, self.y_coords = np.meshgrid(list(range(0, 8)), list(range(0, 8)))\n",
    "        self.x_coords = self.x_coords / 7\n",
    "        self.y_coords = self.y_coords / 7\n",
    "        self.state_size = self.observe()[0].shape\n",
    "        self.init_action_decoder()\n",
    "        self.whites_turn = True\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment\"\"\"\n",
    "        self.board = chess.Board()\n",
    "        \n",
    "    def terminal_test(self):\n",
    "        \"\"\"Checks if the game is over\"\"\"\n",
    "        return self.board.is_game_over(claim_draw = True)\n",
    "    \n",
    "    def result(self):\n",
    "        \"\"\"Gives the end game result\"\"\"\n",
    "\n",
    "        result = self.board.result(claim_draw = True)\n",
    "        if result == '1-0':\n",
    "            return 1\n",
    "        elif result == '0-1':\n",
    "            return -1\n",
    "        elif result == '1/2-1/2':\n",
    "            return 0.5\n",
    "        elif result == '*':\n",
    "            return 0\n",
    "        else:\n",
    "            raise Exception('Invalid Result', result)\n",
    "        \n",
    "    def legal_actions(self):\n",
    "        \"\"\"Provides a list of legal actions in current state\"\"\"\n",
    "        legal_actions = [str(legal_action) for legal_action in list(self.board.legal_moves)]\n",
    "        return legal_actions\n",
    "    \n",
    "    def encode(self):\n",
    "        \"\"\"Encodes game state into a string\"\"\"\n",
    "        board_ = self.board.piece_map()\n",
    "            \n",
    "        encoded = {\n",
    "            'board' : board_,\n",
    "            'turn' : self.board.turn,\n",
    "            'legal_actions' : self.legal_actions()\n",
    "        }\n",
    "        \n",
    "        return pickle.dumps(encoded)\n",
    "    \n",
    "    def decode(self, encoded):\n",
    "        \"\"\"Decodes string into game state and sets board and turn\"\"\"\n",
    "        decoded = pickle.loads(encoded)\n",
    "        self.board.set_piece_map(decoded['board'])\n",
    "        if decoded['turn'] == False:\n",
    "            self.board = self.board.mirror()\n",
    "        self.board.turn = decoded['turn']\n",
    "\n",
    "    def observe(self):\n",
    "        \"\"\"Create observation from the game state\"\"\"\n",
    "\n",
    "        board_ = copy(self.board)\n",
    "            \n",
    "        board_ = np.ndarray.flatten(np.array(board_.__str__().split())).reshape(8, 8)\n",
    "        \n",
    "        black_pawns = np.isin(copy(board_), ['p']).astype(int)\n",
    "        black_knights = np.isin(copy(board_), ['n']).astype(int)\n",
    "        black_rooks = np.isin(copy(board_), ['r']).astype(int)\n",
    "        black_bishops = np.isin(copy(board_), ['b']).astype(int)\n",
    "        black_queen = np.isin(copy(board_), ['q']).astype(int)\n",
    "        black_king = np.isin(copy(board_), ['k']).astype(int)\n",
    "         \n",
    "        white_pawns = np.isin(copy(board_), ['P']).astype(int)\n",
    "        white_knights = np.isin(copy(board_), ['N']).astype(int)\n",
    "        white_rooks = np.isin(copy(board_), ['R']).astype(int)\n",
    "        white_bishops = np.isin(copy(board_), ['B']).astype(int)\n",
    "        white_queen = np.isin(copy(board_), ['Q']).astype(int)\n",
    "        white_king = np.isin(copy(board_), ['K']).astype(int)\n",
    "        \n",
    "        state = np.array([\n",
    "            white_pawns,\n",
    "            white_knights,\n",
    "            white_rooks,\n",
    "            white_bishops,\n",
    "            white_queen,\n",
    "            white_king,\n",
    "            black_pawns,\n",
    "            black_knights,\n",
    "            black_rooks,\n",
    "            black_bishops,\n",
    "            black_queen,\n",
    "            black_king\n",
    "        ])\n",
    "        \n",
    "        return state, self.legal_actions()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Perform a step in the environment\"\"\"\n",
    "        try:\n",
    "            self.board.push_uci(action)\n",
    "        except ValueError:\n",
    "            print(f\"ACTION {action} LEGAL ACTIONS\\n{self.legal_actions()}\")\n",
    "        self.board = self.board.mirror()\n",
    "        if self.whites_turn:\n",
    "            self.whites_turn = False\n",
    "        else:\n",
    "            self.whites_turn = True\n",
    "        return self.observe()\n",
    "    \n",
    "    def move_board(self, move):\n",
    "        \"\"\"Moves the board positions as per the move\"\"\"\n",
    "\n",
    "        char_to_int = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8} \n",
    "\n",
    "        int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "\n",
    "        encoded_board = [(char_to_int[pos[0]], int(pos[1])) for pos in np.ndarray.flatten(BOARD)]\n",
    "\n",
    "        new_board = [tuple(map(sum, zip((char_to_int[pos[0]], int(pos[1])), move))) for pos in np.ndarray.flatten(BOARD)]\n",
    "        moves = []\n",
    "        for pos, new_pos in zip(np.ndarray.flatten(BOARD), new_board):\n",
    "            try:\n",
    "                if new_pos[1] > 8:\n",
    "                    raise Exception()\n",
    "                if move[2] is None:\n",
    "                    move_ = f'{pos}{int_to_char[new_pos[0]]}{new_pos[1]}'\n",
    "                else:\n",
    "                    move_ = f'{pos}{int_to_char[new_pos[0]]}{new_pos[1]}{move[2]}'\n",
    "            \n",
    "                if '-' in move_:\n",
    "                    raise Exception()\n",
    "            \n",
    "                if '0' in move_:\n",
    "                    raise Exception()\n",
    "                \n",
    "            except Exception:\n",
    "                move_ = 'XXXX'\n",
    "            moves.append(move_)   \n",
    "        return np.array(moves).reshape(8, 8)\n",
    "    \n",
    "    def init_action_decoder(self):\n",
    "        \"\"\"Initialize the decoder to decode the actions\"\"\"\n",
    "        decoder = []\n",
    "        for key in MOVES.keys():\n",
    "            decoder_ = self.move_board(MOVES[key])\n",
    "            decoder.append(decoder_)\n",
    "#             print(f'Move {key}\\n', new_board, '\\n')\n",
    "    \n",
    "        self.decoder = np.array(decoder)\n",
    "        self.action_size = self.decoder.shape\n",
    "        \n",
    "    def select_action(self, logits):\n",
    "        \"\"\"Decodes the output from the NN to legal actions\"\"\" \n",
    "        decoder_ = np.ndarray.flatten(self.decoder)\n",
    "        logits_ = np.ndarray.flatten(logits)\n",
    "\n",
    "        move_logits = [(decoder_[idx].lower(), logits_[idx]) for idx in range(len(logits_))]\n",
    "        move_logits = dict(move_logits)\n",
    "        \n",
    "        legal_move_logits = {legal_action: move_logits[legal_action] for legal_action in self.legal_actions()}\n",
    "        probabilities = list(legal_move_logits.values()) / sum(list(legal_move_logits.values()))\n",
    "\n",
    "        action = random.choices(list(legal_move_logits.keys()), weights = probabilities, k = 1)[0]\n",
    "        return action\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Render chess board\"\"\"\n",
    "        chess.svg.board(board = self.board)  \n",
    "\n",
    "env = Chess_Environment()\n",
    "env.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Conv VAE/Test/\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "CNN_VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (enc_conv_mu): Conv(\n",
      "    (conv): Conv1d(512, 600, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      "  (enc_conv_logvar): Conv(\n",
      "    (conv): Conv1d(512, 600, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): ConvTranspose2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (dec_conv): Conv(\n",
      "    (conv): Conv1d(600, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "checkpoints/MDN RNN/Test/\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "MDN_RNN(\n",
      "  (lstm): LSTM(638, 100, batch_first=True)\n",
      "  (fc1): Linear(in_features=100, out_features=12000, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=12000, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=12000, bias=True)\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "Controller(\n",
      "  (fc1): Linear(in_features=700, out_features=1200, bias=True)\n",
      "  (fc_v1): Linear(in_features=700, out_features=100, bias=True)\n",
      "  (fc_v2): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (fc_v3): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(1200, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 76, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, decoder, action_size, vae, mdn, controller, batch_size = 64):\n",
    "        self.batch_size = batch_size\n",
    "        self.action_size = action_size\n",
    "        self.decoder = decoder\n",
    "        self.vae = CNN_VAE(vae, None, 'Latest')\n",
    "        self.mdn = MDN_RNN(mdn, None, 'Latest')\n",
    "        params = {\n",
    "            'hidden_size' : self.mdn.hidden_size,\n",
    "            'z_size' : self.vae.z_size,\n",
    "            'action_size' : action_size,\n",
    "            'expansion_size': 1200\n",
    "        }\n",
    "        self.controller = Controller('Test', params, False)\n",
    "        \n",
    "        self.char_to_int = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8} \n",
    "        self.char_to_int_promo = {'r': 1, 'b': 2, 'q': 3, 'k': 4, 'n': 5, '': 6} \n",
    "        \n",
    "        moves_df = pd.DataFrame(list(zip(self.char_to_int.values(), self.char_to_int.keys())), columns = ['Ids', 'Labels'])\n",
    "        promo_df = pd.DataFrame(list(zip(self.char_to_int_promo.values(), self.char_to_int_promo.keys())), columns = ['Ids', 'Labels'])\n",
    "        self.move_actions_ohe = pd.get_dummies(moves_df['Ids'])\n",
    "        self.promo_actions_ohe = pd.get_dummies(promo_df['Ids'])\n",
    "    \n",
    "    def select_action(self, logits, legal_actions):\n",
    "        \"\"\"Decodes the output from the NN to legal actions\"\"\" \n",
    "        decoder_ = np.ndarray.flatten(self.decoder)\n",
    "        logits_ = np.ndarray.flatten(logits)\n",
    "\n",
    "        move_logits = [(decoder_[idx].lower(), logits_[idx]) for idx in range(len(logits_))]\n",
    "        move_logits = dict(move_logits)\n",
    "        \n",
    "        legal_move_logits = {legal_action: move_logits[legal_action] for legal_action in legal_actions}\n",
    "        probabilities = list(legal_move_logits.values()) / sum(list(legal_move_logits.values()))\n",
    "        \n",
    "        legal_actions = list(legal_move_logits.keys())\n",
    "        action = random.choices(list(legal_move_logits.keys()), weights = probabilities, k = 1)[0]\n",
    "        \n",
    "        action_probabilities = {legal_actions[idx] : probabilities[idx] for idx in range(len(legal_actions))}\n",
    "        return action, action_probabilities\n",
    "    \n",
    "    def one_hot_encode_action(self, action):\n",
    "        \"\"\"One hot encodes the action\"\"\"\n",
    "        if len(action) == 4:\n",
    "            encoded_action = [\n",
    "                self.move_actions_ohe.loc[\n",
    "                self.char_to_int[action[0]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[1]) - 1].values, \n",
    "                self.move_actions_ohe.loc[self.char_to_int[action[2]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[3]) - 1].values,\n",
    "                self.promo_actions_ohe.loc[self.char_to_int_promo[''] - 1].values\n",
    "            ]\n",
    "        else:\n",
    "            encoded_action = [\n",
    "                self.move_actions_ohe.loc[\n",
    "                self.char_to_int[action[0]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[1]) - 1].values, \n",
    "                self.move_actions_ohe.loc[self.char_to_int[action[2]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[3]) - 1].values,\n",
    "                self.promo_actions_ohe.loc[self.char_to_int_promo[action[4]] - 1].values\n",
    "            ]\n",
    "        ohe_action = np.concatenate(encoded_action)\n",
    "        return ohe_action\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        \"\"\"Resets the MDNs hidden state\"\"\"\n",
    "        self.hidden = self.mdn.init_hidden(batch_size)\n",
    "        \n",
    "    def act(self, state, legal_actions):\n",
    "        \"\"\"Gets an action from the agent\"\"\"\n",
    "        state = torch.tensor(state).float().unsqueeze(0)\n",
    "        mu, logvar = self.vae.encode(state)\n",
    "        z = self.vae.reparameterize(mu, logvar).squeeze(-1)\n",
    "        zh = torch.cat((z.to('cpu'), self.hidden[0].squeeze(0).to('cpu')), dim = 1)\n",
    "        if zh.shape[0] > 1:\n",
    "            raise Exception('Batch size > 1 not handled')\n",
    "        logits, values = self.controller(zh)\n",
    "        logits, value = logits.detach().squeeze(0).cpu().numpy(), values.detach().squeeze(0).cpu().numpy()[0]\n",
    "        action, action_probabilities = self.select_action(logits, legal_actions)\n",
    "        return action_probabilities, value\n",
    "    \n",
    "    def mcts_act(self, state, legal_actions):\n",
    "        \"\"\"Gets an action from the agent\"\"\"\n",
    "        logits = np.random.rand(env.action_size[0], env.action_size[1], env.action_size[2])\n",
    "        action, action_probabilities = self.select_action(logits, legal_actions)\n",
    "        \n",
    "        return action_probabilities, np.random.rand(10)[0]\n",
    "    \n",
    "    def train(self, experiences):\n",
    "        \"\"\"Trains the agent from the MCTS experiences\"\"\"\n",
    "        batches = []\n",
    "        \n",
    "    \n",
    "\n",
    "agent = Agent(env.decoder, env.action_size, 'Test', 'Test', 'Test')\n",
    "agent.reset(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state, legal_actions = env.observe()\n",
    "\n",
    "# state_planes = [\n",
    "#     'White Pawns',\n",
    "#     'White Knights',\n",
    "#     'White Rooks',\n",
    "#     'White Bishops',\n",
    "#     'White Queen',\n",
    "#     'White King',\n",
    "#     'Black Pawns',\n",
    "#     'Black Knights',\n",
    "#     'Black Rooks',\n",
    "#     'Black Bishops',\n",
    "#     'Black Queen',\n",
    "#     'Black King'\n",
    "# ]\n",
    "\n",
    "# for inx, state_ in enumerate(state):\n",
    "#     fig = plt.figure()\n",
    "#     fig.suptitle(state_planes[inx], fontsize = 20)\n",
    "#     xticks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "#     yticks = list(range(1, 9))\n",
    "#     yticks.reverse()\n",
    "#     plt.xticks(list(range(0, 8)), xticks)\n",
    "#     plt.yticks(list(range(0, 8)), yticks)\n",
    "#     plt.imshow(state_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 QUEEN MOVES ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'NE1', 'NE2', 'NE3', 'NE4', 'NE5', 'NE6', 'NE7', 'E1']\n",
      "8 KNIGHT MOVES ['2N1E', '1N2E', '1S2E', '2S1E', '2S1W', '1S2W', '1N2W', '2N1W']\n",
      "3 UNDERPROMOTION MOVES ['DOUBLEM', 'NECUT', 'NWCUT']\n",
      "\n",
      "TOTAL MOVES 67\n",
      "['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'NE1', 'NE2', 'NE3', 'NE4', 'NE5', 'NE6', 'NE7', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'SE1', 'SE2', 'SE3', 'SE4', 'SE5', 'SE6', 'SE7', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'SW1', 'SW2', 'SW3', 'SW4', 'SW5', 'SW6', 'SW7', 'W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7', 'NW1', 'NW2', 'NW3', 'NW4', 'NW5', 'NW6', 'NW7', '2N1E', '1N2E', '1S2E', '2S1E', '2S1W', '1S2W', '1N2W', '2N1W', 'DOUBLEM', 'NECUT', 'NWCUT']\n"
     ]
    }
   ],
   "source": [
    "queen_directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "queen_distance = list(range(1, 8))\n",
    "queen_moves = [f'{direction}{distance}' for direction in queen_directions for distance in queen_distance]\n",
    "\n",
    "knight_moves = ['2N1E', '1N2E', '1S2E', '2S1E', '2S1W', '1S2W', '1N2W', '2N1W']\n",
    "underpromotion_moves = ['DOUBLEM', 'NECUT', 'NWCUT']\n",
    "moves = queen_moves + knight_moves + underpromotion_moves\n",
    "\n",
    "print(f'{len(queen_moves)} QUEEN MOVES {queen_moves[: 15]}\\n{len(knight_moves)} KNIGHT MOVES {knight_moves}\\n{len(underpromotion_moves)} UNDERPROMOTION MOVES {underpromotion_moves}')\n",
    "print(f'\\nTOTAL MOVES {len(moves)}')\n",
    "print(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move Q N1\n",
      "(0, 1, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7A8' 'B7B8' 'C7C8' 'D7D8' 'E7E8' 'F7F8' 'G7G8' 'H7H8']\n",
      " ['A6A7' 'B6B7' 'C6C7' 'D6D7' 'E6E7' 'F6F7' 'G6G7' 'H6H7']\n",
      " ['A5A6' 'B5B6' 'C5C6' 'D5D6' 'E5E6' 'F5F6' 'G5G6' 'H5H6']\n",
      " ['A4A5' 'B4B5' 'C4C5' 'D4D5' 'E4E5' 'F4F5' 'G4G5' 'H4H5']\n",
      " ['A3A4' 'B3B4' 'C3C4' 'D3D4' 'E3E4' 'F3F4' 'G3G4' 'H3H4']\n",
      " ['A2A3' 'B2B3' 'C2C3' 'D2D3' 'E2E3' 'F2F3' 'G2G3' 'H2H3']\n",
      " ['A1A2' 'B1B2' 'C1C2' 'D1D2' 'E1E2' 'F1F2' 'G1G2' 'H1H2']] \n",
      "\n",
      "Move Q N2\n",
      "(0, 2, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6A8' 'B6B8' 'C6C8' 'D6D8' 'E6E8' 'F6F8' 'G6G8' 'H6H8']\n",
      " ['A5A7' 'B5B7' 'C5C7' 'D5D7' 'E5E7' 'F5F7' 'G5G7' 'H5H7']\n",
      " ['A4A6' 'B4B6' 'C4C6' 'D4D6' 'E4E6' 'F4F6' 'G4G6' 'H4H6']\n",
      " ['A3A5' 'B3B5' 'C3C5' 'D3D5' 'E3E5' 'F3F5' 'G3G5' 'H3H5']\n",
      " ['A2A4' 'B2B4' 'C2C4' 'D2D4' 'E2E4' 'F2F4' 'G2G4' 'H2H4']\n",
      " ['A1A3' 'B1B3' 'C1C3' 'D1D3' 'E1E3' 'F1F3' 'G1G3' 'H1H3']] \n",
      "\n",
      "Move Q N3\n",
      "(0, 3, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5A8' 'B5B8' 'C5C8' 'D5D8' 'E5E8' 'F5F8' 'G5G8' 'H5H8']\n",
      " ['A4A7' 'B4B7' 'C4C7' 'D4D7' 'E4E7' 'F4F7' 'G4G7' 'H4H7']\n",
      " ['A3A6' 'B3B6' 'C3C6' 'D3D6' 'E3E6' 'F3F6' 'G3G6' 'H3H6']\n",
      " ['A2A5' 'B2B5' 'C2C5' 'D2D5' 'E2E5' 'F2F5' 'G2G5' 'H2H5']\n",
      " ['A1A4' 'B1B4' 'C1C4' 'D1D4' 'E1E4' 'F1F4' 'G1G4' 'H1H4']] \n",
      "\n",
      "Move Q N4\n",
      "(0, 4, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4A8' 'B4B8' 'C4C8' 'D4D8' 'E4E8' 'F4F8' 'G4G8' 'H4H8']\n",
      " ['A3A7' 'B3B7' 'C3C7' 'D3D7' 'E3E7' 'F3F7' 'G3G7' 'H3H7']\n",
      " ['A2A6' 'B2B6' 'C2C6' 'D2D6' 'E2E6' 'F2F6' 'G2G6' 'H2H6']\n",
      " ['A1A5' 'B1B5' 'C1C5' 'D1D5' 'E1E5' 'F1F5' 'G1G5' 'H1H5']] \n",
      "\n",
      "Move Q N5\n",
      "(0, 5, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3A8' 'B3B8' 'C3C8' 'D3D8' 'E3E8' 'F3F8' 'G3G8' 'H3H8']\n",
      " ['A2A7' 'B2B7' 'C2C7' 'D2D7' 'E2E7' 'F2F7' 'G2G7' 'H2H7']\n",
      " ['A1A6' 'B1B6' 'C1C6' 'D1D6' 'E1E6' 'F1F6' 'G1G6' 'H1H6']] \n",
      "\n",
      "Move Q N6\n",
      "(0, 6, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2A8' 'B2B8' 'C2C8' 'D2D8' 'E2E8' 'F2F8' 'G2G8' 'H2H8']\n",
      " ['A1A7' 'B1B7' 'C1C7' 'D1D7' 'E1E7' 'F1F7' 'G1G7' 'H1H7']] \n",
      "\n",
      "Move Q N7\n",
      "(0, 7, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1A8' 'B1B8' 'C1C8' 'D1D8' 'E1E8' 'F1F8' 'G1G8' 'H1H8']] \n",
      "\n",
      "Move Q NE1\n",
      "(1, 1, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7B8' 'B7C8' 'C7D8' 'D7E8' 'E7F8' 'F7G8' 'G7H8' 'XXXX']\n",
      " ['A6B7' 'B6C7' 'C6D7' 'D6E7' 'E6F7' 'F6G7' 'G6H7' 'XXXX']\n",
      " ['A5B6' 'B5C6' 'C5D6' 'D5E6' 'E5F6' 'F5G6' 'G5H6' 'XXXX']\n",
      " ['A4B5' 'B4C5' 'C4D5' 'D4E5' 'E4F5' 'F4G5' 'G4H5' 'XXXX']\n",
      " ['A3B4' 'B3C4' 'C3D4' 'D3E4' 'E3F4' 'F3G4' 'G3H4' 'XXXX']\n",
      " ['A2B3' 'B2C3' 'C2D3' 'D2E3' 'E2F3' 'F2G3' 'G2H3' 'XXXX']\n",
      " ['A1B2' 'B1C2' 'C1D2' 'D1E2' 'E1F2' 'F1G2' 'G1H2' 'XXXX']] \n",
      "\n",
      "Move Q NE2\n",
      "(2, 2, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6C8' 'B6D8' 'C6E8' 'D6F8' 'E6G8' 'F6H8' 'XXXX' 'XXXX']\n",
      " ['A5C7' 'B5D7' 'C5E7' 'D5F7' 'E5G7' 'F5H7' 'XXXX' 'XXXX']\n",
      " ['A4C6' 'B4D6' 'C4E6' 'D4F6' 'E4G6' 'F4H6' 'XXXX' 'XXXX']\n",
      " ['A3C5' 'B3D5' 'C3E5' 'D3F5' 'E3G5' 'F3H5' 'XXXX' 'XXXX']\n",
      " ['A2C4' 'B2D4' 'C2E4' 'D2F4' 'E2G4' 'F2H4' 'XXXX' 'XXXX']\n",
      " ['A1C3' 'B1D3' 'C1E3' 'D1F3' 'E1G3' 'F1H3' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q NE3\n",
      "(3, 3, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5D8' 'B5E8' 'C5F8' 'D5G8' 'E5H8' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4D7' 'B4E7' 'C4F7' 'D4G7' 'E4H7' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3D6' 'B3E6' 'C3F6' 'D3G6' 'E3H6' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2D5' 'B2E5' 'C2F5' 'D2G5' 'E2H5' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1D4' 'B1E4' 'C1F4' 'D1G4' 'E1H4' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q NE4\n",
      "(4, 4, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4E8' 'B4F8' 'C4G8' 'D4H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3E7' 'B3F7' 'C3G7' 'D3H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2E6' 'B2F6' 'C2G6' 'D2H6' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1E5' 'B1F5' 'C1G5' 'D1H5' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q NE5\n",
      "(5, 5, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3F8' 'B3G8' 'C3H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2F7' 'B2G7' 'C2H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1F6' 'B1G6' 'C1H6' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q NE6\n",
      "(6, 6, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2G8' 'B2H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1G7' 'B1H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q NE7\n",
      "(7, 7, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q E1\n",
      "(1, 0, None)\n",
      "[['A8B8' 'B8C8' 'C8D8' 'D8E8' 'E8F8' 'F8G8' 'G8H8' 'XXXX']\n",
      " ['A7B7' 'B7C7' 'C7D7' 'D7E7' 'E7F7' 'F7G7' 'G7H7' 'XXXX']\n",
      " ['A6B6' 'B6C6' 'C6D6' 'D6E6' 'E6F6' 'F6G6' 'G6H6' 'XXXX']\n",
      " ['A5B5' 'B5C5' 'C5D5' 'D5E5' 'E5F5' 'F5G5' 'G5H5' 'XXXX']\n",
      " ['A4B4' 'B4C4' 'C4D4' 'D4E4' 'E4F4' 'F4G4' 'G4H4' 'XXXX']\n",
      " ['A3B3' 'B3C3' 'C3D3' 'D3E3' 'E3F3' 'F3G3' 'G3H3' 'XXXX']\n",
      " ['A2B2' 'B2C2' 'C2D2' 'D2E2' 'E2F2' 'F2G2' 'G2H2' 'XXXX']\n",
      " ['A1B1' 'B1C1' 'C1D1' 'D1E1' 'E1F1' 'F1G1' 'G1H1' 'XXXX']] \n",
      "\n",
      "Move Q E2\n",
      "(2, 0, None)\n",
      "[['A8C8' 'B8D8' 'C8E8' 'D8F8' 'E8G8' 'F8H8' 'XXXX' 'XXXX']\n",
      " ['A7C7' 'B7D7' 'C7E7' 'D7F7' 'E7G7' 'F7H7' 'XXXX' 'XXXX']\n",
      " ['A6C6' 'B6D6' 'C6E6' 'D6F6' 'E6G6' 'F6H6' 'XXXX' 'XXXX']\n",
      " ['A5C5' 'B5D5' 'C5E5' 'D5F5' 'E5G5' 'F5H5' 'XXXX' 'XXXX']\n",
      " ['A4C4' 'B4D4' 'C4E4' 'D4F4' 'E4G4' 'F4H4' 'XXXX' 'XXXX']\n",
      " ['A3C3' 'B3D3' 'C3E3' 'D3F3' 'E3G3' 'F3H3' 'XXXX' 'XXXX']\n",
      " ['A2C2' 'B2D2' 'C2E2' 'D2F2' 'E2G2' 'F2H2' 'XXXX' 'XXXX']\n",
      " ['A1C1' 'B1D1' 'C1E1' 'D1F1' 'E1G1' 'F1H1' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q E3\n",
      "(3, 0, None)\n",
      "[['A8D8' 'B8E8' 'C8F8' 'D8G8' 'E8H8' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7D7' 'B7E7' 'C7F7' 'D7G7' 'E7H7' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6D6' 'B6E6' 'C6F6' 'D6G6' 'E6H6' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5D5' 'B5E5' 'C5F5' 'D5G5' 'E5H5' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4D4' 'B4E4' 'C4F4' 'D4G4' 'E4H4' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3D3' 'B3E3' 'C3F3' 'D3G3' 'E3H3' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2D2' 'B2E2' 'C2F2' 'D2G2' 'E2H2' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1D1' 'B1E1' 'C1F1' 'D1G1' 'E1H1' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q E4\n",
      "(4, 0, None)\n",
      "[['A8E8' 'B8F8' 'C8G8' 'D8H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7E7' 'B7F7' 'C7G7' 'D7H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6E6' 'B6F6' 'C6G6' 'D6H6' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5E5' 'B5F5' 'C5G5' 'D5H5' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4E4' 'B4F4' 'C4G4' 'D4H4' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3E3' 'B3F3' 'C3G3' 'D3H3' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2E2' 'B2F2' 'C2G2' 'D2H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1E1' 'B1F1' 'C1G1' 'D1H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q E5\n",
      "(5, 0, None)\n",
      "[['A8F8' 'B8G8' 'C8H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7F7' 'B7G7' 'C7H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6F6' 'B6G6' 'C6H6' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5F5' 'B5G5' 'C5H5' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4F4' 'B4G4' 'C4H4' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3F3' 'B3G3' 'C3H3' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2F2' 'B2G2' 'C2H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1F1' 'B1G1' 'C1H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q E6\n",
      "(6, 0, None)\n",
      "[['A8G8' 'B8H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7G7' 'B7H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6G6' 'B6H6' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5G5' 'B5H5' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4G4' 'B4H4' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3G3' 'B3H3' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2G2' 'B2H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1G1' 'B1H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q E7\n",
      "(7, 0, None)\n",
      "[['A8H8' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7H7' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6H6' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5H5' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4H4' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A3H3' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A2H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A1H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE1\n",
      "(1, -1, None)\n",
      "[['A8B7' 'B8C7' 'C8D7' 'D8E7' 'E8F7' 'F8G7' 'G8H7' 'XXXX']\n",
      " ['A7B6' 'B7C6' 'C7D6' 'D7E6' 'E7F6' 'F7G6' 'G7H6' 'XXXX']\n",
      " ['A6B5' 'B6C5' 'C6D5' 'D6E5' 'E6F5' 'F6G5' 'G6H5' 'XXXX']\n",
      " ['A5B4' 'B5C4' 'C5D4' 'D5E4' 'E5F4' 'F5G4' 'G5H4' 'XXXX']\n",
      " ['A4B3' 'B4C3' 'C4D3' 'D4E3' 'E4F3' 'F4G3' 'G4H3' 'XXXX']\n",
      " ['A3B2' 'B3C2' 'C3D2' 'D3E2' 'E3F2' 'F3G2' 'G3H2' 'XXXX']\n",
      " ['A2B1' 'B2C1' 'C2D1' 'D2E1' 'E2F1' 'F2G1' 'G2H1' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE2\n",
      "(2, -2, None)\n",
      "[['A8C6' 'B8D6' 'C8E6' 'D8F6' 'E8G6' 'F8H6' 'XXXX' 'XXXX']\n",
      " ['A7C5' 'B7D5' 'C7E5' 'D7F5' 'E7G5' 'F7H5' 'XXXX' 'XXXX']\n",
      " ['A6C4' 'B6D4' 'C6E4' 'D6F4' 'E6G4' 'F6H4' 'XXXX' 'XXXX']\n",
      " ['A5C3' 'B5D3' 'C5E3' 'D5F3' 'E5G3' 'F5H3' 'XXXX' 'XXXX']\n",
      " ['A4C2' 'B4D2' 'C4E2' 'D4F2' 'E4G2' 'F4H2' 'XXXX' 'XXXX']\n",
      " ['A3C1' 'B3D1' 'C3E1' 'D3F1' 'E3G1' 'F3H1' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE3\n",
      "(3, -3, None)\n",
      "[['A8D5' 'B8E5' 'C8F5' 'D8G5' 'E8H5' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7D4' 'B7E4' 'C7F4' 'D7G4' 'E7H4' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6D3' 'B6E3' 'C6F3' 'D6G3' 'E6H3' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5D2' 'B5E2' 'C5F2' 'D5G2' 'E5H2' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A4D1' 'B4E1' 'C4F1' 'D4G1' 'E4H1' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE4\n",
      "(4, -4, None)\n",
      "[['A8E4' 'B8F4' 'C8G4' 'D8H4' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7E3' 'B7F3' 'C7G3' 'D7H3' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6E2' 'B6F2' 'C6G2' 'D6H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A5E1' 'B5F1' 'C5G1' 'D5H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE5\n",
      "(5, -5, None)\n",
      "[['A8F3' 'B8G3' 'C8H3' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7F2' 'B7G2' 'C7H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6F1' 'B6G1' 'C6H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE6\n",
      "(6, -6, None)\n",
      "[['A8G2' 'B8H2' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7G1' 'B7H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SE7\n",
      "(7, -7, None)\n",
      "[['A8H1' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S1\n",
      "(0, -1, None)\n",
      "[['A8A7' 'B8B7' 'C8C7' 'D8D7' 'E8E7' 'F8F7' 'G8G7' 'H8H7']\n",
      " ['A7A6' 'B7B6' 'C7C6' 'D7D6' 'E7E6' 'F7F6' 'G7G6' 'H7H6']\n",
      " ['A6A5' 'B6B5' 'C6C5' 'D6D5' 'E6E5' 'F6F5' 'G6G5' 'H6H5']\n",
      " ['A5A4' 'B5B4' 'C5C4' 'D5D4' 'E5E4' 'F5F4' 'G5G4' 'H5H4']\n",
      " ['A4A3' 'B4B3' 'C4C3' 'D4D3' 'E4E3' 'F4F3' 'G4G3' 'H4H3']\n",
      " ['A3A2' 'B3B2' 'C3C2' 'D3D2' 'E3E2' 'F3F2' 'G3G2' 'H3H2']\n",
      " ['A2A1' 'B2B1' 'C2C1' 'D2D1' 'E2E1' 'F2F1' 'G2G1' 'H2H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S2\n",
      "(0, -2, None)\n",
      "[['A8A6' 'B8B6' 'C8C6' 'D8D6' 'E8E6' 'F8F6' 'G8G6' 'H8H6']\n",
      " ['A7A5' 'B7B5' 'C7C5' 'D7D5' 'E7E5' 'F7F5' 'G7G5' 'H7H5']\n",
      " ['A6A4' 'B6B4' 'C6C4' 'D6D4' 'E6E4' 'F6F4' 'G6G4' 'H6H4']\n",
      " ['A5A3' 'B5B3' 'C5C3' 'D5D3' 'E5E3' 'F5F3' 'G5G3' 'H5H3']\n",
      " ['A4A2' 'B4B2' 'C4C2' 'D4D2' 'E4E2' 'F4F2' 'G4G2' 'H4H2']\n",
      " ['A3A1' 'B3B1' 'C3C1' 'D3D1' 'E3E1' 'F3F1' 'G3G1' 'H3H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S3\n",
      "(0, -3, None)\n",
      "[['A8A5' 'B8B5' 'C8C5' 'D8D5' 'E8E5' 'F8F5' 'G8G5' 'H8H5']\n",
      " ['A7A4' 'B7B4' 'C7C4' 'D7D4' 'E7E4' 'F7F4' 'G7G4' 'H7H4']\n",
      " ['A6A3' 'B6B3' 'C6C3' 'D6D3' 'E6E3' 'F6F3' 'G6G3' 'H6H3']\n",
      " ['A5A2' 'B5B2' 'C5C2' 'D5D2' 'E5E2' 'F5F2' 'G5G2' 'H5H2']\n",
      " ['A4A1' 'B4B1' 'C4C1' 'D4D1' 'E4E1' 'F4F1' 'G4G1' 'H4H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S4\n",
      "(0, -4, None)\n",
      "[['A8A4' 'B8B4' 'C8C4' 'D8D4' 'E8E4' 'F8F4' 'G8G4' 'H8H4']\n",
      " ['A7A3' 'B7B3' 'C7C3' 'D7D3' 'E7E3' 'F7F3' 'G7G3' 'H7H3']\n",
      " ['A6A2' 'B6B2' 'C6C2' 'D6D2' 'E6E2' 'F6F2' 'G6G2' 'H6H2']\n",
      " ['A5A1' 'B5B1' 'C5C1' 'D5D1' 'E5E1' 'F5F1' 'G5G1' 'H5H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S5\n",
      "(0, -5, None)\n",
      "[['A8A3' 'B8B3' 'C8C3' 'D8D3' 'E8E3' 'F8F3' 'G8G3' 'H8H3']\n",
      " ['A7A2' 'B7B2' 'C7C2' 'D7D2' 'E7E2' 'F7F2' 'G7G2' 'H7H2']\n",
      " ['A6A1' 'B6B1' 'C6C1' 'D6D1' 'E6E1' 'F6F1' 'G6G1' 'H6H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S6\n",
      "(0, -6, None)\n",
      "[['A8A2' 'B8B2' 'C8C2' 'D8D2' 'E8E2' 'F8F2' 'G8G2' 'H8H2']\n",
      " ['A7A1' 'B7B1' 'C7C1' 'D7D1' 'E7E1' 'F7F1' 'G7G1' 'H7H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q S7\n",
      "(0, -7, None)\n",
      "[['A8A1' 'B8B1' 'C8C1' 'D8D1' 'E8E1' 'F8F1' 'G8G1' 'H8H1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW1\n",
      "(-1, -1, None)\n",
      "[['XXXX' 'B8A7' 'C8B7' 'D8C7' 'E8D7' 'F8E7' 'G8F7' 'H8G7']\n",
      " ['XXXX' 'B7A6' 'C7B6' 'D7C6' 'E7D6' 'F7E6' 'G7F6' 'H7G6']\n",
      " ['XXXX' 'B6A5' 'C6B5' 'D6C5' 'E6D5' 'F6E5' 'G6F5' 'H6G5']\n",
      " ['XXXX' 'B5A4' 'C5B4' 'D5C4' 'E5D4' 'F5E4' 'G5F4' 'H5G4']\n",
      " ['XXXX' 'B4A3' 'C4B3' 'D4C3' 'E4D3' 'F4E3' 'G4F3' 'H4G3']\n",
      " ['XXXX' 'B3A2' 'C3B2' 'D3C2' 'E3D2' 'F3E2' 'G3F2' 'H3G2']\n",
      " ['XXXX' 'B2A1' 'C2B1' 'D2C1' 'E2D1' 'F2E1' 'G2F1' 'H2G1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW2\n",
      "(-2, -2, None)\n",
      "[['XXXX' 'XXXX' 'C8A6' 'D8B6' 'E8C6' 'F8D6' 'G8E6' 'H8F6']\n",
      " ['XXXX' 'XXXX' 'C7A5' 'D7B5' 'E7C5' 'F7D5' 'G7E5' 'H7F5']\n",
      " ['XXXX' 'XXXX' 'C6A4' 'D6B4' 'E6C4' 'F6D4' 'G6E4' 'H6F4']\n",
      " ['XXXX' 'XXXX' 'C5A3' 'D5B3' 'E5C3' 'F5D3' 'G5E3' 'H5F3']\n",
      " ['XXXX' 'XXXX' 'C4A2' 'D4B2' 'E4C2' 'F4D2' 'G4E2' 'H4F2']\n",
      " ['XXXX' 'XXXX' 'C3A1' 'D3B1' 'E3C1' 'F3D1' 'G3E1' 'H3F1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW3\n",
      "(-3, -3, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'D8A5' 'E8B5' 'F8C5' 'G8D5' 'H8E5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D7A4' 'E7B4' 'F7C4' 'G7D4' 'H7E4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D6A3' 'E6B3' 'F6C3' 'G6D3' 'H6E3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D5A2' 'E5B2' 'F5C2' 'G5D2' 'H5E2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D4A1' 'E4B1' 'F4C1' 'G4D1' 'H4E1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW4\n",
      "(-4, -4, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E8A4' 'F8B4' 'G8C4' 'H8D4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E7A3' 'F7B3' 'G7C3' 'H7D3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E6A2' 'F6B2' 'G6C2' 'H6D2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E5A1' 'F5B1' 'G5C1' 'H5D1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW5\n",
      "(-5, -5, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F8A3' 'G8B3' 'H8C3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F7A2' 'G7B2' 'H7C2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F6A1' 'G6B1' 'H6C1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW6\n",
      "(-6, -6, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G8A2' 'H8B2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G7A1' 'H7B1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q SW7\n",
      "(-7, -7, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H8A1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move Q W1\n",
      "(-1, 0, None)\n",
      "[['XXXX' 'B8A8' 'C8B8' 'D8C8' 'E8D8' 'F8E8' 'G8F8' 'H8G8']\n",
      " ['XXXX' 'B7A7' 'C7B7' 'D7C7' 'E7D7' 'F7E7' 'G7F7' 'H7G7']\n",
      " ['XXXX' 'B6A6' 'C6B6' 'D6C6' 'E6D6' 'F6E6' 'G6F6' 'H6G6']\n",
      " ['XXXX' 'B5A5' 'C5B5' 'D5C5' 'E5D5' 'F5E5' 'G5F5' 'H5G5']\n",
      " ['XXXX' 'B4A4' 'C4B4' 'D4C4' 'E4D4' 'F4E4' 'G4F4' 'H4G4']\n",
      " ['XXXX' 'B3A3' 'C3B3' 'D3C3' 'E3D3' 'F3E3' 'G3F3' 'H3G3']\n",
      " ['XXXX' 'B2A2' 'C2B2' 'D2C2' 'E2D2' 'F2E2' 'G2F2' 'H2G2']\n",
      " ['XXXX' 'B1A1' 'C1B1' 'D1C1' 'E1D1' 'F1E1' 'G1F1' 'H1G1']] \n",
      "\n",
      "Move Q W2\n",
      "(-2, 0, None)\n",
      "[['XXXX' 'XXXX' 'C8A8' 'D8B8' 'E8C8' 'F8D8' 'G8E8' 'H8F8']\n",
      " ['XXXX' 'XXXX' 'C7A7' 'D7B7' 'E7C7' 'F7D7' 'G7E7' 'H7F7']\n",
      " ['XXXX' 'XXXX' 'C6A6' 'D6B6' 'E6C6' 'F6D6' 'G6E6' 'H6F6']\n",
      " ['XXXX' 'XXXX' 'C5A5' 'D5B5' 'E5C5' 'F5D5' 'G5E5' 'H5F5']\n",
      " ['XXXX' 'XXXX' 'C4A4' 'D4B4' 'E4C4' 'F4D4' 'G4E4' 'H4F4']\n",
      " ['XXXX' 'XXXX' 'C3A3' 'D3B3' 'E3C3' 'F3D3' 'G3E3' 'H3F3']\n",
      " ['XXXX' 'XXXX' 'C2A2' 'D2B2' 'E2C2' 'F2D2' 'G2E2' 'H2F2']\n",
      " ['XXXX' 'XXXX' 'C1A1' 'D1B1' 'E1C1' 'F1D1' 'G1E1' 'H1F1']] \n",
      "\n",
      "Move Q W3\n",
      "(-3, 0, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'D8A8' 'E8B8' 'F8C8' 'G8D8' 'H8E8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D7A7' 'E7B7' 'F7C7' 'G7D7' 'H7E7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D6A6' 'E6B6' 'F6C6' 'G6D6' 'H6E6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D5A5' 'E5B5' 'F5C5' 'G5D5' 'H5E5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D4A4' 'E4B4' 'F4C4' 'G4D4' 'H4E4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D3A3' 'E3B3' 'F3C3' 'G3D3' 'H3E3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D2A2' 'E2B2' 'F2C2' 'G2D2' 'H2E2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D1A1' 'E1B1' 'F1C1' 'G1D1' 'H1E1']] \n",
      "\n",
      "Move Q W4\n",
      "(-4, 0, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E8A8' 'F8B8' 'G8C8' 'H8D8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E7A7' 'F7B7' 'G7C7' 'H7D7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E6A6' 'F6B6' 'G6C6' 'H6D6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E5A5' 'F5B5' 'G5C5' 'H5D5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E4A4' 'F4B4' 'G4C4' 'H4D4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E3A3' 'F3B3' 'G3C3' 'H3D3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E2A2' 'F2B2' 'G2C2' 'H2D2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E1A1' 'F1B1' 'G1C1' 'H1D1']] \n",
      "\n",
      "Move Q W5\n",
      "(-5, 0, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F8A8' 'G8B8' 'H8C8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F7A7' 'G7B7' 'H7C7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F6A6' 'G6B6' 'H6C6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F5A5' 'G5B5' 'H5C5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F4A4' 'G4B4' 'H4C4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F3A3' 'G3B3' 'H3C3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F2A2' 'G2B2' 'H2C2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F1A1' 'G1B1' 'H1C1']] \n",
      "\n",
      "Move Q W6\n",
      "(-6, 0, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G8A8' 'H8B8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G7A7' 'H7B7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G6A6' 'H6B6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G5A5' 'H5B5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G4A4' 'H4B4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G3A3' 'H3B3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G2A2' 'H2B2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G1A1' 'H1B1']] \n",
      "\n",
      "Move Q W7\n",
      "(-7, 0, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H8A8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H7A7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H6A6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H5A5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H4A4']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H3A3']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H2A2']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H1A1']] \n",
      "\n",
      "Move Q NW1\n",
      "(-1, 1, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'B7A8' 'C7B8' 'D7C8' 'E7D8' 'F7E8' 'G7F8' 'H7G8']\n",
      " ['XXXX' 'B6A7' 'C6B7' 'D6C7' 'E6D7' 'F6E7' 'G6F7' 'H6G7']\n",
      " ['XXXX' 'B5A6' 'C5B6' 'D5C6' 'E5D6' 'F5E6' 'G5F6' 'H5G6']\n",
      " ['XXXX' 'B4A5' 'C4B5' 'D4C5' 'E4D5' 'F4E5' 'G4F5' 'H4G5']\n",
      " ['XXXX' 'B3A4' 'C3B4' 'D3C4' 'E3D4' 'F3E4' 'G3F4' 'H3G4']\n",
      " ['XXXX' 'B2A3' 'C2B3' 'D2C3' 'E2D3' 'F2E3' 'G2F3' 'H2G3']\n",
      " ['XXXX' 'B1A2' 'C1B2' 'D1C2' 'E1D2' 'F1E2' 'G1F2' 'H1G2']] \n",
      "\n",
      "Move Q NW2\n",
      "(-2, 2, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'C6A8' 'D6B8' 'E6C8' 'F6D8' 'G6E8' 'H6F8']\n",
      " ['XXXX' 'XXXX' 'C5A7' 'D5B7' 'E5C7' 'F5D7' 'G5E7' 'H5F7']\n",
      " ['XXXX' 'XXXX' 'C4A6' 'D4B6' 'E4C6' 'F4D6' 'G4E6' 'H4F6']\n",
      " ['XXXX' 'XXXX' 'C3A5' 'D3B5' 'E3C5' 'F3D5' 'G3E5' 'H3F5']\n",
      " ['XXXX' 'XXXX' 'C2A4' 'D2B4' 'E2C4' 'F2D4' 'G2E4' 'H2F4']\n",
      " ['XXXX' 'XXXX' 'C1A3' 'D1B3' 'E1C3' 'F1D3' 'G1E3' 'H1F3']] \n",
      "\n",
      "Move Q NW3\n",
      "(-3, 3, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D5A8' 'E5B8' 'F5C8' 'G5D8' 'H5E8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D4A7' 'E4B7' 'F4C7' 'G4D7' 'H4E7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D3A6' 'E3B6' 'F3C6' 'G3D6' 'H3E6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D2A5' 'E2B5' 'F2C5' 'G2D5' 'H2E5']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'D1A4' 'E1B4' 'F1C4' 'G1D4' 'H1E4']] \n",
      "\n",
      "Move Q NW4\n",
      "(-4, 4, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E4A8' 'F4B8' 'G4C8' 'H4D8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E3A7' 'F3B7' 'G3C7' 'H3D7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E2A6' 'F2B6' 'G2C6' 'H2D6']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'E1A5' 'F1B5' 'G1C5' 'H1D5']] \n",
      "\n",
      "Move Q NW5\n",
      "(-5, 5, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F3A8' 'G3B8' 'H3C8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F2A7' 'G2B7' 'H2C7']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'F1A6' 'G1B6' 'H1C6']] \n",
      "\n",
      "Move Q NW6\n",
      "(-6, 6, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G2A8' 'H2B8']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'G1A7' 'H1B7']] \n",
      "\n",
      "Move Q NW7\n",
      "(-7, 7, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'H1A8']] \n",
      "\n",
      "Move 2N1E\n",
      "(1, 2, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A6B8' 'B6C8' 'C6D8' 'D6E8' 'E6F8' 'F6G8' 'G6H8' 'XXXX']\n",
      " ['A5B7' 'B5C7' 'C5D7' 'D5E7' 'E5F7' 'F5G7' 'G5H7' 'XXXX']\n",
      " ['A4B6' 'B4C6' 'C4D6' 'D4E6' 'E4F6' 'F4G6' 'G4H6' 'XXXX']\n",
      " ['A3B5' 'B3C5' 'C3D5' 'D3E5' 'E3F5' 'F3G5' 'G3H5' 'XXXX']\n",
      " ['A2B4' 'B2C4' 'C2D4' 'D2E4' 'E2F4' 'F2G4' 'G2H4' 'XXXX']\n",
      " ['A1B3' 'B1C3' 'C1D3' 'D1E3' 'E1F3' 'F1G3' 'G1H3' 'XXXX']] \n",
      "\n",
      "Move 1N2E\n",
      "(2, 1, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7C8' 'B7D8' 'C7E8' 'D7F8' 'E7G8' 'F7H8' 'XXXX' 'XXXX']\n",
      " ['A6C7' 'B6D7' 'C6E7' 'D6F7' 'E6G7' 'F6H7' 'XXXX' 'XXXX']\n",
      " ['A5C6' 'B5D6' 'C5E6' 'D5F6' 'E5G6' 'F5H6' 'XXXX' 'XXXX']\n",
      " ['A4C5' 'B4D5' 'C4E5' 'D4F5' 'E4G5' 'F4H5' 'XXXX' 'XXXX']\n",
      " ['A3C4' 'B3D4' 'C3E4' 'D3F4' 'E3G4' 'F3H4' 'XXXX' 'XXXX']\n",
      " ['A2C3' 'B2D3' 'C2E3' 'D2F3' 'E2G3' 'F2H3' 'XXXX' 'XXXX']\n",
      " ['A1C2' 'B1D2' 'C1E2' 'D1F2' 'E1G2' 'F1H2' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move 1S2E\n",
      "(2, -1, None)\n",
      "[['A8C7' 'B8D7' 'C8E7' 'D8F7' 'E8G7' 'F8H7' 'XXXX' 'XXXX']\n",
      " ['A7C6' 'B7D6' 'C7E6' 'D7F6' 'E7G6' 'F7H6' 'XXXX' 'XXXX']\n",
      " ['A6C5' 'B6D5' 'C6E5' 'D6F5' 'E6G5' 'F6H5' 'XXXX' 'XXXX']\n",
      " ['A5C4' 'B5D4' 'C5E4' 'D5F4' 'E5G4' 'F5H4' 'XXXX' 'XXXX']\n",
      " ['A4C3' 'B4D3' 'C4E3' 'D4F3' 'E4G3' 'F4H3' 'XXXX' 'XXXX']\n",
      " ['A3C2' 'B3D2' 'C3E2' 'D3F2' 'E3G2' 'F3H2' 'XXXX' 'XXXX']\n",
      " ['A2C1' 'B2D1' 'C2E1' 'D2F1' 'E2G1' 'F2H1' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move 2S1E\n",
      "(1, -2, None)\n",
      "[['A8B6' 'B8C6' 'C8D6' 'D8E6' 'E8F6' 'F8G6' 'G8H6' 'XXXX']\n",
      " ['A7B5' 'B7C5' 'C7D5' 'D7E5' 'E7F5' 'F7G5' 'G7H5' 'XXXX']\n",
      " ['A6B4' 'B6C4' 'C6D4' 'D6E4' 'E6F4' 'F6G4' 'G6H4' 'XXXX']\n",
      " ['A5B3' 'B5C3' 'C5D3' 'D5E3' 'E5F3' 'F5G3' 'G5H3' 'XXXX']\n",
      " ['A4B2' 'B4C2' 'C4D2' 'D4E2' 'E4F2' 'F4G2' 'G4H2' 'XXXX']\n",
      " ['A3B1' 'B3C1' 'C3D1' 'D3E1' 'E3F1' 'F3G1' 'G3H1' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move 2S1W\n",
      "(-1, -2, None)\n",
      "[['XXXX' 'B8A6' 'C8B6' 'D8C6' 'E8D6' 'F8E6' 'G8F6' 'H8G6']\n",
      " ['XXXX' 'B7A5' 'C7B5' 'D7C5' 'E7D5' 'F7E5' 'G7F5' 'H7G5']\n",
      " ['XXXX' 'B6A4' 'C6B4' 'D6C4' 'E6D4' 'F6E4' 'G6F4' 'H6G4']\n",
      " ['XXXX' 'B5A3' 'C5B3' 'D5C3' 'E5D3' 'F5E3' 'G5F3' 'H5G3']\n",
      " ['XXXX' 'B4A2' 'C4B2' 'D4C2' 'E4D2' 'F4E2' 'G4F2' 'H4G2']\n",
      " ['XXXX' 'B3A1' 'C3B1' 'D3C1' 'E3D1' 'F3E1' 'G3F1' 'H3G1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move 1S2W\n",
      "(-2, -1, None)\n",
      "[['XXXX' 'XXXX' 'C8A7' 'D8B7' 'E8C7' 'F8D7' 'G8E7' 'H8F7']\n",
      " ['XXXX' 'XXXX' 'C7A6' 'D7B6' 'E7C6' 'F7D6' 'G7E6' 'H7F6']\n",
      " ['XXXX' 'XXXX' 'C6A5' 'D6B5' 'E6C5' 'F6D5' 'G6E5' 'H6F5']\n",
      " ['XXXX' 'XXXX' 'C5A4' 'D5B4' 'E5C4' 'F5D4' 'G5E4' 'H5F4']\n",
      " ['XXXX' 'XXXX' 'C4A3' 'D4B3' 'E4C3' 'F4D3' 'G4E3' 'H4F3']\n",
      " ['XXXX' 'XXXX' 'C3A2' 'D3B2' 'E3C2' 'F3D2' 'G3E2' 'H3F2']\n",
      " ['XXXX' 'XXXX' 'C2A1' 'D2B1' 'E2C1' 'F2D1' 'G2E1' 'H2F1']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']] \n",
      "\n",
      "Move 1N2W\n",
      "(-2, 1, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'C7A8' 'D7B8' 'E7C8' 'F7D8' 'G7E8' 'H7F8']\n",
      " ['XXXX' 'XXXX' 'C6A7' 'D6B7' 'E6C7' 'F6D7' 'G6E7' 'H6F7']\n",
      " ['XXXX' 'XXXX' 'C5A6' 'D5B6' 'E5C6' 'F5D6' 'G5E6' 'H5F6']\n",
      " ['XXXX' 'XXXX' 'C4A5' 'D4B5' 'E4C5' 'F4D5' 'G4E5' 'H4F5']\n",
      " ['XXXX' 'XXXX' 'C3A4' 'D3B4' 'E3C4' 'F3D4' 'G3E4' 'H3F4']\n",
      " ['XXXX' 'XXXX' 'C2A3' 'D2B3' 'E2C3' 'F2D3' 'G2E3' 'H2F3']\n",
      " ['XXXX' 'XXXX' 'C1A2' 'D1B2' 'E1C2' 'F1D2' 'G1E2' 'H1F2']] \n",
      "\n",
      "Move 2N1W\n",
      "(-1, 2, None)\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'B6A8' 'C6B8' 'D6C8' 'E6D8' 'F6E8' 'G6F8' 'H6G8']\n",
      " ['XXXX' 'B5A7' 'C5B7' 'D5C7' 'E5D7' 'F5E7' 'G5F7' 'H5G7']\n",
      " ['XXXX' 'B4A6' 'C4B6' 'D4C6' 'E4D6' 'F4E6' 'G4F6' 'H4G6']\n",
      " ['XXXX' 'B3A5' 'C3B5' 'D3C5' 'E3D5' 'F3E5' 'G3F5' 'H3G5']\n",
      " ['XXXX' 'B2A4' 'C2B4' 'D2C4' 'E2D4' 'F2E4' 'G2F4' 'H2G4']\n",
      " ['XXXX' 'B1A3' 'C1B3' 'D1C3' 'E1D3' 'F1E3' 'G1F3' 'H1G3']] \n",
      "\n",
      "Move PQ N1\n",
      "(0, 1, 'q')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7A8q' 'B7B8q' 'C7C8q' 'D7D8q' 'E7E8q' 'F7F8q' 'G7G8q' 'H7H8q']\n",
      " ['A6A7q' 'B6B7q' 'C6C7q' 'D6D7q' 'E6E7q' 'F6F7q' 'G6G7q' 'H6H7q']\n",
      " ['A5A6q' 'B5B6q' 'C5C6q' 'D5D6q' 'E5E6q' 'F5F6q' 'G5G6q' 'H5H6q']\n",
      " ['A4A5q' 'B4B5q' 'C4C5q' 'D4D5q' 'E4E5q' 'F4F5q' 'G4G5q' 'H4H5q']\n",
      " ['A3A4q' 'B3B4q' 'C3C4q' 'D3D4q' 'E3E4q' 'F3F4q' 'G3G4q' 'H3H4q']\n",
      " ['A2A3q' 'B2B3q' 'C2C3q' 'D2D3q' 'E2E3q' 'F2F3q' 'G2G3q' 'H2H3q']\n",
      " ['A1A2q' 'B1B2q' 'C1C2q' 'D1D2q' 'E1E2q' 'F1F2q' 'G1G2q' 'H1H2q']] \n",
      "\n",
      "Move PR N1\n",
      "(0, 1, 'r')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7A8r' 'B7B8r' 'C7C8r' 'D7D8r' 'E7E8r' 'F7F8r' 'G7G8r' 'H7H8r']\n",
      " ['A6A7r' 'B6B7r' 'C6C7r' 'D6D7r' 'E6E7r' 'F6F7r' 'G6G7r' 'H6H7r']\n",
      " ['A5A6r' 'B5B6r' 'C5C6r' 'D5D6r' 'E5E6r' 'F5F6r' 'G5G6r' 'H5H6r']\n",
      " ['A4A5r' 'B4B5r' 'C4C5r' 'D4D5r' 'E4E5r' 'F4F5r' 'G4G5r' 'H4H5r']\n",
      " ['A3A4r' 'B3B4r' 'C3C4r' 'D3D4r' 'E3E4r' 'F3F4r' 'G3G4r' 'H3H4r']\n",
      " ['A2A3r' 'B2B3r' 'C2C3r' 'D2D3r' 'E2E3r' 'F2F3r' 'G2G3r' 'H2H3r']\n",
      " ['A1A2r' 'B1B2r' 'C1C2r' 'D1D2r' 'E1E2r' 'F1F2r' 'G1G2r' 'H1H2r']] \n",
      "\n",
      "Move PB N1\n",
      "(0, 1, 'b')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7A8b' 'B7B8b' 'C7C8b' 'D7D8b' 'E7E8b' 'F7F8b' 'G7G8b' 'H7H8b']\n",
      " ['A6A7b' 'B6B7b' 'C6C7b' 'D6D7b' 'E6E7b' 'F6F7b' 'G6G7b' 'H6H7b']\n",
      " ['A5A6b' 'B5B6b' 'C5C6b' 'D5D6b' 'E5E6b' 'F5F6b' 'G5G6b' 'H5H6b']\n",
      " ['A4A5b' 'B4B5b' 'C4C5b' 'D4D5b' 'E4E5b' 'F4F5b' 'G4G5b' 'H4H5b']\n",
      " ['A3A4b' 'B3B4b' 'C3C4b' 'D3D4b' 'E3E4b' 'F3F4b' 'G3G4b' 'H3H4b']\n",
      " ['A2A3b' 'B2B3b' 'C2C3b' 'D2D3b' 'E2E3b' 'F2F3b' 'G2G3b' 'H2H3b']\n",
      " ['A1A2b' 'B1B2b' 'C1C2b' 'D1D2b' 'E1E2b' 'F1F2b' 'G1G2b' 'H1H2b']] \n",
      "\n",
      "Move PN N1\n",
      "(0, 1, 'n')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7A8n' 'B7B8n' 'C7C8n' 'D7D8n' 'E7E8n' 'F7F8n' 'G7G8n' 'H7H8n']\n",
      " ['A6A7n' 'B6B7n' 'C6C7n' 'D6D7n' 'E6E7n' 'F6F7n' 'G6G7n' 'H6H7n']\n",
      " ['A5A6n' 'B5B6n' 'C5C6n' 'D5D6n' 'E5E6n' 'F5F6n' 'G5G6n' 'H5H6n']\n",
      " ['A4A5n' 'B4B5n' 'C4C5n' 'D4D5n' 'E4E5n' 'F4F5n' 'G4G5n' 'H4H5n']\n",
      " ['A3A4n' 'B3B4n' 'C3C4n' 'D3D4n' 'E3E4n' 'F3F4n' 'G3G4n' 'H3H4n']\n",
      " ['A2A3n' 'B2B3n' 'C2C3n' 'D2D3n' 'E2E3n' 'F2F3n' 'G2G3n' 'H2H3n']\n",
      " ['A1A2n' 'B1B2n' 'C1C2n' 'D1D2n' 'E1E2n' 'F1F2n' 'G1G2n' 'H1H2n']] \n",
      "\n",
      "Move PQ NE1\n",
      "(1, 1, 'q')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7B8q' 'B7C8q' 'C7D8q' 'D7E8q' 'E7F8q' 'F7G8q' 'G7H8q' 'XXXX']\n",
      " ['A6B7q' 'B6C7q' 'C6D7q' 'D6E7q' 'E6F7q' 'F6G7q' 'G6H7q' 'XXXX']\n",
      " ['A5B6q' 'B5C6q' 'C5D6q' 'D5E6q' 'E5F6q' 'F5G6q' 'G5H6q' 'XXXX']\n",
      " ['A4B5q' 'B4C5q' 'C4D5q' 'D4E5q' 'E4F5q' 'F4G5q' 'G4H5q' 'XXXX']\n",
      " ['A3B4q' 'B3C4q' 'C3D4q' 'D3E4q' 'E3F4q' 'F3G4q' 'G3H4q' 'XXXX']\n",
      " ['A2B3q' 'B2C3q' 'C2D3q' 'D2E3q' 'E2F3q' 'F2G3q' 'G2H3q' 'XXXX']\n",
      " ['A1B2q' 'B1C2q' 'C1D2q' 'D1E2q' 'E1F2q' 'F1G2q' 'G1H2q' 'XXXX']] \n",
      "\n",
      "Move PR NE1\n",
      "(1, 1, 'r')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7B8r' 'B7C8r' 'C7D8r' 'D7E8r' 'E7F8r' 'F7G8r' 'G7H8r' 'XXXX']\n",
      " ['A6B7r' 'B6C7r' 'C6D7r' 'D6E7r' 'E6F7r' 'F6G7r' 'G6H7r' 'XXXX']\n",
      " ['A5B6r' 'B5C6r' 'C5D6r' 'D5E6r' 'E5F6r' 'F5G6r' 'G5H6r' 'XXXX']\n",
      " ['A4B5r' 'B4C5r' 'C4D5r' 'D4E5r' 'E4F5r' 'F4G5r' 'G4H5r' 'XXXX']\n",
      " ['A3B4r' 'B3C4r' 'C3D4r' 'D3E4r' 'E3F4r' 'F3G4r' 'G3H4r' 'XXXX']\n",
      " ['A2B3r' 'B2C3r' 'C2D3r' 'D2E3r' 'E2F3r' 'F2G3r' 'G2H3r' 'XXXX']\n",
      " ['A1B2r' 'B1C2r' 'C1D2r' 'D1E2r' 'E1F2r' 'F1G2r' 'G1H2r' 'XXXX']] \n",
      "\n",
      "Move PB NE1\n",
      "(1, 1, 'b')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7B8b' 'B7C8b' 'C7D8b' 'D7E8b' 'E7F8b' 'F7G8b' 'G7H8b' 'XXXX']\n",
      " ['A6B7b' 'B6C7b' 'C6D7b' 'D6E7b' 'E6F7b' 'F6G7b' 'G6H7b' 'XXXX']\n",
      " ['A5B6b' 'B5C6b' 'C5D6b' 'D5E6b' 'E5F6b' 'F5G6b' 'G5H6b' 'XXXX']\n",
      " ['A4B5b' 'B4C5b' 'C4D5b' 'D4E5b' 'E4F5b' 'F4G5b' 'G4H5b' 'XXXX']\n",
      " ['A3B4b' 'B3C4b' 'C3D4b' 'D3E4b' 'E3F4b' 'F3G4b' 'G3H4b' 'XXXX']\n",
      " ['A2B3b' 'B2C3b' 'C2D3b' 'D2E3b' 'E2F3b' 'F2G3b' 'G2H3b' 'XXXX']\n",
      " ['A1B2b' 'B1C2b' 'C1D2b' 'D1E2b' 'E1F2b' 'F1G2b' 'G1H2b' 'XXXX']] \n",
      "\n",
      "Move PN NE1\n",
      "(1, 1, 'n')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['A7B8n' 'B7C8n' 'C7D8n' 'D7E8n' 'E7F8n' 'F7G8n' 'G7H8n' 'XXXX']\n",
      " ['A6B7n' 'B6C7n' 'C6D7n' 'D6E7n' 'E6F7n' 'F6G7n' 'G6H7n' 'XXXX']\n",
      " ['A5B6n' 'B5C6n' 'C5D6n' 'D5E6n' 'E5F6n' 'F5G6n' 'G5H6n' 'XXXX']\n",
      " ['A4B5n' 'B4C5n' 'C4D5n' 'D4E5n' 'E4F5n' 'F4G5n' 'G4H5n' 'XXXX']\n",
      " ['A3B4n' 'B3C4n' 'C3D4n' 'D3E4n' 'E3F4n' 'F3G4n' 'G3H4n' 'XXXX']\n",
      " ['A2B3n' 'B2C3n' 'C2D3n' 'D2E3n' 'E2F3n' 'F2G3n' 'G2H3n' 'XXXX']\n",
      " ['A1B2n' 'B1C2n' 'C1D2n' 'D1E2n' 'E1F2n' 'F1G2n' 'G1H2n' 'XXXX']] \n",
      "\n",
      "Move PQ NW1\n",
      "(-1, 1, 'q')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'B7A8q' 'C7B8q' 'D7C8q' 'E7D8q' 'F7E8q' 'G7F8q' 'H7G8q']\n",
      " ['XXXX' 'B6A7q' 'C6B7q' 'D6C7q' 'E6D7q' 'F6E7q' 'G6F7q' 'H6G7q']\n",
      " ['XXXX' 'B5A6q' 'C5B6q' 'D5C6q' 'E5D6q' 'F5E6q' 'G5F6q' 'H5G6q']\n",
      " ['XXXX' 'B4A5q' 'C4B5q' 'D4C5q' 'E4D5q' 'F4E5q' 'G4F5q' 'H4G5q']\n",
      " ['XXXX' 'B3A4q' 'C3B4q' 'D3C4q' 'E3D4q' 'F3E4q' 'G3F4q' 'H3G4q']\n",
      " ['XXXX' 'B2A3q' 'C2B3q' 'D2C3q' 'E2D3q' 'F2E3q' 'G2F3q' 'H2G3q']\n",
      " ['XXXX' 'B1A2q' 'C1B2q' 'D1C2q' 'E1D2q' 'F1E2q' 'G1F2q' 'H1G2q']] \n",
      "\n",
      "Move PR NW1\n",
      "(-1, 1, 'r')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'B7A8r' 'C7B8r' 'D7C8r' 'E7D8r' 'F7E8r' 'G7F8r' 'H7G8r']\n",
      " ['XXXX' 'B6A7r' 'C6B7r' 'D6C7r' 'E6D7r' 'F6E7r' 'G6F7r' 'H6G7r']\n",
      " ['XXXX' 'B5A6r' 'C5B6r' 'D5C6r' 'E5D6r' 'F5E6r' 'G5F6r' 'H5G6r']\n",
      " ['XXXX' 'B4A5r' 'C4B5r' 'D4C5r' 'E4D5r' 'F4E5r' 'G4F5r' 'H4G5r']\n",
      " ['XXXX' 'B3A4r' 'C3B4r' 'D3C4r' 'E3D4r' 'F3E4r' 'G3F4r' 'H3G4r']\n",
      " ['XXXX' 'B2A3r' 'C2B3r' 'D2C3r' 'E2D3r' 'F2E3r' 'G2F3r' 'H2G3r']\n",
      " ['XXXX' 'B1A2r' 'C1B2r' 'D1C2r' 'E1D2r' 'F1E2r' 'G1F2r' 'H1G2r']] \n",
      "\n",
      "Move PB NW1\n",
      "(-1, 1, 'b')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'B7A8b' 'C7B8b' 'D7C8b' 'E7D8b' 'F7E8b' 'G7F8b' 'H7G8b']\n",
      " ['XXXX' 'B6A7b' 'C6B7b' 'D6C7b' 'E6D7b' 'F6E7b' 'G6F7b' 'H6G7b']\n",
      " ['XXXX' 'B5A6b' 'C5B6b' 'D5C6b' 'E5D6b' 'F5E6b' 'G5F6b' 'H5G6b']\n",
      " ['XXXX' 'B4A5b' 'C4B5b' 'D4C5b' 'E4D5b' 'F4E5b' 'G4F5b' 'H4G5b']\n",
      " ['XXXX' 'B3A4b' 'C3B4b' 'D3C4b' 'E3D4b' 'F3E4b' 'G3F4b' 'H3G4b']\n",
      " ['XXXX' 'B2A3b' 'C2B3b' 'D2C3b' 'E2D3b' 'F2E3b' 'G2F3b' 'H2G3b']\n",
      " ['XXXX' 'B1A2b' 'C1B2b' 'D1C2b' 'E1D2b' 'F1E2b' 'G1F2b' 'H1G2b']] \n",
      "\n",
      "Move PN NW1\n",
      "(-1, 1, 'n')\n",
      "[['XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX' 'XXXX']\n",
      " ['XXXX' 'B7A8n' 'C7B8n' 'D7C8n' 'E7D8n' 'F7E8n' 'G7F8n' 'H7G8n']\n",
      " ['XXXX' 'B6A7n' 'C6B7n' 'D6C7n' 'E6D7n' 'F6E7n' 'G6F7n' 'H6G7n']\n",
      " ['XXXX' 'B5A6n' 'C5B6n' 'D5C6n' 'E5D6n' 'F5E6n' 'G5F6n' 'H5G6n']\n",
      " ['XXXX' 'B4A5n' 'C4B5n' 'D4C5n' 'E4D5n' 'F4E5n' 'G4F5n' 'H4G5n']\n",
      " ['XXXX' 'B3A4n' 'C3B4n' 'D3C4n' 'E3D4n' 'F3E4n' 'G3F4n' 'H3G4n']\n",
      " ['XXXX' 'B2A3n' 'C2B3n' 'D2C3n' 'E2D3n' 'F2E3n' 'G2F3n' 'H2G3n']\n",
      " ['XXXX' 'B1A2n' 'C1B2n' 'D1C2n' 'E1D2n' 'F1E2n' 'G1F2n' 'H1G2n']] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76, 8, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move_board(move):\n",
    "    \"\"\"Moves the board positions as per the move\"\"\"\n",
    "    print(move)\n",
    "    board = np.array([\n",
    "        ['A8', 'B8', 'C8', 'D8', 'E8', 'F8', 'G8', 'H8'],\n",
    "        ['A7', 'B7', 'C7', 'D7', 'E7', 'F7', 'G7', 'H7'],\n",
    "        ['A6', 'B6', 'C6', 'D6', 'E6', 'F6', 'G6', 'H6'],\n",
    "        ['A5', 'B5', 'C5', 'D5', 'E5', 'F5', 'G5', 'H5'],\n",
    "        ['A4', 'B4', 'C4', 'D4', 'E4', 'F4', 'G4', 'H4'],\n",
    "        ['A3', 'B3', 'C3', 'D3', 'E3', 'F3', 'G3', 'H3'],\n",
    "        ['A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2'],\n",
    "        ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G1', 'H1']\n",
    "    ])\n",
    "\n",
    "    char_to_int = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8} \n",
    "\n",
    "    int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "\n",
    "    encoded_board = [(char_to_int[pos[0]], int(pos[1])) for pos in np.ndarray.flatten(board)]\n",
    "\n",
    "    new_board = [tuple(map(sum, zip((char_to_int[pos[0]], int(pos[1])), move))) for pos in np.ndarray.flatten(board)]\n",
    " \n",
    "    moves = []\n",
    "    for pos, new_pos in zip(np.ndarray.flatten(board), new_board):\n",
    "        try:\n",
    "#             print(pos, new_pos)\n",
    "            if new_pos[1] > 8:\n",
    "                raise Exception()\n",
    "            \n",
    "            if move[2] is None:\n",
    "                move_ = f'{pos}{int_to_char[new_pos[0]]}{new_pos[1]}'\n",
    "            else:\n",
    "                move_ = f'{pos}{int_to_char[new_pos[0]]}{new_pos[1]}{move[2]}'\n",
    "            \n",
    "            if '-' in move_:\n",
    "                raise Exception()\n",
    "            \n",
    "            if '0' in move_:\n",
    "                raise Exception()\n",
    "                \n",
    "        except Exception:\n",
    "            move_ = 'XXXX'\n",
    "        moves.append(move_)\n",
    "    return np.array(moves).reshape(8, 8)\n",
    "\n",
    "moves = {\n",
    "    # Queen Moves\n",
    "    'Q N1': (0, 1, None),\n",
    "    'Q N2': (0, 2, None),\n",
    "    'Q N3': (0, 3, None),\n",
    "    'Q N4': (0, 4, None),\n",
    "    'Q N5': (0, 5, None),\n",
    "    'Q N6': (0, 6, None),\n",
    "    'Q N7': (0, 7, None),\n",
    "    'Q NE1': (1, 1, None),\n",
    "    'Q NE2': (2, 2, None),\n",
    "    'Q NE3': (3, 3, None),\n",
    "    'Q NE4': (4, 4, None),\n",
    "    'Q NE5': (5, 5, None),\n",
    "    'Q NE6': (6, 6, None),\n",
    "    'Q NE7': (7, 7, None),\n",
    "    'Q E1': (1, 0, None),\n",
    "    'Q E2': (2, 0, None),\n",
    "    'Q E3': (3, 0, None),\n",
    "    'Q E4': (4, 0, None),\n",
    "    'Q E5': (5, 0, None),\n",
    "    'Q E6': (6, 0, None),\n",
    "    'Q E7': (7, 0, None),\n",
    "    'Q SE1': (1, -1, None),\n",
    "    'Q SE2': (2, -2, None),\n",
    "    'Q SE3': (3, -3, None),\n",
    "    'Q SE4': (4, -4, None),\n",
    "    'Q SE5': (5, -5, None),\n",
    "    'Q SE6': (6, -6, None),\n",
    "    'Q SE7': (7, -7, None),\n",
    "    'Q S1': (0, -1, None),\n",
    "    'Q S2': (0, -2, None),\n",
    "    'Q S3': (0, -3, None),\n",
    "    'Q S4': (0, -4, None),\n",
    "    'Q S5': (0, -5, None),\n",
    "    'Q S6': (0, -6, None),\n",
    "    'Q S7': (0, -7, None),\n",
    "    'Q SW1': (-1, -1, None),\n",
    "    'Q SW2': (-2, -2, None),\n",
    "    'Q SW3': (-3, -3, None),\n",
    "    'Q SW4': (-4, -4, None),\n",
    "    'Q SW5': (-5, -5, None),\n",
    "    'Q SW6': (-6, -6, None),\n",
    "    'Q SW7': (-7, -7, None),\n",
    "    'Q W1': (-1, 0, None),\n",
    "    'Q W2': (-2, 0, None),\n",
    "    'Q W3': (-3, 0, None),\n",
    "    'Q W4': (-4, 0, None),\n",
    "    'Q W5': (-5, 0, None),\n",
    "    'Q W6': (-6, 0, None),\n",
    "    'Q W7': (-7, 0, None),\n",
    "    'Q NW1': (-1, 1, None),\n",
    "    'Q NW2': (-2, 2, None),\n",
    "    'Q NW3': (-3, 3, None),\n",
    "    'Q NW4': (-4, 4, None),\n",
    "    'Q NW5': (-5, 5, None),\n",
    "    'Q NW6': (-6, 6, None),\n",
    "    'Q NW7': (-7, 7, None),\n",
    "    # Knight Moves\n",
    "    '2N1E' : (1, 2, None),\n",
    "    '1N2E' : (2, 1, None),\n",
    "    '1S2E' : (2, -1, None),\n",
    "    '2S1E' : (1, -2, None),\n",
    "    '2S1W' : (-1, -2, None),\n",
    "    '1S2W' : (-2, -1, None),\n",
    "    '1N2W' : (-2, 1, None),\n",
    "    '2N1W' : (-1, 2, None),\n",
    "    # Promtions\n",
    "    'PQ N1' : (0, 1, 'q'),\n",
    "    'PR N1' : (0, 1, 'r'),\n",
    "    'PB N1' : (0, 1, 'b'),\n",
    "    'PN N1' : (0, 1, 'n'),\n",
    "    'PQ NE1' : (1, 1, 'q'),\n",
    "    'PR NE1' : (1, 1, 'r'),\n",
    "    'PB NE1' : (1, 1, 'b'),\n",
    "    'PN NE1' : (1, 1, 'n'),\n",
    "    'PQ NW1' : (-1, 1, 'q'),\n",
    "    'PR NW1' : (-1, 1, 'r'),\n",
    "    'PB NW1' : (-1, 1, 'b'),\n",
    "    'PN NW1' : (-1, 1, 'n')\n",
    "}\n",
    "\n",
    "new_boards = []\n",
    "for key in moves.keys():\n",
    "    print(f'Move {key}')\n",
    "    new_board = move_board(moves[key])\n",
    "    new_boards.append(new_board)\n",
    "    print(new_board, '\\n')\n",
    "    \n",
    "new_boards = np.array(new_boards)\n",
    "new_boards.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'g1h3': 0.45660709642285646,\n",
       " 'g1f3': 0.7296318376203058,\n",
       " 'b1c3': 0.7758069164651817,\n",
       " 'b1a3': 0.3460048253284187,\n",
       " 'h2h3': 0.7625516770376449,\n",
       " 'g2g3': 0.6475318583153137,\n",
       " 'f2f3': 0.6017392169043637,\n",
       " 'e2e3': 0.6573678123104609,\n",
       " 'd2d3': 0.6416105329701982,\n",
       " 'c2c3': 0.6415560319775794,\n",
       " 'b2b3': 0.23229497495589524,\n",
       " 'a2a3': 0.9515273985409961,\n",
       " 'h2h4': 0.6002194662944027,\n",
       " 'g2g4': 0.897092357683361,\n",
       " 'f2f4': 0.9241730737122926,\n",
       " 'e2e4': 0.989401016818168,\n",
       " 'd2d4': 0.31747830585667214,\n",
       " 'c2c4': 0.8426043755222995,\n",
       " 'b2b4': 0.7034293954573848,\n",
       " 'a2a4': 0.8315008287341005}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits = env.action\n",
    "logits = np.random.rand(len(moves), 8, 8)\n",
    "\n",
    "print(env.action_size)\n",
    "new_boards_ = np.ndarray.flatten(new_boards)\n",
    "logits_ = np.ndarray.flatten(logits)\n",
    "\n",
    "move_logits = [(new_boards_[idx].lower(), logits_[idx]) for idx in range(len(logits_))]\n",
    "move_logits = dict(move_logits)\n",
    "\n",
    "legal_actions = ['g1h3','g1f3','b1c3','b1a3','h2h3','g2g3','f2f3','e2e3','d2d3','c2c3','b2b3','a2a3','h2h4','g2g4','f2f4','e2e4','d2d4','c2c4','b2b4','a2a4']\n",
    "\n",
    "legal_move_logits = {legal_action: move_logits[legal_action] for legal_action in legal_actions}\n",
    "legal_move_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Logits FOR CONTROLLER TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGAL_MULTIPIER = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "legal_move_logits_ = [legal_move_logits for _ in range(BATCH_SIZE)] \n",
    "logits = np.random.rand(BATCH_SIZE, len(moves), 8, 8)\n",
    "logits_ = np.swapaxes(logits.reshape(-1, BATCH_SIZE), 0, 1)\n",
    "new_boards__ = [[x.lower() for x in list(new_boards_)] for _ in range(BATCH_SIZE)]\n",
    "target_policies = []\n",
    "for idx in range(BATCH_SIZE):\n",
    "    new_boards___ = new_boards__[idx]\n",
    "    logits__ = logits_[idx]\n",
    "    legal_move_logits__ = {k.lower(): v * LEGAL_MULTIPIER for k, v in legal_move_logits_[idx].items()}\n",
    "    for move, legal_move_logit in legal_move_logits__.items():\n",
    "        index = new_boards___.index(move)\n",
    "        logits__[index] += legal_move_logit\n",
    "    target_policies.append(logits__)\n",
    "target_policies = np.array(target_policies).reshape(BATCH_SIZE, len(moves), 8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Data for VAE and figure out action size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_vae_training_data(games):\n",
    "#     \"\"\"Creates training date for CNN-VAE\"\"\"\n",
    "#     actions = {}\n",
    "#     states = {}\n",
    "#     for game in range(1, games + 1):\n",
    "#         env.reset()\n",
    "#         state, legal_actions = env.observe()\n",
    "#         encoded_state = env.encode()\n",
    "#         states[encoded_state] = state\n",
    "#         while not env.terminal_test():\n",
    "#             action = random.choice(legal_actions)            \n",
    "#             state, legal_actions = env.step(action)\n",
    "#             encoded_state = env.encode()\n",
    "#             states[encoded_state] = state\n",
    "# #             actions[encoded_state] = agent.one_hot_encode_action(action)\n",
    "#         print(f'Game {game} | Unique States {len(states.keys())} Unique Actions {len(actions)}', end = '\\r')\n",
    "    \n",
    "#     validate_path('data/vae')\n",
    "#     with open('data/vae/states.pkl', 'wb') as file:\n",
    "#         pickle.dump(states, file)\n",
    "#     with open('data/vae/actions.pkl', 'wb') as file:\n",
    "#         pickle.dump(actions, file)\n",
    "    \n",
    "# create_vae_training_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_vae_(name, starting_channels, filename, z_size, epochs, batch_size):\n",
    "#     \"\"\"Trains the CNN-VAE\"\"\"\n",
    "#     params = {\n",
    "#         'z_size' : z_size,\n",
    "#         'batch_size' : batch_size,\n",
    "#         'learning_rate' : 1e-4,\n",
    "#         'kl_tolerance' : 0.5,\n",
    "#         'batch_norm' : False,\n",
    "#         'starting_channels' : starting_channels\n",
    "#     }\n",
    "\n",
    "#     vae = CNN_VAE(name, params, False)\n",
    "#     with open(f'data/vae/{filename}',  'rb') as pickle_file:\n",
    "#         data = list(pickle.load(pickle_file).values())\n",
    "#         data = [np.array(data_) for data_ in data]\n",
    "    \n",
    "#     train_vae(vae, data, epochs, 100)\n",
    "\n",
    "    \n",
    "# train_vae_('Test States', env.state_size[0], 'states.pkl', 600, 100, 200)\n",
    "# # train_vae_('Test Actions', env.action_size[0], 'actions.pkl', 600, 100, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Data for MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mdn_training_data(name, games):\n",
    "#     \"\"\"Create training data for MDN-RNN\"\"\"\n",
    "#     vae = CNN_VAE(name, None, 'Latest')\n",
    "#     vae.eval()\n",
    "#     data = pd.DataFrame(columns = ['Game ID', 'Sequence #', 'State ID'])\n",
    "#     rollouts = []\n",
    "#     transitions = 0\n",
    "    \n",
    "#     for game in range(1, games + 1):\n",
    "#         states = []\n",
    "#         actions = []\n",
    "#         env.reset()\n",
    "        \n",
    "#         state, legal_actions = env.observe()\n",
    "#         while not env.terminal_test():\n",
    "#             action = random.choice(legal_actions)\n",
    "#             states.append(state)\n",
    "#             actions.append(agent.one_hot_encode_action(action))\n",
    "#             state, legal_actions = env.step(action)\n",
    "#             transitions += 1\n",
    "            \n",
    "#         mus, logvars = vae.encode(torch.tensor(states).float())\n",
    "#         zs = vae.reparameterize(mus, logvars)\n",
    "#         mus, logvars, zs = mus.squeeze(-1), logvars.squeeze(-1), zs.squeeze(-1)\n",
    "#         actions = torch.tensor(actions).float().squeeze(-1)\n",
    "#         zas = torch.cat([zs, actions], dim = 1)\n",
    "#         rollouts.append((zs.detach().numpy(), actions.detach().numpy()))\n",
    "        \n",
    "#         print(f'Game {game} Transitions {transitions}', end = '\\r')\n",
    "    \n",
    "#     validate_path('data/mdn')\n",
    "#     with open('data/mdn/rollouts.pkl', 'wb') as file:\n",
    "#         pickle.dump(rollouts, file)\n",
    "    \n",
    "    \n",
    "# create_mdn_training_data('Test', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training_mdn(vae_name, name):\n",
    "#     torch.cuda.empty_cache() \n",
    "#     \"\"\"Trains the MDN-RNN\"\"\"\n",
    "#     epochs = 499\n",
    "#     batch_size = 5\n",
    "    \n",
    "#     params = {\n",
    "#         'hidden_size' : 100,\n",
    "#         'gaussian_size' : 20,\n",
    "#         'stacked_layers': 1,\n",
    "#         'grad_clip' : 0.5,\n",
    "#         'learning_rate' : 1e-4\n",
    "#     }\n",
    "    \n",
    "#     with open(f'data/mdn/rollouts.pkl', 'rb') as pickle_file:\n",
    "#         rollouts = pickle.load(pickle_file)\n",
    "    \n",
    "#     params['z_size'] = rollouts[0][0].shape[1]\n",
    "#     params['action_size'] = rollouts[0][1].shape[1]\n",
    "#     params['batch_size'] = batch_size\n",
    "    \n",
    "#     mdn = MDN_RNN(name, params, False)\n",
    "    \n",
    "#     mdn.train()\n",
    "#     mdn = mdn.to(mdn.device)\n",
    "#     optimizer = optim.Adam(mdn.parameters(), lr = mdn.learning_rate)\n",
    "        \n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "#     seq_lengths = []\n",
    "    \n",
    "#     for rollout in rollouts:\n",
    "#         zs, actions = rollout\n",
    "#         zas = np.concatenate((zs, actions), axis = 1)\n",
    "#         seq_lengths.append(zas.shape[0])\n",
    "#         inputs.append(zas)\n",
    "#         targets.append(zs)\n",
    "        \n",
    "#     idxs = range(len(rollouts))\n",
    "    \n",
    "#     # Sorts order from longest to shortest sequence\n",
    "#     idxs = [x for _, x in sorted(zip(seq_lengths, idxs), reverse = True)]\n",
    "#     seq_lengths = [seq_lengths[x] for x in idxs]\n",
    "#     inputs = [np.array(inputs[x]) for x in idxs]\n",
    "#     targets = [np.array(targets[x]) for x in idxs]\n",
    "    \n",
    "#     max_seq_len = max(seq_lengths)\n",
    "#     rollout_size = len(seq_lengths)\n",
    "    \n",
    "#     padded_X = np.zeros((rollout_size, max_seq_len, inputs[0].shape[-1]))\n",
    "#     padded_Y = np.zeros((rollout_size, max_seq_len, targets[0].shape[-1]))\n",
    "# #     https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "    \n",
    "#     for i, x_len in enumerate(seq_lengths):\n",
    "#         padded_X[i, 0 : x_len] = inputs[i]\n",
    "#         padded_Y[i, 0 : x_len] = targets[i]\n",
    "        \n",
    "#     inputs = torch.tensor(padded_X).float().squeeze(1).to(mdn.device)\n",
    "#     targets = torch.tensor(padded_Y).float().squeeze(1).to(mdn.device)\n",
    "    \n",
    "#     if inputs.shape[0] % batch_size != 0:\n",
    "#         inputs = inputs[inputs.shape[0] // batch_size, :, :]\n",
    "        \n",
    "#     inputs = inputs.reshape(-1, batch_size, max_seq_len, mdn.z_size + mdn.action_size)\n",
    "#     targets = targets.reshape(-1, batch_size, max_seq_len, mdn.z_size)\n",
    "#     seq_lengths = list(torch.tensor(seq_lengths).reshape(-1, batch_size).numpy())\n",
    "    \n",
    "#     for epoch in range(epochs + 1):\n",
    "#         for batch in range(inputs.shape[0]):\n",
    "#             inputs_ = inputs[batch]\n",
    "#             targets_ = targets[batch]\n",
    "#             seq_lengths_ = list(seq_lengths[batch])\n",
    "            \n",
    "#             targets_ = torch.nn.utils.rnn.pack_padded_sequence(targets_, seq_lengths_, batch_first = True)\n",
    "#             targets_, _ = torch.nn.utils.rnn.pad_packed_sequence(targets_, batch_first = True)\n",
    "            \n",
    "#             # Set initial hidden and cell states\n",
    "#             hidden = mdn.init_hidden(batch_size)\n",
    "\n",
    "#             # Forward pass\n",
    "#             hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "#             (pi, mu, sigma), hidden = mdn(inputs_, hidden, seq_lengths_)\n",
    "#             loss = loss_function(targets_, pi, mu, sigma)\n",
    "\n",
    "#             # Backward and optimize\n",
    "#             mdn.zero_grad()\n",
    "#             loss.backward()\n",
    "#             clip_grad_norm_(mdn.parameters(), mdn.grad_clip)\n",
    "#             optimizer.step()\n",
    "#         print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch, epochs, loss.item()))\n",
    "            \n",
    "#     mdn.save_model()\n",
    "# training_mdn('Test', 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPHA GO TIPS \n",
    "\n",
    "\n",
    "## MCTS\n",
    "Each simulation proceeds by\n",
    "selecting in each state s a move a with low visit count, high move probability and high value\n",
    "(averaged over the leaf states of simulations that selected a from s) according to the current\n",
    "neural network f. The search returns a vector  representing a probability distribution over\n",
    "moves, either proportionally or greedily with respect to the visit counts at the root state.\n",
    "The parameters  of the deep neural network in AlphaZero are trained by self-play reinforcement learning, starting from randomly initialised parameters . Games are played by selecting\n",
    "moves for both players by MCTS, at  t\n",
    ". At the end of the game, the terminal position sT is\n",
    "scored according to the rules of the game to compute the game outcome z: 1 for a loss, 0 for\n",
    "a draw, and +1 for a win. The neural network parameters  are updated so as to minimise the\n",
    "error between the predicted outcome vt and the game outcome z, and to maximise the similarity\n",
    "of the policy vector pt\n",
    "to the search probabilities t\n",
    ". Specifically, the parameters  are adjusted\n",
    "by gradient descent on a loss function l that sums over mean-squared error and cross-entropy\n",
    "losses respectively\n",
    "\n",
    "(p, v) = f(s)                    \n",
    "\n",
    "l = (z  v) 2   > log p + c||||2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    \"\"\"Monte Carlo Tree Search Algorithm geared for Neural Networks\"\"\"\n",
    "\n",
    "    def __init__(self, env, agent, mcts_simulations = 100, max_depth = 100, delta = 0.5):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.cpuct = 0.2    # WARNING BULLSHIT NUMBER!\n",
    "        self.delta = delta  # value to prevent crash if no edges are visited\n",
    "        self.mcts_simulations = mcts_simulations\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.Qsa = {}       # stores Q values for s, a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores # times edge s, a was visited\n",
    "        self.Ns = {}        # stores # times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "        self.Es = {}        # stores victory result (1, 0, -1) ended for board s\n",
    "        self.Vs = {}        # stores legal actions for board s\n",
    "        self.zh = {}        # stores preserved state that is fed into the controller\n",
    "\n",
    "    def action_probabilities(self, encoded_state, temp = 1):\n",
    "        \"\"\"\n",
    "        This function performs numMCTSSims simulations of MCTS starting from\n",
    "        canonicalBoard.\n",
    "        Returns:\n",
    "            probs: a policy vector where the probability of the ith action is\n",
    "                   proportional to Nsa[(s,a)]**(1./temp)\n",
    "        \"\"\"\n",
    "        for runs in range(self.mcts_simulations):\n",
    "#             print(f\"{Fore.BLUE}MCTS SIMULATION {runs + 1}{Style.RESET_ALL}\")\n",
    "            self.search(encoded_state, 0)\n",
    "        \n",
    "        s = encoded_state\n",
    "        self.env.decode(encoded_state)\n",
    "        legal_actions = self.env.legal_actions()\n",
    "        counts = [self.Nsa[(s,a)] if (s,a) in self.Nsa else 0 for a in legal_actions]\n",
    "        # counts array represent the number of time each action edge from your current state was traversed\n",
    "\n",
    "        if temp == 0: # temprature is 0 representing taking the best action possible (greedy)\n",
    "            bestA = np.argmax(counts) # bestA: best action number : argmax Returns the indices of the maximum values\n",
    "            probs = [0] * len(counts)\n",
    "            probs[bestA] = 1\n",
    "            action_probs = {legal_actions[idx] : probs[idx] for idx in range(len(legal_actions))}\n",
    "            return action_probs # returns the definite move(s) with same greedy reward, out of which one move HAS to be played\n",
    "        \n",
    "#         print(f\"{Fore.BLUE}COUNTS {sum(counts)} {counts}{Style.RESET_ALL}\")\n",
    "        \n",
    "        # Handles frequent draw situation when MCTS fails to explore when the game is over resulting 0 counts causing div 0 error\n",
    "        if sum(counts) == 0:\n",
    "            counts = [1 for _ in counts]\n",
    "        counts = [x ** (1. / temp) + 0.5 for x in counts]\n",
    "        probs = [x / float(sum(counts)) for x in counts]\n",
    "        action_probs = {legal_actions[idx] : probs[idx] for idx in range(len(legal_actions))}\n",
    "        # If the game isn't over return the state zh or return None at the end\n",
    "        if self.env.result() != 0:\n",
    "            return action_probs, None\n",
    "        return action_probs, self.zh[s]  \n",
    "        #returns the probablity of different moves that CAN be played resulting in uniform distribution\n",
    "\n",
    "\n",
    "    def search(self, encoded_state, depth):\n",
    "        \"\"\"\n",
    "        This function performs one iteration of MCTS. It is recursively called\n",
    "        till a leaf node is found. The action chosen at each node is one that\n",
    "        has the maximum upper confidence bound as in the paper.\n",
    "        Once a leaf node is found, the neural network is called to return an\n",
    "        initial policy P and a value v for the state. This value is propogated\n",
    "        up the search path. In case the leaf node is a terminal state, the\n",
    "        outcome is propogated up the search path. The values of Ns, Nsa, Qsa are\n",
    "        updated.\n",
    "        NOTE: the return values are the negative of the value of the current\n",
    "        state. This is done since v is in [-1,1] and if v is the value of a\n",
    "        state for the current player, then its value is -v for the other player.\n",
    "        Returns:\n",
    "            v: the negative of the value of the current canonicalBoard\n",
    "        \"\"\"\n",
    "\n",
    "        s = deepcopy(encoded_state)\n",
    "        self.env.decode(encoded_state)\n",
    "#         print(f\"{Fore.GREEN}SEARCH DEPTH {depth}{Style.RESET_ALL}\")\n",
    "        \n",
    "        # Check if its an terminal state, -1 Opponent Won, 0 Game not Over, 1 Player Won\n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.env.result()\n",
    "        if self.Es[s] != 0 or self.env.terminal_test():\n",
    "#             print(\"SIMULATION OVER!\", self.env.terminal_test(), -self.Es[s], self.env.board.result())\n",
    "            return -self.Es[s]\n",
    "        \n",
    "        state, legal_actions = self.env.observe()\n",
    "#         legal_actions = self.env.legal_actions()\n",
    "\n",
    "        if s not in self.Ps: #if the current state 's' is not explored/expanded before n=0 by MCTS then create a new node and rollout\n",
    "            self.Ps[s], v, self.zh[s] = self.agent.act(state, legal_actions)\n",
    "#             print(\"self.Ps[s] at Depth\", depth, \"\\n\", self.Ps[s])\n",
    "            valids = legal_actions\n",
    "\n",
    "            self.Vs[s] = valids \n",
    "            self.Ns[s] = 0\n",
    "#             print(\"VALUE\", -v)\n",
    "            return -v\n",
    "        \n",
    "        valids = self.Vs[s] #as already visited the valid moves array 'Vs' is already initialized\n",
    "        cur_best = -float('inf')\n",
    "        best_act = -1\n",
    "        \n",
    "        self.env.decode(encoded_state)\n",
    "        legal_actions = self.env.legal_actions()\n",
    "        # pick the action with the highest upper confidence bound\n",
    "        \n",
    "        agent_actions = list(self.Ps[s].keys())\n",
    "        \n",
    "        # Handles the occasional legal action that isn't an actual legal action\n",
    "        # Pawn side cut even though there is no enemy piece in respective position\n",
    "#         print(\"XXXXX PRE LEGAL ACTIONS\\n\", legal_actions)\n",
    "        if not set(agent_actions) == set(legal_actions):\n",
    "            legal_actions = agent_actions\n",
    "#         print(\"XXXXX POST LEGAL ACTIONS\\n\", legal_actions)\n",
    "        for a in legal_actions:\n",
    "            if (s,a) in self.Qsa:\n",
    "                u = self.Qsa[(s,a)] + self.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (1 + self.Nsa[(s,a)])\n",
    "#                 print(\"In Qsa\")\n",
    "            else:\n",
    "                self.Ps[s][a] \n",
    "                u = self.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s])     # Q = 0 ? : node exists but not explored as added and initilized during nnet phase\n",
    "#                 print(\"Not In Qsa\", self.Ps[s][a], self.Ns[s], math.sqrt(self.Ns[s]))\n",
    "#             print(\"U\", u)\n",
    "            if math.isnan(u):\n",
    "                u = 0\n",
    "#                 print(\"Override U\", u)\n",
    "            if u > cur_best:\n",
    "                cur_best = u\n",
    "                best_act = a\n",
    "#         print(f\"{Fore.GREEN}BEST ACTION {best_act}{Style.RESET_ALL}\")\n",
    "        a = best_act\n",
    "\n",
    "        _, _ = self.env.step(a)\n",
    "        encoded_next_state = self.env.encode()\n",
    "\n",
    "        v = self.search(encoded_next_state, depth + 1) # RECURSION until leaf node or terminal node is found\n",
    "        \n",
    "        self.env.decode(encoded_state)\n",
    "        \n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)] * self.Qsa[(s,a)] + v) / (self.Nsa[(s,a)] + 1) #update the Q Value\n",
    "            self.Nsa[(s,a)] += 1 # increment number of visits to this node in MCTS\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v # initialize the new node\n",
    "            self.Nsa[(s,a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Resets the tracked information\"\"\"\n",
    "        self.Qsa = {}       \n",
    "        self.Nsa = {}       \n",
    "        self.Ns = {}        \n",
    "        self.Ps = {}       \n",
    "        self.Es = {}\n",
    "        self.Vs = {}  \n",
    "        self.zh = {}\n",
    "        self.agent.reset(1)\n",
    "        self.env.reset()\n",
    "\n",
    "# env.reset()\n",
    "# mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# game_move = 0\n",
    "\n",
    "# while not env.terminal_test():\n",
    "# #     print(f\"{Fore.RED}GAME MOVE {game_move}{Style.RESET_ALL}\")\n",
    "#     encoded_state = env.encode()\n",
    "#     if env.whites_turn: \n",
    "#         action_probs = mcts_white.action_probabilities(encoded_state)\n",
    "#     else:\n",
    "#         action_probs = mcts_black.action_probabilities(encoded_state)\n",
    "#     action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "# #     print(f\"{Fore.CYAN}ACTUAL MOVE\\n {action_probs}{Style.RESET_ALL}\")\n",
    "#     _, _ = env.step(action)\n",
    "    \n",
    "#     game_move += 1\n",
    "        \n",
    "# print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! GAME COMPLETED !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # COPY THIS\n",
    "# # https://github.com/suragnair/alpha-zero-general/blob/master/Coach.py\n",
    "\n",
    "# env.reset()\n",
    "# mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# game_move = 0\n",
    "\n",
    "# while not env.terminal_test():\n",
    "#     print(f\"{Fore.RED}GAME MOVE {game_move}{Style.RESET_ALL}\")\n",
    "#     encoded_state = env.encode()\n",
    "#     if env.whites_turn: \n",
    "#         action_probs = mcts_white.action_probabilities(encoded_state)\n",
    "#     else:\n",
    "#         action_probs = mcts_black.action_probabilities(encoded_state)\n",
    "#     action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "#     print(f\"{Fore.CYAN}ACTUAL MOVE\\n {action_probs}{Style.RESET_ALL}\")\n",
    "#     _, _ = env.step(action)\n",
    "    \n",
    "#     game_move += 1\n",
    "        \n",
    "# print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! GAME COMPLETED !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/Conv VAE/Test/\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "CNN_VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (enc_conv_mu): Conv(\n",
      "    (conv): Conv1d(512, 600, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      "  (enc_conv_logvar): Conv(\n",
      "    (conv): Conv1d(512, 600, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): ConvTranspose2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (dec_conv): Conv(\n",
      "    (conv): Conv1d(600, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "checkpoints/MDN RNN/Test/\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "MDN_RNN(\n",
      "  (lstm): LSTM(638, 100, batch_first=True)\n",
      "  (fc1): Linear(in_features=100, out_features=12000, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=12000, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=12000, bias=True)\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "Controller(\n",
      "  (fc1): Linear(in_features=700, out_features=1200, bias=True)\n",
      "  (fc_v1): Linear(in_features=700, out_features=100, bias=True)\n",
      "  (fc_v2): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (fc_v3): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(1200, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 76, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, decoder, action_size, vae, mdn, controller, batch_size = 64, lr = 1e-4, legal_multiplier = 2, save_freq = 30):\n",
    "        self.batch_size = batch_size\n",
    "        self.action_size = action_size\n",
    "        self.legal_multiplier = legal_multiplier # To increase the value of legal actions and MCTS insight as the target policy\n",
    "        self.decoder = decoder\n",
    "        self.save_freq = save_freq\n",
    "        self.vae = CNN_VAE(vae, None, 'Latest')\n",
    "        self.mdn = MDN_RNN(mdn, None, 'Latest')\n",
    "        params = {\n",
    "            'hidden_size' : self.mdn.hidden_size,\n",
    "            'z_size' : self.vae.z_size,\n",
    "            'action_size' : action_size,\n",
    "            'expansion_size': 1200\n",
    "        }\n",
    "        self.controller = Controller('Test', params, False)\n",
    "        self.optimizer = Adam(self.controller.parameters(), lr = lr)\n",
    "        \n",
    "        self.char_to_int = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8} \n",
    "        self.char_to_int_promo = {'r': 1, 'b': 2, 'q': 3, 'k': 4, 'n': 5, '': 6} \n",
    "        \n",
    "        moves_df = pd.DataFrame(list(zip(self.char_to_int.values(), self.char_to_int.keys())), columns = ['Ids', 'Labels'])\n",
    "        promo_df = pd.DataFrame(list(zip(self.char_to_int_promo.values(), self.char_to_int_promo.keys())), columns = ['Ids', 'Labels'])\n",
    "        self.move_actions_ohe = pd.get_dummies(moves_df['Ids'])\n",
    "        self.promo_actions_ohe = pd.get_dummies(promo_df['Ids'])\n",
    "        \n",
    "        self.criterion_pi = nn.NLLLoss()\n",
    "        self.criterion_v = nn.MSELoss()\n",
    "        self.trained_times = 0\n",
    "    \n",
    "    def select_action(self, logits, legal_actions):\n",
    "        \"\"\"Decodes the output from the NN to legal actions\"\"\" \n",
    "        decoder_ = np.ndarray.flatten(self.decoder)\n",
    "        logits_ = np.ndarray.flatten(logits)\n",
    "\n",
    "        move_logits = [(decoder_[idx].lower(), logits_[idx]) for idx in range(len(logits_))]\n",
    "        move_logits = dict(move_logits)\n",
    "        \n",
    "        legal_move_logits = {legal_action: move_logits[legal_action] for legal_action in legal_actions}\n",
    "        probabilities = list(legal_move_logits.values()) / sum(list(legal_move_logits.values()))\n",
    "        \n",
    "        legal_actions = list(legal_move_logits.keys())\n",
    "        action = random.choices(list(legal_move_logits.keys()), weights = probabilities, k = 1)[0]\n",
    "        \n",
    "        action_probabilities = {legal_actions[idx] : probabilities[idx] for idx in range(len(legal_actions))}\n",
    "        return action, action_probabilities\n",
    "    \n",
    "    def one_hot_encode_action(self, action):\n",
    "        \"\"\"One hot encodes the action\"\"\"\n",
    "        if len(action) == 4:\n",
    "            encoded_action = [\n",
    "                self.move_actions_ohe.loc[\n",
    "                self.char_to_int[action[0]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[1]) - 1].values, \n",
    "                self.move_actions_ohe.loc[self.char_to_int[action[2]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[3]) - 1].values,\n",
    "                self.promo_actions_ohe.loc[self.char_to_int_promo[''] - 1].values\n",
    "            ]\n",
    "        else:\n",
    "            encoded_action = [\n",
    "                self.move_actions_ohe.loc[\n",
    "                self.char_to_int[action[0]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[1]) - 1].values, \n",
    "                self.move_actions_ohe.loc[self.char_to_int[action[2]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[3]) - 1].values,\n",
    "                self.promo_actions_ohe.loc[self.char_to_int_promo[action[4]] - 1].values\n",
    "            ]\n",
    "        ohe_action = np.concatenate(encoded_action)\n",
    "        return ohe_action\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        \"\"\"Resets the MDNs hidden state\"\"\"\n",
    "        self.hidden = self.mdn.init_hidden(batch_size)\n",
    "        \n",
    "    def act(self, state, legal_actions):\n",
    "        \"\"\"Gets an action from the agent\"\"\"\n",
    "        state = torch.tensor(state).float().unsqueeze(0)\n",
    "        mu, logvar = self.vae.encode(state)\n",
    "        z = self.vae.reparameterize(mu, logvar).squeeze(-1)\n",
    "        zh = torch.cat((z.to('cpu'), self.hidden[0].squeeze(0).to('cpu')), dim = 1)\n",
    "        if zh.shape[0] > 1:\n",
    "            raise Exception('Batch size > 1 not handled')\n",
    "        logits, values = self.controller(zh)\n",
    "        logits, value = logits.detach().squeeze(0).cpu().numpy(), values.detach().squeeze(0).cpu().numpy()[0]\n",
    "        action, action_probabilities = self.select_action(logits, legal_actions)\n",
    "        return action_probabilities, value, zh\n",
    "    \n",
    "    def train(self, experiences):\n",
    "        \"\"\"Trains the controller from the MCTS experiences\"\"\"\n",
    "        batches = [experiences[i : i + self.batch_size] for i in range(0, len(experiences), self.batch_size)]\n",
    "        for batch in deepcopy(batches):\n",
    "            zh, target_action_probs, returns = zip(*batch)\n",
    "            returns = torch.tensor(returns).float()\n",
    "            zh = torch.tensor(np.concatenate(zh, axis = 0)).float()\n",
    "            self.optimizer.zero_grad()\n",
    "            logits, values = self.controller(zh)\n",
    "            target_policies = self.target_policies(logits, target_action_probs)\n",
    "            \n",
    "            policy_losses = []\n",
    "            value_losses = []\n",
    "            \n",
    "            for idx in range(logits.shape[0]):\n",
    "                advantage = returns[idx] - values[idx]\n",
    "                # converts logits to action probabilities\n",
    "                policy_losses.append(-F.softmax(logits[idx], dim = 0) * advantage)\n",
    "                value_losses.append(F.smooth_l1_loss(values[idx], returns[idx]))\n",
    "            \n",
    "            # sum up all the values of policy_losses and value_losses\n",
    "            loss = torch.stack(policy_losses).mean() + torch.stack(value_losses).mean()\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.trained_times % self.save_freq == 0:\n",
    "            print(\"SAVING\")\n",
    "            self.controller.name = f\"{self.controller.name} {self.trained_times}\"\n",
    "            self.controller.save_model()\n",
    "        self.trained_times += 1\n",
    "                \n",
    "    def target_policies(self, logits, legal_move_logits):\n",
    "        \"\"\"Takes the logits from the current policy and layers the insights from MCTS\"\"\"\n",
    "        new_boards__ = [[x.lower() for x in list(np.ndarray.flatten(self.decoder))] for _ in range(logits.shape[0])]\n",
    "        target_policies = []\n",
    "        for idx in range(logits.shape[0]):\n",
    "            new_boards___ = new_boards__[idx]\n",
    "            logits__ = logits[idx].view(-1)\n",
    "            legal_move_logits__ = {k.lower(): v * LEGAL_MULTIPIER for k, v in legal_move_logits_[idx].items()}\n",
    "            for move, legal_move_logit in legal_move_logits__.items():\n",
    "                index = new_boards___.index(move)\n",
    "                logits__[index] += legal_move_logit\n",
    "            target_policies.append(logits__)\n",
    "        target_policies = torch.cat(target_policies, dim = 0).reshape(logits.shape[0], 76, 8, 8).float()\n",
    "        return target_policies\n",
    "    \n",
    "agent = Agent(env.decoder, env.action_size, 'Test', 'Test', 'Test')\n",
    "\n",
    "agent.reset(1)\n",
    "# print(len(TRAIN_EXAMPLES))\n",
    "# agent.train(TRAIN_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SanujaPC\\AppData\\Local\\conda\\conda\\envs\\trader\\lib\\site-packages\\ipykernel_launcher.py:79: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229a8fcd890a4ec6b1cd5950d57df017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Self Play', max=5.0, style=ProgressStyle(description_widt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SanujaPC\\AppData\\Local\\conda\\conda\\envs\\trader\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 0 Score 0.5\n",
      "Game 1 Score 0.5\n",
      "Game 2 Score 0.5\n",
      "Game 3 Score 0.5\n",
      "Game 4 Score 0.5\n",
      "\n",
      "309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SanujaPC\\AppData\\Local\\conda\\conda\\envs\\trader\\lib\\site-packages\\ipykernel_launcher.py:107: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0165, grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, grad_fn=<AddBackward0>)\n",
      "SAVING\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976da2636a174c83bb5abe41fde562ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Self Play', max=5.0, style=ProgressStyle(description_widt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 5 Score 0.5\n",
      "Game 6 Score -1\n",
      "Game 7 Score 0.5\n",
      "Game 8 Score 0.5\n",
      "Game 9 Score -1\n",
      "\n",
      "316\n",
      "tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "tensor(0.0276, grad_fn=<AddBackward0>)\n",
      "tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "tensor(0.0134, grad_fn=<AddBackward0>)\n",
      "tensor(0.0192, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6d53deaae642e19e4ceefddef0d01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Self Play', max=5.0, style=ProgressStyle(description_widt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 10 Score 0.5\n",
      "Game 11 Score -1\n",
      "Game 12 Score 0.5\n",
      "Game 13 Score 0.5\n",
      "Game 14 Score 0.5\n",
      "\n",
      "240\n",
      "tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "tensor(0.0180, grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, grad_fn=<AddBackward0>)\n",
      "tensor(0.0132, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6533f7c2c84cee954396e83d91c286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Self Play', max=5.0, style=ProgressStyle(description_widt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 15 Score 0.5\n",
      "Game 16 Score 0.5\n",
      "Game 17 Score -1\n",
      "Game 18 Score -1\n",
      "Game 19 Score 0.5\n",
      "\n",
      "335\n",
      "tensor(0.0192, grad_fn=<AddBackward0>)\n",
      "tensor(0.0190, grad_fn=<AddBackward0>)\n",
      "tensor(0.0183, grad_fn=<AddBackward0>)\n",
      "tensor(0.0159, grad_fn=<AddBackward0>)\n",
      "tensor(0.0223, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4d1ea742c54d29a68275e13d05ab10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Self Play', max=5.0, style=ProgressStyle(description_widt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Coach():\n",
    "    \"\"\"\n",
    "    This class executes the self-play + learning. It uses the functions defined\n",
    "    in Game and NeuralNet. args are specified in main.py.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, agent, params):\n",
    "        self.iterations = params['iterations']\n",
    "        self.episodes = params['episodes']\n",
    "        self.queue_length = params['queue_length']\n",
    "        self.env = deepcopy(env)\n",
    "        self.agent = agent\n",
    "        self.mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = params['simulations'])\n",
    "        self.mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = params['simulations'])\n",
    "        self.trainExamplesHistory = []  # history of examples from args.numItersForTrainExamplesHistory latest iterations\n",
    "        self.games = 0\n",
    "\n",
    "    def executeEpisode(self):\n",
    "        \"\"\"\n",
    "        This function executes one episode of self-play, starting with player 1.\n",
    "        As the game is played, each turn is added as a training example to\n",
    "        trainExamples. The game is played till the game ends. After the game\n",
    "        ends, the outcome of the game is used to assign values to each example\n",
    "        in trainExamples.\n",
    "        It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "        uses temp=0.\n",
    "        Returns:\n",
    "            trainExamples: a list of examples of the form (canonicalBoard, currPlayer, pi,v)\n",
    "                           pi is the MCTS informed policy vector, v is +1 if\n",
    "                           the player eventually won the game, else -1.\n",
    "        \"\"\"\n",
    "        experiences = []\n",
    "        self.env.reset()\n",
    "        self.mcts_white.reset()  # reset search tree\n",
    "        self.mcts_black.reset()\n",
    "        game_move = 0\n",
    "        while not self.env.terminal_test():\n",
    "            encoded_state = self.env.encode()\n",
    "            if self.env.whites_turn: \n",
    "                action_probs, zh = self.mcts_white.action_probabilities(encoded_state)\n",
    "            else:\n",
    "                action_probs, zh = self.mcts_black.action_probabilities(encoded_state)\n",
    "            if zh is not None:\n",
    "                experiences.append([zh.detach().cpu().numpy(), self.env.whites_turn, action_probs, None])\n",
    "            action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "            _, _ = self.env.step(action)\n",
    "    \n",
    "            game_move += 1\n",
    "        \n",
    "        reward = self.env.result()\n",
    "        print(f\"Game {self.games} Score {reward}\")\n",
    "        experiences_ = []\n",
    "        DISCOUNT_GAMMA = 0.95\n",
    "        \n",
    "        for idx, experience in enumerate(experiences):\n",
    "            reward_ = reward\n",
    "            # calculates the discounted return from the reward.. \n",
    "            # / 2 becauses it contains experiences of both black and white\n",
    "            return_ = reward_ * (DISCOUNT_GAMMA ** (len(experiences) - idx) / 2)\n",
    "            if experience[1] != self.env.whites_turn and (reward_ == 1 or reward_ == -1):\n",
    "                return_ *= -1\n",
    "            experiences_.append((experience[0], experience[2], return_))\n",
    "        return experiences_\n",
    "    \n",
    "    \n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Performs numIters iterations with numEps episodes of self-play in each\n",
    "        iteration. After every iteration, it retrains neural network with\n",
    "        examples in trainExamples (which has a maximum length of maxlenofQueue).\n",
    "        It then pits the new neural network against the old one and accepts it\n",
    "        only if it wins >= updateThreshold fraction of games.\n",
    "        \"\"\"\n",
    "        # deletes historical experiences so AI to enable online learning\n",
    "        self.trainExamplesHistory = []\n",
    "        \n",
    "        for i in range(1, self.iterations + 1):\n",
    "            iterationTrainExamples = deque([], maxlen = self.queue_length)\n",
    "            for _ in tnrange(self.episodes, desc = \"Self Play\"):\n",
    "                iterationTrainExamples += self.executeEpisode()\n",
    "                self.games += 1\n",
    "\n",
    "            # save the iteration examples to the history \n",
    "            self.trainExamplesHistory.append(iterationTrainExamples)\n",
    "\n",
    "        # shuffle examples before training\n",
    "        trainExamples = []\n",
    "        for e in self.trainExamplesHistory:\n",
    "            trainExamples.extend(e)\n",
    "        shuffle(trainExamples)\n",
    "        print(len(trainExamples))\n",
    "        \n",
    "        self.agent.train(trainExamples)\n",
    "        self.mcts_white.agent = deepcopy(self.agent)\n",
    "        self.mcts_black.agent = deepcopy(self.agent)\n",
    "        \n",
    "\n",
    "#         # training new network, keeping a copy of the old one\n",
    "#         self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "#         self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "#         pmcts = MCTS(self.game, self.pnet, self.args)\n",
    "\n",
    "#         \n",
    "#         nmcts = MCTS(self.game, self.nnet, self.args)\n",
    "\n",
    "#         log.info('PITTING AGAINST PREVIOUS VERSION')\n",
    "#         arena = Arena(lambda x: np.argmax(pmcts.getActionProb(x, temp=0)),\n",
    "#                           lambda x: np.argmax(nmcts.getActionProb(x, temp=0)), self.game)\n",
    "#         pwins, nwins, draws = arena.playGames(self.args.arenaCompare)\n",
    "\n",
    "#         log.info('NEW/PREV WINS : %d / %d ; DRAWS : %d' % (nwins, pwins, draws))\n",
    "#         if pwins + nwins == 0 or float(nwins) / (pwins + nwins) < self.args.updateThreshold:\n",
    "#             log.info('REJECTING NEW MODEL')\n",
    "#             self.nnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "#         else:\n",
    "#             log.info('ACCEPTING NEW MODEL')\n",
    "#             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename=self.getCheckpointFile(i))\n",
    "#             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='best.pth.tar')\n",
    "        \n",
    "\n",
    "params = {\n",
    "    'iterations': 1,\n",
    "    'episodes': 5,\n",
    "    'queue_length' : 500,\n",
    "    'simulations' : 200\n",
    "}\n",
    "coach = Coach(env, agent, params)\n",
    "for _ in range(500):\n",
    "    coach.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.decode(b'\\x80\\x03}q\\x00(X\\x05\\x00\\x00\\x00boardq\\x01}q\\x02(K?cchess\\nPiece\\nq\\x03)\\x81q\\x04}q\\x05(X\\n\\x00\\x00\\x00piece_typeq\\x06K\\x04X\\x05\\x00\\x00\\x00colorq\\x07\\x89ubK>h\\x03)\\x81q\\x08}q\\t(h\\x06K\\x02h\\x07\\x89ubK=h\\x03)\\x81q\\n}q\\x0b(h\\x06K\\x03h\\x07\\x89ubK<h\\x03)\\x81q\\x0c}q\\r(h\\x06K\\x06h\\x07\\x89ubK;h\\x03)\\x81q\\x0e}q\\x0f(h\\x06K\\x05h\\x07\\x89ubK:h\\x03)\\x81q\\x10}q\\x11(h\\x06K\\x03h\\x07\\x89ubK9h\\x03)\\x81q\\x12}q\\x13(h\\x06K\\x02h\\x07\\x89ubK8h\\x03)\\x81q\\x14}q\\x15(h\\x06K\\x04h\\x07\\x89ubK7h\\x03)\\x81q\\x16}q\\x17(h\\x06K\\x01h\\x07\\x89ubK6h\\x03)\\x81q\\x18}q\\x19(h\\x06K\\x01h\\x07\\x89ubK5h\\x03)\\x81q\\x1a}q\\x1b(h\\x06K\\x01h\\x07\\x89ubK4h\\x03)\\x81q\\x1c}q\\x1d(h\\x06K\\x01h\\x07\\x89ubK3h\\x03)\\x81q\\x1e}q\\x1f(h\\x06K\\x01h\\x07\\x89ubK2h\\x03)\\x81q }q!(h\\x06K\\x01h\\x07\\x89ubK1h\\x03)\\x81q\"}q#(h\\x06K\\x01h\\x07\\x89ubK0h\\x03)\\x81q$}q%(h\\x06K\\x01h\\x07\\x89ubK\\x0fh\\x03)\\x81q&}q\\'(h\\x06K\\x01h\\x07\\x88ubK\\x0eh\\x03)\\x81q(}q)(h\\x06K\\x01h\\x07\\x88ubK\\rh\\x03)\\x81q*}q+(h\\x06K\\x01h\\x07\\x88ubK\\x0ch\\x03)\\x81q,}q-(h\\x06K\\x01h\\x07\\x88ubK\\x0bh\\x03)\\x81q.}q/(h\\x06K\\x01h\\x07\\x88ubK\\nh\\x03)\\x81q0}q1(h\\x06K\\x01h\\x07\\x88ubK\\th\\x03)\\x81q2}q3(h\\x06K\\x01h\\x07\\x88ubK\\x08h\\x03)\\x81q4}q5(h\\x06K\\x01h\\x07\\x88ubK\\x07h\\x03)\\x81q6}q7(h\\x06K\\x04h\\x07\\x88ubK\\x06h\\x03)\\x81q8}q9(h\\x06K\\x02h\\x07\\x88ubK\\x05h\\x03)\\x81q:}q;(h\\x06K\\x03h\\x07\\x88ubK\\x04h\\x03)\\x81q<}q=(h\\x06K\\x06h\\x07\\x88ubK\\x03h\\x03)\\x81q>}q?(h\\x06K\\x05h\\x07\\x88ubK\\x02h\\x03)\\x81q@}qA(h\\x06K\\x03h\\x07\\x88ubK\\x01h\\x03)\\x81qB}qC(h\\x06K\\x02h\\x07\\x88ubK\\x00h\\x03)\\x81qD}qE(h\\x06K\\x04h\\x07\\x88ubuX\\x04\\x00\\x00\\x00turnqF\\x88X\\r\\x00\\x00\\x00legal_actionsqG]qH(X\\x04\\x00\\x00\\x00g1h3qIX\\x04\\x00\\x00\\x00g1f3qJX\\x04\\x00\\x00\\x00b1c3qKX\\x04\\x00\\x00\\x00b1a3qLX\\x04\\x00\\x00\\x00h2h3qMX\\x04\\x00\\x00\\x00g2g3qNX\\x04\\x00\\x00\\x00f2f3qOX\\x04\\x00\\x00\\x00e2e3qPX\\x04\\x00\\x00\\x00d2d3qQX\\x04\\x00\\x00\\x00c2c3qRX\\x04\\x00\\x00\\x00b2b3qSX\\x04\\x00\\x00\\x00a2a3qTX\\x04\\x00\\x00\\x00h2h4qUX\\x04\\x00\\x00\\x00g2g4qVX\\x04\\x00\\x00\\x00f2f4qWX\\x04\\x00\\x00\\x00e2e4qXX\\x04\\x00\\x00\\x00d2d4qYX\\x04\\x00\\x00\\x00c2c4qZX\\x04\\x00\\x00\\x00b2b4q[X\\x04\\x00\\x00\\x00a2a4q\\\\eu.')\n",
    "env.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-trader]",
   "language": "python",
   "name": "conda-env-conda-trader-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
