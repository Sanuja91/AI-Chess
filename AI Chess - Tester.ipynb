{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# DEEPMIND ALPHAZERO CHESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Calculate Advantages in Agent Train Function\n",
    "- Have training on GPU and inference CPU\n",
    "- Implement https://www.youtube.com/watch?v=a4VvcmqnkhY\n",
    "- print(f\"INVALID ACTION {action}.\\nSELECTING A RANDOM ACTION FROM LEGAL ACTIONS\\n{self.legal_actions()}\") #### DISABLED FOR VIEWING PRINTS PROPERLY!\n",
    "\n",
    "\n",
    "## TODO LATER\n",
    "#### - Get backward possibly loss to train the controller. Might need to save the tensor output like states, values, etc in MCTS\n",
    "- Create Self play class\n",
    "- Create Arena class\n",
    "\n",
    "DEEP MIND OPEN ACCESS PAPER \n",
    "\n",
    "https://kstatic.googleusercontent.com/files/2f51b2a749a284c2e2dfa13911da965f4855092a179469aedd15fbe4efe8f8cbf9c515ef83ac03a6515fa990e6f85fd827dcd477845e806f23a17845072dc7bd\n",
    "\n",
    "RAY ALPHA ZERO IMPLEMENTATION \n",
    "\n",
    "https://github.com/ray-project/ray/tree/master/rllib/contrib/alpha_zero\n",
    "\n",
    "DUPLICATED MCTS IMPLEMENTATION\n",
    "\n",
    "https://github.com/suragnair/alpha-zero-general/blob/master/MCTS.py\n",
    "\n",
    "DISTRIBUTED IMPLEMENTATION\n",
    "\n",
    "https://github.com/mokemokechicken/reversi-alpha-zero/blob/master/src/reversi_zero/lib/ggf.py\n",
    "\n",
    "CHESS MOVES\n",
    "\n",
    "https://www.ichess.net/blog/chess-pieces-moves/\n",
    "\n",
    "BOARD REPRESENTATIONS\n",
    "\n",
    "https://medium.com/datadriveninvestor/reconstructing-chess-positions-f195fd5944e\n",
    "\n",
    "ALPHA ZERO EXPLANATION\n",
    "\n",
    "https://nikcheerla.github.io/deeplearningschool/2018/01/01/AlphaZero-Explained/\n",
    "\n",
    "TRANSFORMER NETWORK IMPLEMENTATION\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user python-chess gym colorama tqdm PyQt5 ray tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess, gym, pickle, random, torch, math\n",
    "# ray\n",
    "# ray.init()\n",
    "import chess.svg as svg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy, deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Categorical\n",
    "# plt.style.use('ggplot')\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from copy import deepcopy\n",
    "from colorama import init, Fore, Back, Style\n",
    "from collections import Counter, deque\n",
    "from tqdm import tqdm, tnrange, notebook\n",
    "from random import shuffle\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from PyQt5.QtSvg import QSvgWidget\n",
    "from PyQt5.QtWidgets import QApplication, QWidget\n",
    "\n",
    "from utilities import *\n",
    "# import constants \n",
    "from constants import *\n",
    "from models.vae import CNN_AE, CNN_VAE, train_ae, train_vae, Conv\n",
    "from models.mdn import MDN_RNN, loss_function, clip_grad_norm_\n",
    "from models.controller import Policy_Controller, Value_Controller\n",
    "\n",
    "# init(convert = True)\n",
    "# REFERENCES\n",
    "# Tensorflow implementation for Chess\n",
    "# https://github.com/saurabhk7/chess-alpha-zero\n",
    "\n",
    "# Pytorch implementation for Connect4\n",
    "# https://github.com/plkmo/AlphaZero_Connect4/tree/master/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    \"\"\"Monte Carlo Tree Search Algorithm geared for Neural Networks\"\"\"\n",
    "\n",
    "    def __init__(self, env, agent, mcts_simulations = 100, max_depth = 100, delta = 0.5):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.cpuct = 1.5    # WARNING BULLSHIT NUMBER!\n",
    "        self.delta = delta  # value to prevent crash if no edges are visited\n",
    "        self.mcts_simulations = mcts_simulations\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.Qsa = {}       # stores Q values for s, a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores # times edge s, a was visited\n",
    "        self.Ns = {}        # stores # times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "        self.Es = {}        # stores victory result (1, 0, -1) ended for board s\n",
    "        self.Vs = {}        # stores legal actions for board s\n",
    "        self.z = {}         # stores the features of the state\n",
    "        self.hidden = {}    # stores the hidden states\n",
    "\n",
    "    def action_probabilities(self, encoded_state, temp = 1):\n",
    "        \"\"\"\n",
    "        This function performs numMCTSSims simulations of MCTS starting from\n",
    "        canonicalBoard.\n",
    "        Returns:\n",
    "            probs: a policy vector where the probability of the ith action is\n",
    "                   proportional to Nsa[(s,a)]**(1./temp)\n",
    "        \"\"\"\n",
    "        for runs in range(self.mcts_simulations):\n",
    "#             print(f\"{Fore.BLUE}MCTS SIMULATION {runs + 1}{Style.RESET_ALL}\")\n",
    "            self.search(encoded_state, 0)\n",
    "        \n",
    "        s = encoded_state\n",
    "        self.env.decode(encoded_state)\n",
    "        legal_actions = self.env.legal_actions()\n",
    "        counts = [self.Nsa[(s,a)] if (s,a) in self.Nsa else 0 for a in legal_actions]\n",
    "        # counts array represent the number of time each action edge from your current state was traversed\n",
    "        \n",
    "        # temprature is 0 representing taking the best action possible (greedy)\n",
    "        if temp == 0: \n",
    "            # bestA: best action number : argmax Returns the indices of the maximum values\n",
    "            bestA = np.argmax(counts) \n",
    "            probs = [0] * len(counts)\n",
    "            probs[bestA] = 1\n",
    "            action_probs = {legal_actions[idx] : probs[idx] for idx in range(len(legal_actions))}\n",
    "            zh = torch.cat((self.z[s].to('cpu'), self.hidden[s][0].squeeze(0).to('cpu')), dim = 1)\n",
    "            # returns the definite move(s) with same greedy reward, out of which one move HAS to be played\n",
    "            return action_probs, zh\n",
    "        \n",
    "#         print(f\"{Fore.BLUE}COUNTS {sum(counts)} {counts}{Style.RESET_ALL}\")\n",
    "        \n",
    "        # Handles frequent draw situation when MCTS fails to explore when the game is over resulting 0 counts causing div 0 error\n",
    "        if sum(counts) == 0:\n",
    "            counts = [1 for _ in counts]\n",
    "            \n",
    "        counts = [x ** (1. / temp) + 0.5 for x in counts]\n",
    "        probs = [x / float(sum(counts)) for x in counts]\n",
    "        action_probs = {legal_actions[idx] : probs[idx] for idx in range(len(legal_actions))}\n",
    "        zh = torch.cat((self.z[s].to('cpu'), self.hidden[s][0].squeeze(0).to('cpu')), dim = 1)\n",
    "#         print(zh)\n",
    "        return action_probs, zh\n",
    "        #returns the probablity of different moves that CAN be played resulting in uniform distribution\n",
    "\n",
    "\n",
    "    def search(self, encoded_state, depth):\n",
    "        \"\"\"\n",
    "        This function performs one iteration of MCTS. It is recursively called\n",
    "        till a leaf node is found. The action chosen at each node is one that\n",
    "        has the maximum upper confidence bound as in the paper.\n",
    "        Once a leaf node is found, the neural network is called to return an\n",
    "        initial policy P and a value v for the state. This value is propogated\n",
    "        up the search path. In case the leaf node is a terminal state, the\n",
    "        outcome is propogated up the search path. The values of Ns, Nsa, Qsa are\n",
    "        updated.\n",
    "        NOTE: the return values are the negative of the value of the current\n",
    "        state. This is done since v is in [-1,1] and if v is the value of a\n",
    "        state for the current player, then its value is -v for the other player.\n",
    "        Returns:\n",
    "            v: the negative of the value of the current canonicalBoard\n",
    "        \"\"\"\n",
    "\n",
    "        s = deepcopy(encoded_state)\n",
    "        self.env.decode(encoded_state)\n",
    "#         print(f\"{Fore.GREEN}SEARCH DEPTH {depth}{Style.RESET_ALL}\")\n",
    "        \n",
    "        # Check if its an terminal state, -1 Opponent Won, 0 Game not Over, 1 Player Won\n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.env.result()\n",
    "        \n",
    "        # Handles the maintaining of the MDNs hidden states\n",
    "        if s not in self.hidden:\n",
    "            self.hidden[s] = self.agent.get_hidden()\n",
    "        else:\n",
    "            self.agent.load_hidden(self.hidden[s])\n",
    "        \n",
    "        # Checks if the game is over and returns the respective value\n",
    "        if self.env.terminal_test():\n",
    "            state, _ = self.env.observe()\n",
    "            self.z[s] = self.agent.encode_z(state)\n",
    "            \n",
    "#             print(\"SIMULATION OVER!\", self.env.terminal_test(), -self.Es[s], self.env.board.result())\n",
    "            return -self.Es[s]          \n",
    "        \n",
    "        state, legal_actions = self.env.observe()\n",
    "\n",
    "        # if the current state 's' is not explored/expanded before n = 0 by MCTS then create a new node and rollout\n",
    "        if s not in self.Ps: \n",
    "            self.Ps[s], v, self.z[s] = self.agent.act(state, legal_actions)\n",
    "#             print(\"self.Ps[s] at Depth\", depth, \"\\n\", self.Ps[s])\n",
    "            valids = legal_actions\n",
    "\n",
    "            self.Vs[s] = valids \n",
    "            self.Ns[s] = 0\n",
    "#             print(\"VALUE\", -v)\n",
    "            return -v\n",
    "\n",
    "        # as already visited the valid moves array 'Vs' is already initialized\n",
    "        valids = self.Vs[s] \n",
    "        cur_best = -float('inf')\n",
    "        best_act = -1\n",
    "        \n",
    "        self.env.decode(encoded_state)\n",
    "        legal_actions = self.env.legal_actions()\n",
    "        # pick the action with the highest upper confidence bound\n",
    "        \n",
    "        agent_actions = list(self.Ps[s].keys())\n",
    "        \n",
    "        # Handles the occasional legal action that isn't an actual legal action\n",
    "        # Pawn side cut even though there is no enemy piece in respective position\n",
    "#         print(\"XXXXX PRE LEGAL ACTIONS\\n\", legal_actions)\n",
    "        if not set(agent_actions) == set(legal_actions):\n",
    "            legal_actions = agent_actions\n",
    "#         print(\"XXXXX POST LEGAL ACTIONS\\n\", legal_actions)\n",
    "        for a in legal_actions:\n",
    "            if (s,a) in self.Qsa:\n",
    "                u = self.Qsa[(s,a)] + self.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (1 + self.Nsa[(s,a)])\n",
    "#                 print(\"In Qsa\")\n",
    "            else:\n",
    "                self.Ps[s][a] \n",
    "                u = self.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s])     # Q = 0 ? : node exists but not explored as added and initilized during nnet phase\n",
    "#                 print(\"Not In Qsa\", self.Ps[s][a], self.Ns[s], math.sqrt(self.Ns[s]))\n",
    "#             print(\"U\", u)\n",
    "            if math.isnan(u):\n",
    "                u = 0\n",
    "#                 print(\"Override U\", u)\n",
    "            if u > cur_best:\n",
    "                cur_best = u\n",
    "                best_act = a\n",
    "#         print(f\"{Fore.GREEN}BEST ACTION {best_act}{Style.RESET_ALL}\")\n",
    "        a = best_act\n",
    "\n",
    "        _, _ = self.env.step(a)\n",
    "        self.agent.step(self.z[s], a)\n",
    "        \n",
    "        encoded_next_state = self.env.encode()\n",
    "\n",
    "        v = self.search(encoded_next_state, depth + 1) # RECURSION until leaf node or terminal node is found\n",
    "        \n",
    "        self.env.decode(encoded_state)\n",
    "        \n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)] * self.Qsa[(s,a)] + v) / (self.Nsa[(s,a)] + 1) #update the Q Value\n",
    "            self.Nsa[(s,a)] += 1 # increment number of visits to this node in MCTS\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v # initialize the new node\n",
    "            self.Nsa[(s,a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Resets the tracked information\"\"\"\n",
    "        self.Qsa = {}       \n",
    "        self.Nsa = {}       \n",
    "        self.Ns = {}        \n",
    "        self.Ps = {}       \n",
    "        self.Es = {}\n",
    "        self.Vs = {}  \n",
    "        self.zh = {}\n",
    "        self.hidden = {}\n",
    "        self.agent.reset(1)\n",
    "        self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"390\" version=\"1.1\" viewBox=\"0 0 390 390\" width=\"390\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><g class=\"white pawn\" id=\"white-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#000000; stroke:#000000;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /></g><g class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g class=\"black pawn\" id=\"black-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#ececec; stroke:#ececec;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-linejoin=\"miter\" stroke-width=\"1\" /></g><g class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect fill=\"#212121\" height=\"390\" width=\"390\" x=\"0\" y=\"0\" /><rect class=\"square dark a1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"330\" /><use transform=\"translate(15, 330)\" xlink:href=\"#white-rook\" /><rect class=\"square light b1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"330\" /><use transform=\"translate(60, 330)\" xlink:href=\"#white-knight\" /><rect class=\"square dark c1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"330\" /><use transform=\"translate(105, 330)\" xlink:href=\"#white-bishop\" /><rect class=\"square light d1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"330\" /><use transform=\"translate(150, 330)\" xlink:href=\"#white-queen\" /><rect class=\"square dark e1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"330\" /><use transform=\"translate(195, 330)\" xlink:href=\"#white-king\" /><rect class=\"square light f1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"330\" /><use transform=\"translate(240, 330)\" xlink:href=\"#white-bishop\" /><rect class=\"square dark g1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"330\" /><use transform=\"translate(285, 330)\" xlink:href=\"#white-knight\" /><rect class=\"square light h1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"330\" /><use transform=\"translate(330, 330)\" xlink:href=\"#white-rook\" /><rect class=\"square light a2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"285\" /><use transform=\"translate(15, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark b2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"285\" /><use transform=\"translate(60, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light c2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"285\" /><use transform=\"translate(105, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark d2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"285\" /><use transform=\"translate(150, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light e2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"285\" /><use transform=\"translate(195, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark f2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"285\" /><use transform=\"translate(240, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light g2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"285\" /><use transform=\"translate(285, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark h2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"285\" /><use transform=\"translate(330, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark a3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"240\" /><rect class=\"square light b3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"240\" /><rect class=\"square dark c3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"240\" /><rect class=\"square light d3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"240\" /><rect class=\"square dark e3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"240\" /><rect class=\"square light f3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"240\" /><rect class=\"square dark g3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"240\" /><rect class=\"square light h3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"240\" /><rect class=\"square light a4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"195\" /><rect class=\"square dark b4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"195\" /><rect class=\"square light c4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"195\" /><rect class=\"square dark d4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"195\" /><rect class=\"square light e4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"195\" /><rect class=\"square dark f4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"195\" /><rect class=\"square light g4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"195\" /><rect class=\"square dark h4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"195\" /><rect class=\"square dark a5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"150\" /><rect class=\"square light b5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"150\" /><rect class=\"square dark c5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"150\" /><rect class=\"square light d5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"150\" /><rect class=\"square dark e5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"150\" /><rect class=\"square light f5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"150\" /><rect class=\"square dark g5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"150\" /><rect class=\"square light h5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"150\" /><rect class=\"square light a6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"105\" /><rect class=\"square dark b6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"105\" /><rect class=\"square light c6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"105\" /><rect class=\"square dark d6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"105\" /><rect class=\"square light e6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"105\" /><rect class=\"square dark f6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"105\" /><rect class=\"square light g6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"105\" /><rect class=\"square dark h6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"105\" /><rect class=\"square dark a7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"60\" /><use transform=\"translate(15, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light b7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"60\" /><use transform=\"translate(60, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark c7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"60\" /><use transform=\"translate(105, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light d7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"60\" /><use transform=\"translate(150, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark e7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"60\" /><use transform=\"translate(195, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light f7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"60\" /><use transform=\"translate(240, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark g7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"60\" /><use transform=\"translate(285, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light h7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"60\" /><use transform=\"translate(330, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light a8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"15\" /><use transform=\"translate(15, 15)\" xlink:href=\"#black-rook\" /><rect class=\"square dark b8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"15\" /><use transform=\"translate(60, 15)\" xlink:href=\"#black-knight\" /><rect class=\"square light c8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"15\" /><use transform=\"translate(105, 15)\" xlink:href=\"#black-bishop\" /><rect class=\"square dark d8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"15\" /><use transform=\"translate(150, 15)\" xlink:href=\"#black-queen\" /><rect class=\"square light e8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"15\" /><use transform=\"translate(195, 15)\" xlink:href=\"#black-king\" /><rect class=\"square dark f8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"15\" /><use transform=\"translate(240, 15)\" xlink:href=\"#black-bishop\" /><rect class=\"square light g8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"15\" /><use transform=\"translate(285, 15)\" xlink:href=\"#black-knight\" /><rect class=\"square dark h8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"15\" /><use transform=\"translate(330, 15)\" xlink:href=\"#black-rook\" /><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 0) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 375) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 0) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 375) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 0) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 375) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 0) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 375) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 0) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 375) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 0) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 375) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 0) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 375) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 0) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 375) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
      ],
      "text/plain": [
       "Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Chess_Environment(gym.Env):\n",
    "    \"\"\"Chess Environment\"\"\"\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "        self.white_pieces = ['P', 'N', 'B', 'R', 'Q', 'K']\n",
    "        self.black_pieces = [piece.lower() for piece in self.white_pieces]\n",
    "        self.x_coords, self.y_coords = np.meshgrid(list(range(0, 8)), list(range(0, 8)))\n",
    "        self.x_coords = self.x_coords / 7\n",
    "        self.y_coords = self.y_coords / 7\n",
    "        self.state_size = self.observe()[0].shape\n",
    "        self.init_action_decoder()\n",
    "        self.whites_turn = True\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment\"\"\"\n",
    "        self.board = chess.Board()\n",
    "        \n",
    "    def terminal_test(self):\n",
    "        \"\"\"Checks if the game is over\"\"\"\n",
    "        return self.board.is_game_over(claim_draw = True)\n",
    "    \n",
    "    def result(self):\n",
    "        \"\"\"Gives the end game result\"\"\"\n",
    "\n",
    "        result = self.board.result(claim_draw = True)\n",
    "        if result == '1-0':\n",
    "            return 1\n",
    "        elif result == '0-1':\n",
    "            return -1\n",
    "        elif result == '1/2-1/2':\n",
    "            return 0\n",
    "        elif result == '*':\n",
    "            return 0\n",
    "        else:\n",
    "            raise Exception('Invalid Result', result)\n",
    "        \n",
    "    def legal_actions(self):\n",
    "        \"\"\"Provides a list of legal actions in current state\"\"\"\n",
    "        legal_actions = [str(legal_action) for legal_action in list(self.board.legal_moves)]\n",
    "        return legal_actions\n",
    "    \n",
    "    def encode(self):\n",
    "        \"\"\"Encodes game state into a string\"\"\"\n",
    "        board_ = self.board.piece_map()\n",
    "            \n",
    "        encoded = {\n",
    "            'board' : board_,\n",
    "            'turn' : self.board.turn,\n",
    "            'legal_actions' : self.legal_actions()\n",
    "        }\n",
    "        \n",
    "        return pickle.dumps(encoded)\n",
    "    \n",
    "    def decode(self, encoded):\n",
    "        \"\"\"Decodes string into game state and sets board and turn\"\"\"\n",
    "        decoded = pickle.loads(encoded)\n",
    "        self.board.set_piece_map(decoded['board'])\n",
    "        if decoded['turn'] == False:\n",
    "            self.board = self.board.mirror()\n",
    "        self.board.turn = decoded['turn']\n",
    "\n",
    "    def observe(self):\n",
    "        \"\"\"Create observation from the game state\"\"\"\n",
    "\n",
    "        board_ = copy(self.board)\n",
    "            \n",
    "        board_ = np.ndarray.flatten(np.array(board_.__str__().split())).reshape(8, 8)\n",
    "        \n",
    "        black_pawns = np.isin(copy(board_), ['p']).astype(int)\n",
    "        black_knights = np.isin(copy(board_), ['n']).astype(int)\n",
    "        black_rooks = np.isin(copy(board_), ['r']).astype(int)\n",
    "        black_bishops = np.isin(copy(board_), ['b']).astype(int)\n",
    "        black_queen = np.isin(copy(board_), ['q']).astype(int)\n",
    "        black_king = np.isin(copy(board_), ['k']).astype(int)\n",
    "         \n",
    "        white_pawns = np.isin(copy(board_), ['P']).astype(int)\n",
    "        white_knights = np.isin(copy(board_), ['N']).astype(int)\n",
    "        white_rooks = np.isin(copy(board_), ['R']).astype(int)\n",
    "        white_bishops = np.isin(copy(board_), ['B']).astype(int)\n",
    "        white_queen = np.isin(copy(board_), ['Q']).astype(int)\n",
    "        white_king = np.isin(copy(board_), ['K']).astype(int)\n",
    "        \n",
    "        state = np.array([\n",
    "            white_pawns,\n",
    "            white_knights,\n",
    "            white_rooks,\n",
    "            white_bishops,\n",
    "            white_queen,\n",
    "            white_king,\n",
    "            black_pawns,\n",
    "            black_knights,\n",
    "            black_rooks,\n",
    "            black_bishops,\n",
    "            black_queen,\n",
    "            black_king\n",
    "        ])\n",
    "        \n",
    "        return state, self.legal_actions()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Perform a step in the environment\"\"\"\n",
    "        try:\n",
    "            self.board.push_uci(action)\n",
    "        except ValueError:\n",
    "#             print(f\"INVALID ACTION {action}.\\nSELECTING A RANDOM ACTION FROM LEGAL ACTIONS\\n{self.legal_actions()}\")\n",
    "            actions = random.choices(self.legal_actions())\n",
    "            self.board.push_uci(actions[0])\n",
    "            \n",
    "        self.board = self.board.mirror()\n",
    "        if self.whites_turn:\n",
    "            self.whites_turn = False\n",
    "        else:\n",
    "            self.whites_turn = True\n",
    "        return self.observe()\n",
    "    \n",
    "    def move_board(self, move):\n",
    "        \"\"\"Moves the board positions as per the move\"\"\"\n",
    "\n",
    "        char_to_int = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8} \n",
    "\n",
    "        int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "\n",
    "        encoded_board = [(char_to_int[pos[0]], int(pos[1])) for pos in np.ndarray.flatten(BOARD)]\n",
    "\n",
    "        new_board = [tuple(map(sum, zip((char_to_int[pos[0]], int(pos[1])), move))) for pos in np.ndarray.flatten(BOARD)]\n",
    "        moves = []\n",
    "        for pos, new_pos in zip(np.ndarray.flatten(BOARD), new_board):\n",
    "            try:\n",
    "                if new_pos[1] > 8:\n",
    "                    raise Exception()\n",
    "                if move[2] is None:\n",
    "                    move_ = f'{pos}{int_to_char[new_pos[0]]}{new_pos[1]}'\n",
    "                else:\n",
    "                    move_ = f'{pos}{int_to_char[new_pos[0]]}{new_pos[1]}{move[2]}'\n",
    "            \n",
    "                if '-' in move_:\n",
    "                    raise Exception()\n",
    "            \n",
    "                if '0' in move_:\n",
    "                    raise Exception()\n",
    "                \n",
    "            except Exception:\n",
    "                move_ = 'XXXX'\n",
    "            moves.append(move_)   \n",
    "        return np.array(moves).reshape(8, 8)\n",
    "    \n",
    "    def init_action_decoder(self):\n",
    "        \"\"\"Initialize the decoder to decode the actions\"\"\"\n",
    "        decoder = []\n",
    "        for key in MOVES.keys():\n",
    "            decoder_ = self.move_board(MOVES[key])\n",
    "            decoder.append(decoder_)\n",
    "#             print(f'Move {key}\\n', new_board, '\\n')\n",
    "    \n",
    "        self.decoder = np.array(decoder)\n",
    "        self.action_size = self.decoder.shape\n",
    "        \n",
    "    def select_action(self, logits):\n",
    "        \"\"\"Decodes the output from the NN to legal actions\"\"\" \n",
    "        decoder_ = np.ndarray.flatten(self.decoder)\n",
    "        logits_ = np.ndarray.flatten(logits)\n",
    "\n",
    "        move_logits = [(decoder_[idx].lower(), logits_[idx]) for idx in range(len(logits_))]\n",
    "        move_logits = dict(move_logits)\n",
    "        \n",
    "        legal_move_logits = {legal_action: move_logits[legal_action] for legal_action in self.legal_actions()}\n",
    "        probabilities = list(legal_move_logits.values()) / sum(list(legal_move_logits.values()))\n",
    "\n",
    "        action = random.choices(list(legal_move_logits.keys()), weights = probabilities, k = 1)[0]\n",
    "        return action\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Render chess board\"\"\"\n",
    "        chess.svg.board(board = self.board)  \n",
    "\n",
    "env = Chess_Environment()\n",
    "env.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicReplayBuffer:\n",
    "    \"\"\"\n",
    "    Holds the agents episodes in memory\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        self.capacity = params['capacity']\n",
    "        self.memory = deque(maxlen = self.capacity)\n",
    "        self.gamma = params['gamma']\n",
    "\n",
    "    def add(self, episodes):\n",
    "        \"\"\"\n",
    "        Stores the episodes in the replay buffer\n",
    "        \"\"\"\n",
    "        for episode in episodes:\n",
    "            if episode is not None:\n",
    "                self.memory.append(episode)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        \"\"\"\n",
    "        Return a sample of size of batch size as an experience tuple.\n",
    "        \"\"\"\n",
    "        if len(self.memory) == 0:\n",
    "            return None\n",
    "        if len(self.memory) >= sample_size:\n",
    "            batch = random.sample(self.memory, k = sample_size)\n",
    "        else:\n",
    "            batch = random.sample(self.memory, k = len(self.memory))\n",
    "#         state, actions, returns_, dones = zip(*batch)\n",
    "\n",
    "#         # Stacks the experiences \n",
    "#         # Get inputs into correct shape\n",
    "#         states = torch.tensor(state).float().to(self.device)\n",
    "# #         actions = torch.stack(actions).to(self.device)\n",
    "#         returns_ = torch.tensor(returns_).float().to(self.device)\n",
    "#         dones = torch.tensor(dones).float().to(self.device)\n",
    "       \n",
    "        # print(\"SAMPLE | STATES\", states.shape, \"ACTIONS\", actions.shape, \"P VECTORS\", portfolio_vectors.shape,\"NEXT STATES\", next_states.shape, \"REWARDS\", rewards.shape, \"DONES\", dones.shape)\n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def reset_memory(self):\n",
    "        \"\"\"Resets the replay buffer\"\"\"\n",
    "        self.memory = deque(maxlen = self.capacity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Running on cuda\n",
      "\n",
      "CNN_AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (enc_linear): Linear(in_features=512, out_features=300, bias=True)\n",
      "  (dec_linear): Linear(in_features=300, out_features=512, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): ConvTranspose2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "MDN_RNN(\n",
      "  (lstm): LSTM(338, 150, batch_first=True)\n",
      "  (fc1): Linear(in_features=150, out_features=900, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=900, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=900, bias=True)\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "Policy_Controller(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=450, out_features=1200, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(1200, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 76, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(76, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "Value_Controller(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=450, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, decoder, action_size, vae, mdn, controller, test_mode = False, batch_size = 128, lr = 1e-4, legal_multiplier = 3, save_freq = 8, train_times = 4, lambda_ = 0.9, gamma = 0.98):\n",
    "        self.batch_size = batch_size\n",
    "        self.action_size = action_size\n",
    "        self.trained_times = 0\n",
    "        self.train_times = train_times\n",
    "        self.lambda_ = lambda_\n",
    "        self.gamma = gamma\n",
    "        self.legal_multiplier = legal_multiplier # To increase the value of legal actions and MCTS insight as the target policy\n",
    "        self.decoder = decoder\n",
    "        self.save_freq = save_freq\n",
    "        if vae is not None:\n",
    "            self.vae = CNN_AE(vae, None, 'Latest')\n",
    "            self.vae.eval()\n",
    "        if mdn is not None:\n",
    "            self.mdn = MDN_RNN(mdn, None, 'Latest')\n",
    "            self.mdn.eval()\n",
    "            params = {\n",
    "                'hidden_size' : self.mdn.hidden_size,\n",
    "                'z_size' : self.vae.z_size,\n",
    "                'action_size' : action_size,\n",
    "                'expansion_size': 1200\n",
    "            }\n",
    "\n",
    "            if test_mode:\n",
    "                self.actor = Policy_Controller(controller, None, 'Latest')\n",
    "                self.critic = Value_Controller(controller, None, 'Latest')\n",
    "            else:\n",
    "                self.actor = Policy_Controller(controller, params, False)\n",
    "                self.critic = Value_Controller(controller, params, False)\n",
    "                self.actor.save_model(0)\n",
    "                self.critic.save_model(0)\n",
    "        \n",
    "            self.actor_optimizer = Adam(self.actor.parameters(), lr = lr)\n",
    "            self.critic_optimizer = Adam(self.critic.parameters(), lr = lr)\n",
    "        \n",
    "        self.char_to_int = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8} \n",
    "        self.char_to_int_promo = {'r': 1, 'b': 2, 'q': 3, 'k': 4, 'n': 5, '': 6} \n",
    "        \n",
    "        moves_df = pd.DataFrame(list(zip(self.char_to_int.values(), self.char_to_int.keys())), columns = ['Ids', 'Labels'])\n",
    "        promo_df = pd.DataFrame(list(zip(self.char_to_int_promo.values(), self.char_to_int_promo.keys())), columns = ['Ids', 'Labels'])\n",
    "        self.move_actions_ohe = pd.get_dummies(moves_df['Ids'])\n",
    "        self.promo_actions_ohe = pd.get_dummies(promo_df['Ids'])\n",
    "        \n",
    "        self.criterion_pi = nn.NLLLoss()\n",
    "        self.criterion_v = nn.SmoothL1Loss()\n",
    "    \n",
    "    def select_action(self, logits, legal_actions):\n",
    "        \"\"\"Decodes the output from the NN to legal actions\"\"\" \n",
    "        decoder_ = np.ndarray.flatten(self.decoder)\n",
    "        logits_ = np.ndarray.flatten(logits)\n",
    "\n",
    "        move_logits = [(decoder_[idx].lower(), logits_[idx]) for idx in range(len(logits_))]\n",
    "        move_logits = dict(move_logits)\n",
    "        \n",
    "        legal_move_logits = {legal_action: move_logits[legal_action] for legal_action in legal_actions}\n",
    "        probabilities = list(legal_move_logits.values()) / sum(list(legal_move_logits.values()))\n",
    "        \n",
    "        legal_actions = list(legal_move_logits.keys())\n",
    "        action = random.choices(list(legal_move_logits.keys()), weights = probabilities, k = 1)[0]\n",
    "        \n",
    "        action_probabilities = {legal_actions[idx] : probabilities[idx] for idx in range(len(legal_actions))}\n",
    "        return action, action_probabilities\n",
    "    \n",
    "    def one_hot_encode_action(self, action):\n",
    "        \"\"\"One hot encodes the action\"\"\"\n",
    "        if len(action) == 4:\n",
    "            encoded_action = [\n",
    "                self.move_actions_ohe.loc[\n",
    "                self.char_to_int[action[0]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[1]) - 1].values, \n",
    "                self.move_actions_ohe.loc[self.char_to_int[action[2]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[3]) - 1].values,\n",
    "                self.promo_actions_ohe.loc[self.char_to_int_promo[''] - 1].values\n",
    "            ]\n",
    "        else:\n",
    "            encoded_action = [\n",
    "                self.move_actions_ohe.loc[\n",
    "                self.char_to_int[action[0]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[1]) - 1].values, \n",
    "                self.move_actions_ohe.loc[self.char_to_int[action[2]] - 1].values, \n",
    "                self.move_actions_ohe.loc[int(action[3]) - 1].values,\n",
    "                self.promo_actions_ohe.loc[self.char_to_int_promo[action[4]] - 1].values\n",
    "            ]\n",
    "        ohe_action = np.concatenate(encoded_action)\n",
    "        return ohe_action\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        \"\"\"Resets the MDNs hidden state\"\"\"\n",
    "        self.hidden = self.mdn.init_hidden(batch_size)\n",
    "        self.hidden = (self.hidden[0].detach().to('cpu'), self.hidden[1].detach().to('cpu'))\n",
    "        \n",
    "    def act(self, state, legal_actions):\n",
    "        \"\"\"Gets an action from the agent\"\"\"\n",
    "        state = torch.tensor(state).float().unsqueeze(0)\n",
    "        z = self.vae.encode(state)\n",
    "    \n",
    "        zh = torch.cat((z.to('cpu'), self.hidden[0].squeeze(0).to('cpu')), dim = 1)\n",
    "        if zh.shape[0] > 1:\n",
    "            raise Exception('Batch size > 1 not handled')\n",
    "            \n",
    "        logits = self.actor(zh)\n",
    "        values = self.critic(zh)\n",
    "        logits, value = logits.detach().squeeze(0).cpu().numpy(), values.detach().squeeze(0).cpu().numpy()[0]\n",
    "        action, action_probabilities = self.select_action(logits, legal_actions)\n",
    "        \n",
    "        return action_probabilities, value, z\n",
    "    \n",
    "    def encode_z(self, state):\n",
    "        \"\"\"Encodes the state using the autoencoder\"\"\"\n",
    "        state = torch.tensor(state).float().unsqueeze(0)\n",
    "        return self.vae.encode(state)\n",
    "    \n",
    "    def train(self, episodes):\n",
    "        \"\"\"Trains the controller from the MCTS experiences\"\"\"\n",
    "        all_zh = []\n",
    "        all_returns = []\n",
    "        all_mcts_action_probs = []\n",
    "#         batches = [experiences[i : i + self.batch_size] for i in range(0, len(experiences), self.batch_size)]\n",
    "        for idx, episode in enumerate(episodes):\n",
    "            zh, mcts_action_probs, rewards, masks = zip(*episode)\n",
    "            \n",
    "            zh_ = torch.tensor(zh).float().unsqueeze(1)\n",
    "            values = self.critic(zh_.to(self.critic.device))\n",
    "            \n",
    "            # Calculate GAE\n",
    "            returns = []\n",
    "            values_ = list(values.view(-1).detach().cpu().numpy())\n",
    "            gae = 0\n",
    "\n",
    "            for i in reversed(range(len(rewards))):\n",
    "                if i == len(rewards) - 1:\n",
    "                    delta = rewards[i] - values[i]\n",
    "                else:\n",
    "                    delta = rewards[i] + self.gamma * values[i + 1] * masks[i] - values[i]\n",
    "                gae = delta + self.gamma * self.lambda_ * masks[i] * gae\n",
    "                returns.insert(0, gae + values[i])\n",
    "            all_returns.extend(returns)\n",
    "            all_zh.extend(list(zh))\n",
    "            all_mcts_action_probs.extend([x for x in mcts_action_probs])\n",
    "            \n",
    "#         all_returns = [item for sublist in all_returns for item in sublist]\n",
    "#         all_zh = [item for sublist in all_zh for item in sublist]\n",
    "#         all_mcts_action_probs = [item for sublist in all_mcts_action_probs for item in sublist]\n",
    "        \n",
    "        # Trains on random experiences to decoralate the information\n",
    "        idxs = random.choices(range(len(all_zh)), k = self.batch_size)\n",
    "        mcts_action_probs = [all_mcts_action_probs[idx] for idx in idxs]\n",
    "        returns = torch.stack([torch.tensor(all_returns[idx]).float() for idx in idxs]).to(self.critic.device)\n",
    "        actor_zh = torch.stack([torch.tensor(all_zh[idx]).float() for idx in idxs]).to(self.actor.device)\n",
    "        critic_zh = actor_zh.clone().to(self.critic.device)\n",
    "        \n",
    "        logits = self.actor(actor_zh)\n",
    "        values = self.critic(critic_zh)\n",
    "                              \n",
    "        self.actor_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "#             print(zh.is_cuda, type(zh))\n",
    "        improvement_estimate = self.improvement_estimate(logits, mcts_action_probs)\n",
    "        epsilon = 1e-7\n",
    "#             print(logits.shape, torch.log(logits + epsilon))\n",
    "#             print(improvement_estimate.shape, improvement_estimate)\n",
    "            \n",
    "        actor_losses = -improvement_estimate * torch.log(logits + epsilon)\n",
    "        critic_losses = (returns.view(-1) - values.view(-1)).pow(2)\n",
    "            \n",
    "#             print(actor_losses)\n",
    "#             print(\"IMP EST\", improvement_estimate.shape, \"LOGITS\", logits.shape, \"ACTOR LOSS\", actor_losses.shape)\n",
    "#             print(\"RETURNS\", returns.view(-1).shape, \"VALUES\", values.view(-1).shape, \"CRITIC LOSS\", critic_losses.shape)\n",
    "\n",
    "            \n",
    "#             for idx in range(logits.shape[0]):\n",
    "#                 advantage = returns[idx] - values[idx]\n",
    "#                 # converts logits to action probabilities\n",
    "# #                 print(values[idx].squeeze(0).shape, returns[idx].shape)\n",
    "# #                 print(values[idx].squeeze(0), returns[idx])\n",
    "#                 policy_losses.append(-F.softmax(logits[idx], dim = 0) * advantage)\n",
    "#                 value_losses.append(F.smooth_l1_loss(values[idx].squeeze(0), returns[idx]))\n",
    "            \n",
    "            # sum up all the values of policy_losses and value_losses\n",
    "        actor_loss = actor_losses.sum()\n",
    "#             critic_loss = critic_losses.sum()\n",
    "        critic_loss = critic_losses.sum()\n",
    "            \n",
    "#             writer.add_scalar('policy_loss', policy_loss, writer.games)\n",
    "#             writer.add_scalar('value_loss_loss', value_loss, writer.games)\n",
    "#             loss = policy_loss + value_loss\n",
    "            \n",
    "        print(\"ACTOR LOSS\", actor_loss.item(), \"| CRITIC LOSS\", critic_loss.item())\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "        if self.trained_times % self.save_freq == 0:\n",
    "            print(\"SAVING\")\n",
    "            self.actor.save_model(self.trained_times)\n",
    "            self.critic.save_model(self.trained_times)\n",
    "        self.trained_times += 1\n",
    "        \n",
    "    def load_hidden(self, hidden):\n",
    "        \"\"\"Loads the hidden state to the MDN RNN\"\"\"\n",
    "        self.hidden = deepcopy(hidden)\n",
    "        \n",
    "    def get_hidden(self):\n",
    "        \"\"\"Gets the hidden state from the MDN RNN\"\"\"\n",
    "        return deepcopy(self.hidden)\n",
    "    \n",
    "    def random_controller(self): \n",
    "        \"\"\"Updates the controller from a randomly selected save file\"\"\"\n",
    "        path = f'checkpoints_/{self.actor.type}/{self.actor.name}/'\n",
    "        list_of_files = [x for x in os.listdir(path) if '.pth' in x]\n",
    "        file_name = random.choice(list_of_files)\n",
    "        print(f'Loading Random Controllers {file_name}')\n",
    "        \n",
    "        self.actor.load_model(file_name)\n",
    "        self.critic.load_model(file_name)\n",
    "        \n",
    "    def step(self, z, action):\n",
    "        \"\"\"Updates the hidden state of the MDN-RNN\"\"\"\n",
    "        z.squeeze_(-1)\n",
    "        ohe_action = self.one_hot_encode_action(action)\n",
    "        za = torch.cat((z.to('cpu'), torch.tensor(ohe_action).float().to('cpu').unsqueeze(0)), dim = 1)\n",
    "        _, self.hidden = self.mdn(za.unsqueeze(1), self.hidden)\n",
    "        self.hidden = (self.hidden[0].detach().to('cpu'), self.hidden[1].detach().to('cpu'))\n",
    "        \n",
    "                \n",
    "    def improvement_estimate(self, logits, legal_move_logits):\n",
    "        \"\"\"Create an improvement estimate by layering the insights from MCTS\"\"\"\n",
    "        new_boards__ = [[x.lower() for x in list(np.ndarray.flatten(self.decoder))] for _ in range(logits.shape[0])]\n",
    "        improve_est = []\n",
    "        for idx in range(logits.shape[0]):\n",
    "            new_boards___ = new_boards__[idx]\n",
    "            improve_est__ = logits[idx].clone().view(-1)\n",
    "            improve_est__.data.fill_(0)\n",
    "            legal_move_logits__ = {k.lower(): v * self.legal_multiplier for k, v in legal_move_logits[idx].items()}\n",
    "            for move, legal_move_logit in legal_move_logits__.items():\n",
    "                index = new_boards___.index(move)\n",
    "                improve_est__[index] += legal_move_logit\n",
    "            improve_est.append(improve_est__.reshape(76, 8, 8))\n",
    "        return torch.stack(improve_est)\n",
    "    \n",
    "agent = Agent(env.decoder, env.action_size, 'Test', 'Test', 'Test', test_mode = False)\n",
    "agent.reset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Coach():\n",
    "#     \"\"\"\n",
    "#     This class executes the self-play + learning. It uses the functions defined\n",
    "#     in Game and NeuralNet. args are specified in main.py.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, env, agent, params):\n",
    "#         self.iterations = params['iterations']\n",
    "#         self.episodes = params['episodes']\n",
    "#         self.queue_length = params['queue_length']\n",
    "#         self.simulations = params['simulations']\n",
    "#         self.train_times = params['train_times']\n",
    "#         self.memory_samples = params['memory_samples']\n",
    "#         self.env = deepcopy(env)\n",
    "#         self.agent = agent\n",
    "#         self.trainExamplesHistory = []  # history of examples from args.numItersForTrainExamplesHistory latest iterations\n",
    "#         self.games = 0\n",
    "#         params = {\n",
    "#             'capacity' : 70,\n",
    "#             'gamma' : 0.98\n",
    "#         } \n",
    "        \n",
    "#         self.memory = EpisodicReplayBuffer(params)\n",
    "    \n",
    "#     @ray.remote\n",
    "#     def execute_episode(self, agent, game):\n",
    "#         \"\"\"\n",
    "#         This function executes one episode of self-play, starting with player 1.\n",
    "#         As the game is played, each turn is added as a training example to\n",
    "#         trainExamples. The game is played till the game ends. After the game\n",
    "#         ends, the outcome of the game is used to assign values to each example\n",
    "#         in trainExamples.\n",
    "#         It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "#         uses temp=0.\n",
    "#         Returns:\n",
    "#             trainExamples: a list of examples of the form (canonicalBoard, currPlayer, pi,v)\n",
    "#                            pi is the MCTS informed policy vector, v is +1 if\n",
    "#                            the player eventually won the game, else -1.\n",
    "#         \"\"\"\n",
    "#         env = Chess_Environment()\n",
    "#         experiences = []\n",
    "#         agent.reset(1)\n",
    "#         mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = self.simulations)\n",
    "#         mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = self.simulations)  \n",
    "#         mcts_black.agent.random_controller()\n",
    "        \n",
    "#         # RESET HIDDEN STATES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#         game_move = 0\n",
    "        \n",
    "#         terminal_test = env.terminal_test()\n",
    "#         while not terminal_test:\n",
    "#             encoded_state = env.encode()\n",
    "#             if env.whites_turn: \n",
    "#                 action_probs, zh = mcts_white.action_probabilities(encoded_state)\n",
    "#             else:\n",
    "#                 action_probs, zh = mcts_black.action_probabilities(encoded_state)\n",
    "\n",
    "#             if env.whites_turn:\n",
    "#                 experiences.append([zh.detach().cpu().numpy(), action_probs, 1, terminal_test]) # mask is 'not done'\n",
    "#             action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "#             _, _ = env.step(action)\n",
    "    \n",
    "#             game_move += 1\n",
    "#             terminal_test = env.terminal_test()\n",
    "        \n",
    "#         reward = env.result()\n",
    "#         if not env.whites_turn and ((reward == 1) or (reward == -1)):\n",
    "#             reward = reward * -1\n",
    "        \n",
    "#         experiences[-1][-1] = 0 # mask is 'not done'\n",
    "#         experiences[-1][-2] = reward\n",
    "        \n",
    "#         if reward == -1:\n",
    "#             print(f\"Game {game} White Loss\")\n",
    "#         elif reward == 1:\n",
    "#             print(f\"Game {game} White Won\")\n",
    "#         else:\n",
    "#             print(f\"Game {game} Draw\")\n",
    "#             print(\"WARNING DELETING EXPERIENCES\")\n",
    "#             return None\n",
    "            \n",
    "        \n",
    "\n",
    "#         return experiences\n",
    "    \n",
    "#     def learn(self, ray):    \n",
    "# #     def learn(self):\n",
    "#         \"\"\"\n",
    "#         Performs numIters iterations with numEps episodes of self-play in each\n",
    "#         iteration. After every iteration, it retrains neural network with\n",
    "#         examples in trainExamples (which has a maximum length of maxlenofQueue).\n",
    "#         It then pits the new neural network against the old one and accepts it\n",
    "#         only if it wins >= updateThreshold fraction of games.\n",
    "#         \"\"\"\n",
    "        \n",
    "# #         for i in range(1, self.iterations + 1):\n",
    "#         episodes = ray.get([self.execute_episode.remote(self, self.agent, self.games + idx) for idx in range(self.episodes)])\n",
    "# #         episodes = [self.execute_episode(self.agent, self.games + idx) for idx in range(self.episodes)]\n",
    "#         self.games += len(episodes)\n",
    "        \n",
    "#         if episodes is not None:\n",
    "#             self.memory.add(episodes)\n",
    "#         for _ in range(self.train_times):\n",
    "#             episodes = self.memory.sample(self.memory_samples)\n",
    "#             if episodes is not None:\n",
    "#                 self.agent.train(episodes)\n",
    "\n",
    "# #         # training new network, keeping a copy of the old one\n",
    "# #         self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         pmcts = MCTS(self.game, self.pnet, self.args)\n",
    "\n",
    "# #         \n",
    "# #         nmcts = MCTS(self.game, self.nnet, self.args)\n",
    "\n",
    "# #         log.info('PITTING AGAINST PREVIOUS VERSION')\n",
    "# #         arena = Arena(lambda x: np.argmax(pmcts.getActionProb(x, temp=0)),\n",
    "# #                           lambda x: np.argmax(nmcts.getActionProb(x, temp=0)), self.game)\n",
    "# #         pwins, nwins, draws = arena.playGames(self.args.arenaCompare)\n",
    "\n",
    "# #         log.info('NEW/PREV WINS : %d / %d ; DRAWS : %d' % (nwins, pwins, draws))\n",
    "# #         if pwins + nwins == 0 or float(nwins) / (pwins + nwins) < self.args.updateThreshold:\n",
    "# #             log.info('REJECTING NEW MODEL')\n",
    "# #             self.nnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         else:\n",
    "# #             log.info('ACCEPTING NEW MODEL')\n",
    "# #             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename=self.getCheckpointFile(i))\n",
    "# #             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='best.pth.tar')\n",
    "        \n",
    "\n",
    "# # params = {\n",
    "# #     'iterations': 1,\n",
    "# #     'episodes': 16,\n",
    "# #     'queue_length' : 2000,\n",
    "# #     'simulations' : 200,\n",
    "# #     'train_times' : 10,\n",
    "# #     'memory_samples' : 32\n",
    "# # }\n",
    "\n",
    "# # coach = Coach(env, agent, params)\n",
    "# # for _ in range(1000):\n",
    "# #     coach.learn(ray)\n",
    "# # #     coach.learn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPHA GO TIPS \n",
    "\n",
    "\n",
    "## MCTS\n",
    "Each simulation proceeds by\n",
    "selecting in each state s a move a with low visit count, high move probability and high value\n",
    "(averaged over the leaf states of simulations that selected a from s) according to the current\n",
    "neural network f. The search returns a vector  representing a probability distribution over\n",
    "moves, either proportionally or greedily with respect to the visit counts at the root state.\n",
    "The parameters  of the deep neural network in AlphaZero are trained by self-play reinforcement learning, starting from randomly initialised parameters . Games are played by selecting\n",
    "moves for both players by MCTS, at  t\n",
    ". At the end of the game, the terminal position sT is\n",
    "scored according to the rules of the game to compute the game outcome z: 1 for a loss, 0 for\n",
    "a draw, and +1 for a win. The neural network parameters  are updated so as to minimise the\n",
    "error between the predicted outcome vt and the game outcome z, and to maximise the similarity\n",
    "of the policy vector pt\n",
    "to the search probabilities t\n",
    ". Specifically, the parameters  are adjusted\n",
    "by gradient descent on a loss function l that sums over mean-squared error and cross-entropy\n",
    "losses respectively\n",
    "\n",
    "(p, v) = f(s)                    \n",
    "\n",
    "l = (z  v) 2   > log p + c||||2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MCTS():\n",
    "#     \"\"\"Monte Carlo Tree Search Algorithm geared for Neural Networks\"\"\"\n",
    "\n",
    "#     def __init__(self, env, agent, mcts_simulations = 100, max_depth = 100, delta = 0.5):\n",
    "#         self.env = env\n",
    "#         self.agent = agent\n",
    "#         self.cpuct = 1.5    # WARNING BULLSHIT NUMBER!\n",
    "#         self.delta = delta  # value to prevent crash if no edges are visited\n",
    "#         self.mcts_simulations = mcts_simulations\n",
    "#         self.max_depth = max_depth\n",
    "        \n",
    "#         self.Qsa = {}       # stores Q values for s, a (as defined in the paper)\n",
    "#         self.Nsa = {}       # stores # times edge s, a was visited\n",
    "#         self.Ns = {}        # stores # times board s was visited\n",
    "#         self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "#         self.Es = {}        # stores victory result (1, 0, -1) ended for board s\n",
    "#         self.Vs = {}        # stores legal actions for board s\n",
    "#         self.z = {}         # stores the features of the state\n",
    "#         self.hidden = {}    # stores the hidden states\n",
    "\n",
    "#     def action_probabilities(self, encoded_state, temp = 1):\n",
    "#         \"\"\"\n",
    "#         This function performs numMCTSSims simulations of MCTS starting from\n",
    "#         canonicalBoard.\n",
    "#         Returns:\n",
    "#             probs: a policy vector where the probability of the ith action is\n",
    "#                    proportional to Nsa[(s,a)]**(1./temp)\n",
    "#         \"\"\"\n",
    "#         for runs in range(self.mcts_simulations):\n",
    "# #             print(f\"{Fore.BLUE}MCTS SIMULATION {runs + 1}{Style.RESET_ALL}\")\n",
    "#             self.search(encoded_state, 0)\n",
    "        \n",
    "#         s = encoded_state\n",
    "#         self.env.decode(encoded_state)\n",
    "#         legal_actions = self.env.legal_actions()\n",
    "#         counts = [self.Nsa[(s,a)] if (s,a) in self.Nsa else 0 for a in legal_actions]\n",
    "#         # counts array represent the number of time each action edge from your current state was traversed\n",
    "        \n",
    "#         # temprature is 0 representing taking the best action possible (greedy)\n",
    "#         if temp == 0: \n",
    "#             # bestA: best action number : argmax Returns the indices of the maximum values\n",
    "#             bestA = np.argmax(counts) \n",
    "#             probs = [0] * len(counts)\n",
    "#             probs[bestA] = 1\n",
    "#             action_probs = {legal_actions[idx] : probs[idx] for idx in range(len(legal_actions))}\n",
    "#             # returns the definite move(s) with same greedy reward, out of which one move HAS to be played\n",
    "#             return action_probs \n",
    "        \n",
    "# #         print(f\"{Fore.BLUE}COUNTS {sum(counts)} {counts}{Style.RESET_ALL}\")\n",
    "        \n",
    "#         # Handles frequent draw situation when MCTS fails to explore when the game is over resulting 0 counts causing div 0 error\n",
    "#         if sum(counts) == 0:\n",
    "#             counts = [1 for _ in counts]\n",
    "            \n",
    "#         counts = [x ** (1. / temp) + 0.5 for x in counts]\n",
    "#         probs = [x / float(sum(counts)) for x in counts]\n",
    "#         action_probs = {legal_actions[idx] : probs[idx] for idx in range(len(legal_actions))}\n",
    "#         zh = torch.cat((self.z[s].to('cpu'), self.hidden[s][0].squeeze(0).to('cpu')), dim = 1)\n",
    "# #         print(zh)\n",
    "#         return action_probs, zh\n",
    "#         #returns the probablity of different moves that CAN be played resulting in uniform distribution\n",
    "\n",
    "\n",
    "#     def search(self, encoded_state, depth):\n",
    "#         \"\"\"\n",
    "#         This function performs one iteration of MCTS. It is recursively called\n",
    "#         till a leaf node is found. The action chosen at each node is one that\n",
    "#         has the maximum upper confidence bound as in the paper.\n",
    "#         Once a leaf node is found, the neural network is called to return an\n",
    "#         initial policy P and a value v for the state. This value is propogated\n",
    "#         up the search path. In case the leaf node is a terminal state, the\n",
    "#         outcome is propogated up the search path. The values of Ns, Nsa, Qsa are\n",
    "#         updated.\n",
    "#         NOTE: the return values are the negative of the value of the current\n",
    "#         state. This is done since v is in [-1,1] and if v is the value of a\n",
    "#         state for the current player, then its value is -v for the other player.\n",
    "#         Returns:\n",
    "#             v: the negative of the value of the current canonicalBoard\n",
    "#         \"\"\"\n",
    "\n",
    "#         s = deepcopy(encoded_state)\n",
    "#         self.env.decode(encoded_state)\n",
    "# #         print(f\"{Fore.GREEN}SEARCH DEPTH {depth}{Style.RESET_ALL}\")\n",
    "        \n",
    "#         # Check if its an terminal state, -1 Opponent Won, 0 Game not Over, 1 Player Won\n",
    "#         if s not in self.Es:\n",
    "#             self.Es[s] = self.env.result()\n",
    "        \n",
    "#         # Handles the maintaining of the MDNs hidden states\n",
    "#         if s not in self.hidden:\n",
    "#             self.hidden[s] = self.agent.get_hidden()\n",
    "#         else:\n",
    "#             self.agent.load_hidden(self.hidden[s])\n",
    "        \n",
    "#         # Checks if the game is over and returns the respective value\n",
    "#         if self.env.terminal_test():\n",
    "#             state, _ = self.env.observe()\n",
    "#             self.z[s] = self.agent.encode_z(state)\n",
    "            \n",
    "# #             print(\"SIMULATION OVER!\", self.env.terminal_test(), -self.Es[s], self.env.board.result())\n",
    "#             return -self.Es[s]          \n",
    "        \n",
    "#         state, legal_actions = self.env.observe()\n",
    "\n",
    "#         # if the current state 's' is not explored/expanded before n = 0 by MCTS then create a new node and rollout\n",
    "#         if s not in self.Ps: \n",
    "#             self.Ps[s], v, self.z[s] = self.agent.act(state, legal_actions)\n",
    "# #             print(\"self.Ps[s] at Depth\", depth, \"\\n\", self.Ps[s])\n",
    "#             valids = legal_actions\n",
    "\n",
    "#             self.Vs[s] = valids \n",
    "#             self.Ns[s] = 0\n",
    "# #             print(\"VALUE\", -v)\n",
    "#             return -v\n",
    "\n",
    "#         # as already visited the valid moves array 'Vs' is already initialized\n",
    "#         valids = self.Vs[s] \n",
    "#         cur_best = -float('inf')\n",
    "#         best_act = -1\n",
    "        \n",
    "#         self.env.decode(encoded_state)\n",
    "#         legal_actions = self.env.legal_actions()\n",
    "#         # pick the action with the highest upper confidence bound\n",
    "        \n",
    "#         agent_actions = list(self.Ps[s].keys())\n",
    "        \n",
    "#         # Handles the occasional legal action that isn't an actual legal action\n",
    "#         # Pawn side cut even though there is no enemy piece in respective position\n",
    "# #         print(\"XXXXX PRE LEGAL ACTIONS\\n\", legal_actions)\n",
    "#         if not set(agent_actions) == set(legal_actions):\n",
    "#             legal_actions = agent_actions\n",
    "# #         print(\"XXXXX POST LEGAL ACTIONS\\n\", legal_actions)\n",
    "#         for a in legal_actions:\n",
    "#             if (s,a) in self.Qsa:\n",
    "#                 u = self.Qsa[(s,a)] + self.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (1 + self.Nsa[(s,a)])\n",
    "# #                 print(\"In Qsa\")\n",
    "#             else:\n",
    "#                 self.Ps[s][a] \n",
    "#                 u = self.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s])     # Q = 0 ? : node exists but not explored as added and initilized during nnet phase\n",
    "# #                 print(\"Not In Qsa\", self.Ps[s][a], self.Ns[s], math.sqrt(self.Ns[s]))\n",
    "# #             print(\"U\", u)\n",
    "#             if math.isnan(u):\n",
    "#                 u = 0\n",
    "# #                 print(\"Override U\", u)\n",
    "#             if u > cur_best:\n",
    "#                 cur_best = u\n",
    "#                 best_act = a\n",
    "# #         print(f\"{Fore.GREEN}BEST ACTION {best_act}{Style.RESET_ALL}\")\n",
    "#         a = best_act\n",
    "\n",
    "#         _, _ = self.env.step(a)\n",
    "#         self.agent.step(self.z[s], a)\n",
    "        \n",
    "#         encoded_next_state = self.env.encode()\n",
    "\n",
    "#         v = self.search(encoded_next_state, depth + 1) # RECURSION until leaf node or terminal node is found\n",
    "        \n",
    "#         self.env.decode(encoded_state)\n",
    "        \n",
    "#         if (s,a) in self.Qsa:\n",
    "#             self.Qsa[(s,a)] = (self.Nsa[(s,a)] * self.Qsa[(s,a)] + v) / (self.Nsa[(s,a)] + 1) #update the Q Value\n",
    "#             self.Nsa[(s,a)] += 1 # increment number of visits to this node in MCTS\n",
    "#         else:\n",
    "#             self.Qsa[(s,a)] = v # initialize the new node\n",
    "#             self.Nsa[(s,a)] = 1\n",
    "\n",
    "#         self.Ns[s] += 1\n",
    "#         return -v\n",
    "    \n",
    "#     def reset(self):\n",
    "#         \"\"\"Resets the tracked information\"\"\"\n",
    "#         self.Qsa = {}       \n",
    "#         self.Nsa = {}       \n",
    "#         self.Ns = {}        \n",
    "#         self.Ps = {}       \n",
    "#         self.Es = {}\n",
    "#         self.Vs = {}  \n",
    "#         self.zh = {}\n",
    "#         self.hidden = {}\n",
    "#         self.agent.reset(1)\n",
    "#         self.env.reset()\n",
    "\n",
    "# # for _ in range(5):\n",
    "# #     env.reset()\n",
    "# #     mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# #     mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# #     game_move = 0\n",
    "# #     while not env.terminal_test():\n",
    "# #     #     print(f\"{Fore.RED}GAME MOVE {game_move}{Style.RESET_ALL}\")\n",
    "# #         encoded_state = env.encode()\n",
    "# #         if env.whites_turn: \n",
    "# #             action_probs, zh = mcts_white.action_probabilities(encoded_state)\n",
    "# #         else:\n",
    "# #             action_probs, zh = mcts_black.action_probabilities(encoded_state)\n",
    "        \n",
    "        \n",
    "# # #         print(game_move, env.whites_turn, env.terminal_test(), type(zh))\n",
    "# # #         if zh == None:\n",
    "# # #             print(encoded_state)\n",
    "# #         action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "# # #         print(f\"{Fore.CYAN}ACTUAL MOVE\\n {action_probs}{Style.RESET_ALL}\")\n",
    "# #         _, _ = env.step(action)\n",
    "    \n",
    "# #         game_move += 1    \n",
    "# #     print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! GAME COMPLETED !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # COPY THIS\n",
    "# # https://github.com/suragnair/alpha-zero-general/blob/master/Coach.py\n",
    "\n",
    "# env.reset()\n",
    "# mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = 20)\n",
    "# game_move = 0\n",
    "\n",
    "# while not env.terminal_test():\n",
    "#     print(f\"{Fore.RED}GAME MOVE {game_move}{Style.RESET_ALL}\")\n",
    "#     encoded_state = env.encode()\n",
    "#     if env.whites_turn: \n",
    "#         action_probs = mcts_white.action_probabilities(encoded_state)\n",
    "#     else:\n",
    "#         action_probs = mcts_black.action_probabilities(encoded_state)\n",
    "#     action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "#     print(f\"{Fore.CYAN}ACTUAL MOVE\\n {action_probs}{Style.RESET_ALL}\")\n",
    "#     _, _ = env.step(action)\n",
    "    \n",
    "#     game_move += 1\n",
    "        \n",
    "# print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! GAME COMPLETED !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.decode(b'\\x80\\x03}q\\x00(X\\x05\\x00\\x00\\x00boardq\\x01}q\\x02(K<cchess\\nPiece\\nq\\x03)\\x81q\\x04}q\\x05(X\\n\\x00\\x00\\x00piece_typeq\\x06K\\x02X\\x05\\x00\\x00\\x00colorq\\x07\\x88ubK9h\\x03)\\x81q\\x08}q\\t(h\\x06K\\x06h\\x07\\x89ubK8h\\x03)\\x81q\\n}q\\x0b(h\\x06K\\x04h\\x07\\x89ubK5h\\x03)\\x81q\\x0c}q\\r(h\\x06K\\x01h\\x07\\x89ubK1h\\x03)\\x81q\\x0e}q\\x0f(h\\x06K\\x01h\\x07\\x89ubK0h\\x03)\\x81q\\x10}q\\x11(h\\x06K\\x01h\\x07\\x89ubK)h\\x03)\\x81q\\x12}q\\x13(h\\x06K\\x01h\\x07\\x88ubK&h\\x03)\\x81q\\x14}q\\x15(h\\x06K\\x01h\\x07\\x89ubK\\x1dh\\x03)\\x81q\\x16}q\\x17(h\\x06K\\x01h\\x07\\x89ubK\\x1ch\\x03)\\x81q\\x18}q\\x19(h\\x06K\\x01h\\x07\\x88ubK\\x1bh\\x03)\\x81q\\x1a}q\\x1b(h\\x06K\\x01h\\x07\\x89ubK\\x1ah\\x03)\\x81q\\x1c}q\\x1d(h\\x06K\\x01h\\x07\\x88ubK\\x19h\\x03)\\x81q\\x1e}q\\x1f(h\\x06K\\x02h\\x07\\x89ubK\\x14h\\x03)\\x81q }q!(h\\x06K\\x03h\\x07\\x89ubK\\x0ch\\x03)\\x81q\"}q#(h\\x06K\\x03h\\x07\\x88ubK\\x08h\\x03)\\x81q$}q%(h\\x06K\\x01h\\x07\\x88ubK\\x06h\\x03)\\x81q&}q\\'(h\\x06K\\x04h\\x07\\x89ubK\\x05h\\x03)\\x81q(}q)(h\\x06K\\x06h\\x07\\x88ubK\\x01h\\x03)\\x81q*}q+(h\\x06K\\x02h\\x07\\x88ubK\\x00h\\x03)\\x81q,}q-(h\\x06K\\x04h\\x07\\x88ubuX\\x04\\x00\\x00\\x00turnq.\\x88X\\r\\x00\\x00\\x00legal_actionsq/]q0u.')\n",
    "# env.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Coach():\n",
    "#     \"\"\"\n",
    "#     This class executes the self-play + learning. It uses the functions defined\n",
    "#     in Game and NeuralNet. args are specified in main.py.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, env, agent, params):\n",
    "#         self.iterations = params['iterations']\n",
    "#         self.episodes = params['episodes']\n",
    "#         self.queue_length = params['queue_length']\n",
    "#         self.env = deepcopy(env)\n",
    "#         self.agent = agent\n",
    "#         self.mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = params['simulations'])\n",
    "#         self.mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = params['simulations'])\n",
    "#         self.trainExamplesHistory = []  # history of examples from args.numItersForTrainExamplesHistory latest iterations\n",
    "#         self.games = 0\n",
    "\n",
    "#     def executeEpisode(self):\n",
    "#         \"\"\"\n",
    "#         This function executes one episode of self-play, starting with player 1.\n",
    "#         As the game is played, each turn is added as a training example to\n",
    "#         trainExamples. The game is played till the game ends. After the game\n",
    "#         ends, the outcome of the game is used to assign values to each example\n",
    "#         in trainExamples.\n",
    "#         It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "#         uses temp=0.\n",
    "#         Returns:\n",
    "#             trainExamples: a list of examples of the form (canonicalBoard, currPlayer, pi,v)\n",
    "#                            pi is the MCTS informed policy vector, v is +1 if\n",
    "#                            the player eventually won the game, else -1.\n",
    "#         \"\"\"\n",
    "#         experiences = []\n",
    "#         self.env.reset()\n",
    "#         # RESET HIDDEN STATES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#         game_move = 0\n",
    "#         while not self.env.terminal_test():\n",
    "#             encoded_state = self.env.encode()\n",
    "#             if self.env.whites_turn: \n",
    "#                 action_probs, zh = self.mcts_white.action_probabilities(encoded_state)\n",
    "#             else:\n",
    "#                 action_probs, zh = self.mcts_black.action_probabilities(encoded_state)\n",
    "# #             if zh is not None:\n",
    "# #                 print(\"ZH NOT NONE\")\n",
    "#             experiences.append([zh.detach().cpu().numpy(), self.env.whites_turn, action_probs, None])\n",
    "# #             else:\n",
    "# #                 print(\"ZH NONE\")\n",
    "#             action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "#             _, _ = self.env.step(action)\n",
    "    \n",
    "#             game_move += 1\n",
    "        \n",
    "#         reward = self.env.result()\n",
    "#         print(f\"Game {self.games} Score {reward}\")\n",
    "#         experiences_ = []\n",
    "#         DISCOUNT_GAMMA = 0.95\n",
    "        \n",
    "#         for idx, experience in enumerate(experiences):\n",
    "#             reward_ = reward\n",
    "#             # calculates the discounted return from the reward.. \n",
    "#             # / 2 becauses it contains experiences of both black and white\n",
    "#             return_ = reward_ * (DISCOUNT_GAMMA ** (len(experiences) - idx) / 2)\n",
    "#             if experience[1] != self.env.whites_turn and (reward_ == 1 or reward_ == -1):\n",
    "#                 return_ *= -1\n",
    "#             experiences_.append((experience[0], experience[2], return_))\n",
    "#         return experiences_\n",
    "    \n",
    "    \n",
    "#     def learn(self):\n",
    "#         \"\"\"\n",
    "#         Performs numIters iterations with numEps episodes of self-play in each\n",
    "#         iteration. After every iteration, it retrains neural network with\n",
    "#         examples in trainExamples (which has a maximum length of maxlenofQueue).\n",
    "#         It then pits the new neural network against the old one and accepts it\n",
    "#         only if it wins >= updateThreshold fraction of games.\n",
    "#         \"\"\"\n",
    "#         # deletes historical experiences so AI to enable online learning\n",
    "#         self.trainExamplesHistory = []\n",
    "        \n",
    "#         for i in range(1, self.iterations + 1):\n",
    "#             iterationTrainExamples = deque([], maxlen = self.queue_length)\n",
    "#             for _ in tnrange(self.episodes, desc = \"Self Play\"):\n",
    "#                 iterationTrainExamples += self.executeEpisode()\n",
    "#                 self.games += 1\n",
    "\n",
    "#             # save the iteration examples to the history \n",
    "#             self.trainExamplesHistory.append(iterationTrainExamples)\n",
    "\n",
    "#         # shuffle examples before training\n",
    "#         trainExamples = []\n",
    "#         for e in self.trainExamplesHistory:\n",
    "#             trainExamples.extend(e)\n",
    "#         shuffle(trainExamples)\n",
    "#         print(len(trainExamples))\n",
    "        \n",
    "#         self.agent.train(trainExamples)\n",
    "#         self.mcts_white.agent = deepcopy(self.agent)\n",
    "#         self.mcts_black.agent = deepcopy(self.agent)\n",
    "        \n",
    "#         self.mcts_white.reset()  # reset search tree as agents brain is now different\n",
    "#         self.mcts_black.reset()\n",
    "        \n",
    "\n",
    "# #         # training new network, keeping a copy of the old one\n",
    "# #         self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         pmcts = MCTS(self.game, self.pnet, self.args)\n",
    "\n",
    "# #         \n",
    "# #         nmcts = MCTS(self.game, self.nnet, self.args)\n",
    "\n",
    "# #         log.info('PITTING AGAINST PREVIOUS VERSION')\n",
    "# #         arena = Arena(lambda x: np.argmax(pmcts.getActionProb(x, temp=0)),\n",
    "# #                           lambda x: np.argmax(nmcts.getActionProb(x, temp=0)), self.game)\n",
    "# #         pwins, nwins, draws = arena.playGames(self.args.arenaCompare)\n",
    "\n",
    "# #         log.info('NEW/PREV WINS : %d / %d ; DRAWS : %d' % (nwins, pwins, draws))\n",
    "# #         if pwins + nwins == 0 or float(nwins) / (pwins + nwins) < self.args.updateThreshold:\n",
    "# #             log.info('REJECTING NEW MODEL')\n",
    "# #             self.nnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         else:\n",
    "# #             log.info('ACCEPTING NEW MODEL')\n",
    "# #             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename=self.getCheckpointFile(i))\n",
    "# #             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='best.pth.tar')\n",
    "        \n",
    "\n",
    "# params = {\n",
    "#     'iterations': 1,\n",
    "#     'episodes': 5,\n",
    "#     'queue_length' : 2000,\n",
    "#     'simulations' : 200\n",
    "# }\n",
    "# coach = Coach(env, agent, params)\n",
    "# for _ in range(1000):\n",
    "#     coach.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coach Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Coach():\n",
    "#     \"\"\"\n",
    "#     This class executes the self-play + learning. It uses the functions defined\n",
    "#     in Game and NeuralNet. args are specified in main.py.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, env, agent, params):\n",
    "#         self.iterations = params['iterations']\n",
    "#         self.episodes = params['episodes']\n",
    "#         self.queue_length = params['queue_length']\n",
    "#         self.simulations = params['simulations']\n",
    "#         self.env = deepcopy(env)\n",
    "#         self.agent = agent\n",
    "#         self.trainExamplesHistory = []  # history of examples from args.numItersForTrainExamplesHistory latest iterations\n",
    "#         self.games = 0\n",
    "    \n",
    "# #     @ray.remote\n",
    "#     def execute_episode(self, agent, game):\n",
    "#         \"\"\"\n",
    "#         This function executes one episode of self-play, starting with player 1.\n",
    "#         As the game is played, each turn is added as a training example to\n",
    "#         trainExamples. The game is played till the game ends. After the game\n",
    "#         ends, the outcome of the game is used to assign values to each example\n",
    "#         in trainExamples.\n",
    "#         It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "#         uses temp=0.\n",
    "#         Returns:\n",
    "#             trainExamples: a list of examples of the form (canonicalBoard, currPlayer, pi,v)\n",
    "#                            pi is the MCTS informed policy vector, v is +1 if\n",
    "#                            the player eventually won the game, else -1.\n",
    "#         \"\"\"\n",
    "#         env = Chess_Environment()\n",
    "#         experiences = []\n",
    "#         mcts_white = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = self.simulations)\n",
    "#         mcts_black = MCTS(deepcopy(env), deepcopy(agent), mcts_simulations = self.simulations)  \n",
    "#         mcts_black.agent.random_controller()\n",
    "#         # RESET HIDDEN STATES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#         game_move = 0\n",
    "#         while not env.terminal_test():\n",
    "#             encoded_state = env.encode()\n",
    "#             if env.whites_turn: \n",
    "#                 action_probs, zh = mcts_white.action_probabilities(encoded_state)\n",
    "#             else:\n",
    "#                 action_probs, zh = mcts_black.action_probabilities(encoded_state)\n",
    "# #             if zh is not None:\n",
    "# #                 print(\"ZH NOT NONE\")\n",
    "#             if env.whites_turn:\n",
    "#                 experiences.append([zh.detach().cpu().numpy(), env.whites_turn, action_probs, None])\n",
    "# #             else:\n",
    "# #                 print(\"ZH NONE\")\n",
    "#             action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "#             _, _ = env.step(action)\n",
    "    \n",
    "#             game_move += 1\n",
    "        \n",
    "#         reward = env.result()\n",
    "#         if not env.whites_turn and ((reward == 1) or (reward == -1)):\n",
    "#             reward = reward * -1\n",
    "        \n",
    "#         if reward == -1:\n",
    "#             print(f\"Game {game} White Loss\")\n",
    "#         elif reward == 1:\n",
    "#             print(f\"Game {game} White Won\")\n",
    "#         else:\n",
    "#             print(f\"Game {game} Draw\")\n",
    "#         experiences_ = []\n",
    "#         DISCOUNT_GAMMA = 0.98\n",
    "        \n",
    "#         for idx, experience in enumerate(experiences):\n",
    "#             if idx == len(experiences) - 1:\n",
    "#                 done = 1\n",
    "#             else: \n",
    "#                 done = 0\n",
    "#             reward_ = reward\n",
    "#             # calculates the discounted return from the reward.. \n",
    "#             # / 2 becauses it contains experiences of both black and white\n",
    "#             return_ = reward_ * (DISCOUNT_GAMMA ** (len(experiences) - idx))\n",
    "# #             if experience[1] != env.whites_turn and (reward_ == 1 or reward_ == -1):\n",
    "# #                 return_ *= -1\n",
    "#             experiences_.append((experience[0], experience[2], return_, done))\n",
    "#         return experiences_\n",
    "    \n",
    "# #     def learn(self, ray):    \n",
    "#     def learn(self):\n",
    "#         \"\"\"\n",
    "#         Performs numIters iterations with numEps episodes of self-play in each\n",
    "#         iteration. After every iteration, it retrains neural network with\n",
    "#         examples in trainExamples (which has a maximum length of maxlenofQueue).\n",
    "#         It then pits the new neural network against the old one and accepts it\n",
    "#         only if it wins >= updateThreshold fraction of games.\n",
    "#         \"\"\"\n",
    "#         # deletes historical experiences so AI to enable online learning\n",
    "#         self.trainExamplesHistory = []\n",
    "        \n",
    "#         for i in range(1, self.iterations + 1):\n",
    "# #             iterationTrainExamples = ray.get([self.execute_episode.remote(self, self.agent, self.games + idx) for idx in range(self.episodes)])\n",
    "#             iterationTrainExamples = [self.execute_episode(self.agent, self.games + idx) for idx in range(self.episodes)]\n",
    "#             self.games += len(iterationTrainExamples)\n",
    "# #             iterationTrainExamples = [item for sublist in iterationTrainExamples for item in sublist]\n",
    "# #             for _ in tnrange(self.episodes, desc = \"Self Play\"):\n",
    "# #                 iterationTrainExamples += self.execute_episode(self.agent, deepcopy(self.agent))\n",
    "# #                 self.games += 1\n",
    "# #             print(len(iterationTrainExamples))\n",
    "#             # save the iteration examples to the history \n",
    "# #             self.trainExamplesHistory.append(iterationTrainExamples)\n",
    "\n",
    "#         # shuffle examples before training\n",
    "# #         trainExamples = []\n",
    "# #         for e in self.trainExamplesHistory:\n",
    "# #             trainExamples.extend(e)\n",
    "# #         shuffle(iterationTrainExamples)\n",
    "# #         print(len(iterationTrainExamples))\n",
    "        \n",
    "#         self.agent.train(iterationTrainExamples)\n",
    "\n",
    "# #         # training new network, keeping a copy of the old one\n",
    "# #         self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         pmcts = MCTS(self.game, self.pnet, self.args)\n",
    "\n",
    "# #         \n",
    "# #         nmcts = MCTS(self.game, self.nnet, self.args)\n",
    "\n",
    "# #         log.info('PITTING AGAINST PREVIOUS VERSION')\n",
    "# #         arena = Arena(lambda x: np.argmax(pmcts.getActionProb(x, temp=0)),\n",
    "# #                           lambda x: np.argmax(nmcts.getActionProb(x, temp=0)), self.game)\n",
    "# #         pwins, nwins, draws = arena.playGames(self.args.arenaCompare)\n",
    "\n",
    "# #         log.info('NEW/PREV WINS : %d / %d ; DRAWS : %d' % (nwins, pwins, draws))\n",
    "# #         if pwins + nwins == 0 or float(nwins) / (pwins + nwins) < self.args.updateThreshold:\n",
    "# #             log.info('REJECTING NEW MODEL')\n",
    "# #             self.nnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "# #         else:\n",
    "# #             log.info('ACCEPTING NEW MODEL')\n",
    "# #             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename=self.getCheckpointFile(i))\n",
    "# #             self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='best.pth.tar')\n",
    "        \n",
    "\n",
    "# params = {\n",
    "#     'iterations': 1,\n",
    "#     'episodes': 2,\n",
    "#     'queue_length' : 2000,\n",
    "#     'simulations' : 2,\n",
    "# }\n",
    "\n",
    "# coach = Coach(env, agent, params)\n",
    "# for _ in range(1):\n",
    "# #     coach.learn(ray)\n",
    "#     coach.learn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setGeometry(100, 100, 1100, 1100)\n",
    "\n",
    "        self.widgetSvg = QSvgWidget(parent=self)\n",
    "        self.widgetSvg.setGeometry(10, 10, 1080, 1080)\n",
    "\n",
    "\n",
    "# board = chess.Board()\n",
    "# app = QApplication([])\n",
    "# window = MainWindow()\n",
    "# window.show()\n",
    "# app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Running on cuda\n",
      "\n",
      "CNN_AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (enc_linear): Linear(in_features=512, out_features=300, bias=True)\n",
      "  (dec_linear): Linear(in_features=300, out_features=512, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (4): Conv(\n",
      "      (conv): ConvTranspose2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "MDN_RNN(\n",
      "  (lstm): LSTM(338, 150, batch_first=True)\n",
      "  (fc1): Linear(in_features=150, out_features=900, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=900, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=900, bias=True)\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "Policy_Controller(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=450, out_features=1200, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): ConvTranspose2d(1200, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): ConvTranspose2d(64, 76, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(76, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "AI Running on cuda\n",
      "\n",
      "Value_Controller(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=450, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADxCAYAAABoIWSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWRElEQVR4nO3debwd8/3H8deXJGQtTTTC6EPtNFoNLcW0pQja0BatR0vVz/KotaVVUz8/+zLqQVu/1pouqpafChVLRavFqIYSRAi1hBoikkhFQiKJ+f0xk9wbuVnmLPOZmfN+Ph73cc49d+7pOzrzvt8zy3dckiSIiEgxVrMOICLSSVS6IiIFUumKiBRIpSsiUiCVrohIgVS6IiIFUulKZTnnLnTOJc65ydnjHOfcgux5969fZ8u855xb5Jyb6Jy7OPvZXOfc+z38Tl/rf5/Uk0pX6mBvYCfgcWAK8D4Qd/v5odky7wIO+BSwDbAQuAbYC3j5A+/5z/ZGlk7VyzqASBN2yx5f7PbafGAIMOkDy44FBmXPF3Z7/WPAEUCf7PuEtJh11ZC0hUa6UmUbZo/PAV/LnvcBDgP+1G25BLi92/cTgJnZ8x2AfYBh2fcue/xMi7OKAOB0GbBUlXPufbpKsrtnSHcPHJx9/zIwi3SXwgctAhaQlvV7wBrZe/4tSZJdW51ZRCNdqYPNkiTpXr5j6Srcn2WP3X/+MvBW9nx1YE3SbWHNbsvt0p6o0ulUulJl87LHa51z52XPE+BH3ZZ5NXu8o9trnyQtWIDpwM+B35GOeBd/9JvW8rQiaPeCVJhz7hLguFVcfB3SIv3gQGMR6Wj3gwYlSfJ2E/FEeqSRrlRWkiTHA8OzXQubZi//MkkS18PXDNLR7VrZ8ruSFu6HlrO8ClfaQiNdqTTn3AK6Tn2ckSTJOitYdhjwPF2DjfOSJDm7zRFFlqLSFREpkHYviIgUSKUrIlIgla6ISIE094KURhxEHwLWI70kd1i35+sC/UnX115Ab9LTvBaRzqOw+Gse6WlhU4HXssfFz2d6oa8DGGJOB9KkUHEQrQl8AtgWGAFsQVe5tnM6xQXA66Ql/Dzp/AuPAhO80J/dxv9dkaWodKVt4iDqS3r11wjSkt0W+Djl+oSVkJbwo9nXBNIi/o9pKqktla60TBxEDtgOGAV8iXREW6aCXVWLi/gu0nkc7vNCf4FtJKkLla40JdtdsBtp0X6ZdFdB3bwFjCMt4Du90J9lnEcqTKUrucVB9BHSkh0F7A70s01UqIXAA8BtwFgv9J83ziMVo9KVVRIHUS/SXQZHAHvS8yQxnegh4CrgBi/051qHkfJT6coKxUG0IWnRHkrX3RVkWW8D1wNXeKE/wTqMlJdKV3oUB9Hnge+R3spGo9p8/k46R+/NXugvsg4j5aLSlSXiIFodOAj4Pj3f2kbyeQX4JXCpF/qaKlIAla5k4iDaHzgH2Nw6Sw1NB84FLvNC/z3rMGJLpdvh4iDaFQiBT1tn6QAvAacDv/dC/33jLGJEpduh4iAaQVq2u1tn6UBPAqd4oX/7SpeU2lHpdpg4iDYh3Y3wdXq+fbkU5wHgZC/0H7QOIsVR6XaIbB6Es4HjSWfpkvIYAxzjhb7uQNwBVLodIA6iHYHfAJtZZ5Hlmgkc54X+9dZBpL1UujWWzYtwDnACmrC+Km4BvuuF/hvWQaQ9VLo1FQfRZ0lHtzoFrHpmAsd6oX+DdRBpPZVuzWSj27OBE9HotupuBo7SqLdeVLo1EgfRtsDvSe/GIPUwg3R3wxjrINIaKt2aiIPoW8BoYE3rLNIW5wGn6j5v1afSrbg4iFYDzgd+ZJ1F2m4scJDmcag2lW6FxUE0CLiOdJ5b6QyTgH280J9iHUQao9KtqOzKsrHAltZZpHAzgf290L/XOojkp6PbFRQH0W7Aw6hwO9Vg4M9xEB1tHUTy00i3YuIgOg74KZpYXFJXkJ7Tu9A6iKwalW6FxEF0NnCqdQ4pnVuAAzVXbzWodCsiDqKfACdZ55DSuhPYzwv9edZBZMVUuiUXB5Ejvd/WcdZZpPT+Auzrhf471kFk+XQgrfx+gQpXVs1uwB3ZNJ5SUirdEouD6GJAR6gljy8Af4yDaA3rINIzlW5JxUF0HumUjCJ57QH8IQ4iTVZfQirdEoqD6L+BH1vnkEobBVyXXSYuJaL/Q0omDqIDSSceF2nW/qTzckiJ6OyFEsnu0PsAoAMh0koHeaF/rXUISal0SyIOoqHAI4BnnUVqZx7wOS/0/2kdRFS6pRAHUR/gXuCzxlFKYYMLPrfU96+cfP9S3181/gbOuu/SJd8P6t2fp0780yr9bgd7DdjOC/2p1kE6nfbplsPlqHAB+MfzEwEY0LsvF+z+QwA2+smuSy2zuHAXF+rsBXOXWu60zx/NwN79l3o/YT3SU8k0yb0xla6xOIhOAA61zlEWXx9zLACTTxzHN0fsA8CCZPlzuVz91RCAmTNnLlnuiB0O5Ols5Lv4/QSAzwBXWofodCpdQ3EQ7QFcaJ2jitZZc20Adt1sRwAO+qOmpVhFB8dBpP9YhlS6RuIgGgbcgKZobIleq/eyjlAlYRxEvnWITqXStXMlsLZ1iKqaPm8WAH/914MA/HaUTkfNYTXgN3EQ9bMO0olUugbiIPo28GXrHGW0eB/tVhfvxXUTxgLQawUfBg65JQBg8ODBS5a7avwNbHXxXgDcuN8v2hm3yjZGF06Y0CljBYuDaD3gKWAt6yxl1dNpX4tfe+Xk+7kkupoLH/zVkp8P6N2XySeOW+7vynIlwBe80Nd/pAKpdAsWB9Ht6O69Uh4vAJ/QHLzF0e6FAsVBdAgqXCmXjYHQOkQn0Ui3IHEQrQ9MQrsVpHwSYBcv9O+zDtIJNNItzpWocKWcHPDrOIj6WwfpBCrdAsRB9HVgb+scIiuwEXCadYhOoN0LbZbN3v80sIl1FpGVmAds6oV+bB2kzjTSbb/DUeFKNawJnGEdou400m2jbB/Z88C61llEVtEiYGsv9CdbB6krjXTb6/uocKVaVgfOtQ5RZxrptkkcRIOBF4FB1llEGrCDF/oPWYeoI4102+cUVLhSXbpgok000m2DOIg+CvwLWMM6i0gT9vJC/y7rEHWjkW57nIEKV6rv/DiInHWIulHptlh2ue9B1jlEWmAbYKR1iLpR6bbe0UBv6xAiLfI96wB1o326LZTdafUVYIh1FpEWSYAtvdB/1jpIXWik21rfQoUr9eKA461D1IlKt7V0v2+po0PiIBpoHaIuVLotEgfRp0kPPIjUTX/gm9Yh6kKl2zpHWAcQaSOt3y2iA2ktEAfRAGAqMMA6i0gbjfBC/zHrEFWnkW5rfAMVrtTf4dYB6kCl2xoHWAcQKcB+ukKteSrdJmVHdXexziFSgKHA9tYhqk6l27yRQB/rECIF2cc6QNWpdJs3yjqASIG0vjdJZy80IQ6i1YHX0VVo0lk28kJ/inWIqtJItzk7osKVzqNdDE1Q6TZHH7WkE2m9b4JKtzn6iy+d6HNxEH3IOkRVqXQbFAfRZsDm1jlEDPQG9rIOUVUq3cbp3FzpZFr/G6TSbdy21gFEDGn9b5BKt3Fa6aSTbR0HkS4KaoBKtwHZyjbcOoeIIW0DDVLpNmZrdOmviD7tNUCl2xitbCLaDhqi0m3MCOsAIiWg0m2ASrcxWtlE0oNpva1DVI1KN6dsJdvaOodICayBDqblptLNb0vSlU1E4FPWAapGpZvfR60DiJTIBtYBqkalm98w6wAiJaLtISeVbn5ayUS6aHvISaWb33rWAURKRKWbk0o3P61kIl20PeSk0s1PK5lIl3XjIHLWIapEpZufdi+IdOkFrGMdokpUujnEQbQaMNQ6h0jJ6NNfDirdfIaQ/mUXkS4q3RxUuvkMtg4gUkLaLnJQ6eajyT1ElqXtIgeVbj7atSCyLG0XOah089FfdJFlabvIQaWbj/6iiyxL20UOKl0RaZYujshBpZvPQusAIiW0wDpAlah081HpiixL20UOKt18tHKJLEvbRQ4q3Xz0MUpkWdouclDp5vMf6wAiJaTtIgeVbj7TgPetQ4iUzFTrAFWi0s3BC/1FwBvWOURKRqWbg0o3P61gIl3eJ/0EKKtIpZufSlekyxvZJ0BZRSrd/FS6Il20PeSk0s3vNesAIiWi0s1JpZufVjKRLtoeclLp5qeVTKSLtoecVLr5xdYBRErkVesAVaPSze9pQEdrRVJPWAeoGpVuTl7ovwNMts4hUgKLUOnmptJtzATrACIlMDkbhEgOKt3GPGodQKQEtB00QKXbGK1sItoOGqLSbczjaLYxEZVuA1S6DfBCfy7wjHUOEUOLSAcfkpNKt3H6Ky+d7BkdRGuMSrdxKl3pZFr/G6TSbdz91gFEDEXWAapKpdsgL/QfQ5cES2dKgNutQ1SVSrc5WvGkE/3TC/3XrUNUlUq3OWOtA4gY0HrfBJVuc/4KzLEOIVIwlW4TVLpN8EJ/PvBn6xwiBXrJC/0nrUNUmUq3efqrL53kNusAVafSbd4d6JJg6RwaZDRJpdskL/SnA+Otc4gUYDZwn3WIqlPptsYY6wAiBbjNC/0F1iGqTqXbGtcA71mHEGmzX1kHqAOVbgtkuxhutc4h0kbPA/dah6gDlW7rXGUdQKSNRnuhn1iHqAOVbuv8BZhiHUKkDRYAv7UOURcq3RbJRgGXWecQaYMxXuhPsw5RFyrd1hoNzLUOIdJiP7cOUCcq3RbyQn8W8DvrHCIt9JAX+joPvYVUuq13Cel8oyJ1oFFui6l0W8wL/WdILw0WqbqXgZusQ9SNSrc9/hvNxyDVd5quQGs9lW4beKE/EbjOOodIE54Efm8doo5Uuu3zP+jSYKmuU7zQ16e1NlDptokX+i8Bl1vnEGnAA17o6/5/baLSba9zgLetQ4jkFFgHqDOVbhtlE+FcZJ1DJIfbvND/u3WIOlPptt9FwBvWIURWwfvAKdYh6k6l22Ze6M8h3c0gUnbXeKE/yTpE3al0i3EZ8Kh1CJEVmAmcbB2iE6h0C+CF/kLgO+gUMimvYzWTWDFUugXJPradZZ1DpAc3e6F/g3WITqHSLdYFaDeDlMsM4CjrEJ3EJYkmxCpSHETDSYu3j3UWSz+4M+SeFx5kcL+1ueewqwGY9e5sjrn1DF6ZPZUNBg3j0q+cyVprDiRJEk6/5xL++sJ4+vZeg4v3/jFbr7v5Mu858fVnOfGO85i38D123XgHzvzi8Tjnlvu+AsCBXuj/n3WITqKRbsGy3QxnWuewdsDWe3LNARcu9dql469lpw1HEB15PTttOIJLx6eX/v/txfFMeTMmOvI6Lhh5EqfcfXGP73nK3RdxwZ4nER15HVPejLn3xYdW+L7CGBVu8VS6Ni4AHrEOYWmHDbZhrb6Dlnrt7ucfYP/hewKw//A9GffcA+nrzz3AfsNH4pxjxPofZ/b8OUybM2Op3502ZwZz5r/DtusPxznHfsNHMu65aIXv2+FmAEdbh+hEKl0DXugvIj2bYb5xlFKZMXcWQwcMAWDogCHMnDsLgNfnzGC9QR9Zstywgevw+ttLl+7rb89g2MB1ll4mK+blvW+HO8YLfV20Y0Cla8QL/aeAY61zVEFPxx2cc0sv08PNOhxumdcEgMu90L/ROkSnUuka8kJ/NPAL6xxlMaT/2kt2G0ybM4PB/dcG0lHra7O7BmVT357O0AGDl/rdYQPXYerb03tcZnnv26HuBY63DtHJVLr2TgDusQ5RBrtvshM3TboLgJsm3cUem+ycvr7pzoyZNI4kSZjw6lMMXKP/kt0Fiw0dMIT+ffox4dWnSJKEMZPGscemO6/wfTvQFOAA3Q3Clk4ZK4E4iD4MPAxsbJ2lKMeMPZPx/36MN999iyH9PswPdj6UkZv5HHXr6bw6exrrDxrKZfuexdp9B5EkCaf++afcO+Vh+vZag4v2/jGfHLYFACN/81+MO/TXADwx9RlOvPN85i2czy4bbc/Zu30/O2XsrR7ft8PMAXb0Qv9J6yCdTqVbEnEQbQWMB3QCqbRaAnzNC/0/WgcR7V4oDS/0nwa+iW5oKa13ugq3PFS6JZLdIuVU6xxSKzd6oX+2dQjpotItGS/0zweuts4htfAwcKh1CFmaSrecDgP+YB1CKu0xYKQX+u9YB5Gl6UBaScVB1Au4CdjXOotUziRgFy/0Z6x0SSmcSrfE4iDqA9wK7GmdRSrjWeDzmpC8vLR7ocS80H8P+Cpwp3UWqYTJpCNcFW6JqXRLzgv9eaTFq1N+ZEUmko5wp1oHkRVT6VZANuI9ANDcp9KTR0lHuNNXuqSYU+lWRHZzy2+R3llYZLF7gC96of+mdRBZNTqQVkFxEB0FXAL0ss4ipv4XODH7gywVodKtqDiIvkB6StnglSwq9fMe6STko62DSH4q3QqLg+hjpKeUbW2dRQoznXTyGt1zqKK0T7fCvNCfAuxIWrxSf08An1bhVptKt+K80J9DekrZudZZpK3GADt5of+ydRBpjnYv1EgcRPsDVwIdfT+amlkAnAmc54W+NtYaUOnWTBxEw0iL98vWWaRpTwDf8UL/cesg0joq3ZqKg+jbwM+BtayzSG4LgPOAc3U/s/pR6dZYHETrkY56v2SdRVaZRrc1p9LtAHEQHQL8DI16y2wBcD5wjka39abS7RBxEK0PXIFGvWWk0W0HUel2mDiI9gBC4FPWWYRXgNOB33mhv8g6jBRDpduB4iBywDeAc4CNjeN0ojdJD5T9Mpu6UzqISreDxUHUGzgCOA0YahynE7xDum/9J17ov2UdRmyodIU4iPoDJwAnAYOM49TRQmA0cJYmGReVriwRB9Fg0uI9El3V1grzgetJryZ7zjqMlINKV5YRB1E/4GDgeGAr4zhVNJV0svkrvNB/wzqMlItKV1YoDqLdge8C+6BJ01fmftKLUW7UubayPCpdWSVxEA0FvgMcDmxim6ZUpgNXA6O90H/WOoyUn0pXcslON9sJ2BcYBWxum8jEVOB2YCxwd3bjUJFVotKVpsRBtBnprodRpGW8um2itplIWrJjgUc0zaI0SqUrLRMH0YdJLzMeBewJDLRN1JT3gPvIitYL/X8b55GaUOlKW8RBtDrpmQ/bAiOyx22Afpa5lmMB8BTwKDAhe3xCV4tJO6h0pTBZEW9BWsCLy3hLir2j8WzgBdJiXfw10Qv9+QVmkA6m0hVzcRD1AdYFhgHrZY8ffN6P9JS1XkBv0n3Hi0iv9lr8NQ+YRnqg67XscWr3773Qf6eof5dIT1S6IiIF0t2ARUQKpNIVESmQSldEpEAqXRGRAql0RUQKpNKVQjnnjnfOTXbOJc65idnXg865T/awzLXOuX2zZR53zj3inNvZMr9Is3TKmBTKOfcMsBfpubeTkySZ5ZzbCzgjSZLtuy+TJMkU59wAYG6SJIlz7hPAjUmSbGH2DxBpkka6Uhjn3OXARqTzGWyfJMms7EfjAe+DyzjnTkiSZE7SNTLoD2iUIJWmka4Uyjn3ErBdkiQzur32Q2CLJEkO72kZ59xXgfOBjwBfSpLkH0XnFmkVjXTFlHNuF+Aw4OTlLZMkyS3ZLoWvAGcXlU2kHVS6YibbRzsa2DdJkpkrWz5JkvuBjZ1zQ9oeTqRNVLpiwjn3UeBm4OAkSf61guU2cc657PkIoA+w0oIWKSvdaFCsnEY6peOlWacuTJJkux6W2w/4tnNuAfAu8I1EByKkwnQgTUSkQNq9ICJSIJWuiEiBVLoiIgVS6YqIFEilKyJSIJWuiEiBVLoiIgX6fwdNYDIGA+xAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SanujaPC\\AppData\\Local\\conda\\conda\\envs\\trader\\lib\\site-packages\\ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plotter\n",
    "class Arena:\n",
    "    \"\"\"An Arena where you can have two players fight\"\"\"\n",
    "    \n",
    "    def __init__(self, env, agent):\n",
    "        self.env = env        \n",
    "        self.agent = agent\n",
    "        self.root = tk.Tk()\n",
    "        self.root.withdraw()\n",
    "        self.app = QApplication([])\n",
    "        self.window = MainWindow()\n",
    "    \n",
    "    def vs_human(self):\n",
    "        \"\"\"Fight Against the AI\"\"\"\n",
    "        self.agent = Agent(self.env.decoder, self.env.action_size, 'Test', 'Test', 'Test', test_mode = True)\n",
    "        self.mcts_black = MCTS(deepcopy(self.env), deepcopy(self.agent), mcts_simulations = 20)\n",
    "        \n",
    "        self.env.reset()\n",
    "        self.mcts_black.reset()\n",
    "        game_move = 0\n",
    "        while not self.env.terminal_test():\n",
    "            if not self.env.whites_turn:\n",
    "                encoded_state = self.env.encode()\n",
    "                action_probs, zh = self.mcts_black.action_probabilities(encoded_state, temp = 0)\n",
    "                \n",
    "                figureObject, axesObject = plotter.subplots()\n",
    "                # Draw the pie chart\n",
    "                axesObject.pie(list(action_probs.values()), labels = list(action_probs.keys()), autopct = '%1.2f', startangle = 90)\n",
    "                # Aspect ratio - equal means pie is a circl\n",
    "                axesObject.axis('equal')\n",
    "                plotter.show()\n",
    "                \n",
    "                \n",
    "                action = random.choices(list(action_probs.keys()), weights = action_probs.values(), k = 1)[0]\n",
    "            else:\n",
    "                legal_actions = self.env.legal_actions() \n",
    "                self.render()\n",
    "                action = simpledialog.askstring(title = \"Move\", prompt = f\"What's your next move?\\n{legal_actions}\")\n",
    "                while action not in legal_actions:\n",
    "                    action = simpledialog.askstring(title = \"Move\", prompt = f\"Invalid Move. What's your next move?\\n{legal_actions}\")\n",
    "                    if action is None:\n",
    "                        break\n",
    "                if action is None:\n",
    "                    break\n",
    "            \n",
    "            _, _ = self.env.step(action)\n",
    "            game_move += 1   \n",
    "        print(env.result())\n",
    "        \n",
    "    def render(self):\n",
    "        \"\"\"Renders the chess board\"\"\"\n",
    "        chessboardSvg = chess.svg.board(self.env.board).encode(\"UTF-8\")\n",
    "        self.window.widgetSvg.load(chessboardSvg)\n",
    "        self.window.show()\n",
    "        self.app.exec()\n",
    "        \n",
    "        \n",
    "arena = Arena(env, agent)\n",
    "arena.vs_human()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-trader]",
   "language": "python",
   "name": "conda-env-conda-trader-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
